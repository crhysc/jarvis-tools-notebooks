{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/crhysc/jarvis-tools-notebooks/blob/master/jarvis-tools-notebooks/flowmm_example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Tutorial**: FlowMM & FlowLLM\n",
        "\n",
        "\n",
        "\n",
        "**Authors**: Charles \"Rhys\" Campbell (crc00042@mix.wvu.edu)"
      ],
      "metadata": {
        "id": "MUMuDXuhXvRE"
      },
      "id": "MUMuDXuhXvRE"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TABLE OF CONTENTS\n",
        "\n",
        "- Background and Central Goal\n",
        "- Installation, Configuration, and Dependencies\n",
        "- Dataset ETL\n",
        "- Training\n",
        "  - Manifolds\n",
        "  - Unconditional Training\n",
        "  - Conditional Training\n",
        "  - FlowLLM\n",
        "- Inference\n",
        "  - De Novo Generation / Unconditional Evalation\n",
        "  - Reconstruction / Conditional Evaluation\n",
        "- Next Steps & References"
      ],
      "metadata": {
        "id": "dMNVDRFTNM12"
      },
      "id": "dMNVDRFTNM12"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (1) BACKGROUND AND CENTRAL GOAL\n"
      ],
      "metadata": {
        "id": "GHy9RobiX6HO"
      },
      "id": "GHy9RobiX6HO"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Background\n",
        "### FlowMM\n",
        "**FlowMM** uses Riemannian flow matching to learn how to transform simple base noise into full periodic crystal structures by jointly modeling fractional atomic coordinates and lattice parameters on the manifold defined by crystal symmetries. It tackles both **Crystal Structure Prediction** (finding the stable arrangement for a known composition) and **De Novo Generation** (proposing entirely new materials), doing so with about three times fewer integration steps than comparable diffusion-based approaches.  \n",
        "\n",
        "### FlowLLM\n",
        "**FlowLLM** builds on FlowMM by swapping out the simple analytic noise prior for samples from a pretrained CrystalLLM (a LLaMA‐style model fine-tuned on crystal data). You generate initial “noisy” structures with the LLM, then use the same Riemannian flow-matching steps to refine those into accurate crystal geometries.\n",
        "\n",
        "\n",
        "# Central Goal\n",
        "Show viewers how to install, train, and use FlowMM and FlowLLM.\n",
        "  \n"
      ],
      "metadata": {
        "id": "-j5wcOCnLGsZ"
      },
      "id": "-j5wcOCnLGsZ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (2) INSTALLATION, CONFIGURATION, AND DEPENDENCIES\n"
      ],
      "metadata": {
        "id": "RxCe6MOhX8wW"
      },
      "id": "RxCe6MOhX8wW"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install Conda"
      ],
      "metadata": {
        "id": "ZFu1FE4zxU_G"
      },
      "id": "ZFu1FE4zxU_G"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d40fa633",
      "metadata": {
        "id": "d40fa633"
      },
      "outputs": [],
      "source": [
        "!pip install -q condacolab\n",
        "import condacolab, os, sys\n",
        "condacolab.install()\n",
        "print(\"Done\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note**: Colab and FlowMM have hard pins for different Python and CUDA versions. To bypass this, the \"!conda run\" command will be used to run most code in this notebook. This bypasses the hard pinned Colab Python version by spinning up a conda subprocess that runs its own Python kernel with the correct version required by FlowMM."
      ],
      "metadata": {
        "id": "e14fotvTP8C7"
      },
      "id": "e14fotvTP8C7"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install FlowMM"
      ],
      "metadata": {
        "id": "RxnmdEiyX-3s"
      },
      "id": "RxnmdEiyX-3s"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87930ce0",
      "metadata": {
        "id": "87930ce0",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "import os\n",
        "%cd /content\n",
        "if not os.path.exists('flowmm'):\n",
        "  !git clone https://github.com/crhysc/flowmm.git\n",
        "print(\"Done\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load FlowMM submodules"
      ],
      "metadata": {
        "id": "zcCZJKnD9QxI"
      },
      "id": "zcCZJKnD9QxI"
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "cd /content/flowmm\n",
        "cat .gitmodules\n",
        "sed -i 's|git@github.com:jiaor17/DiffCSP.git|https://github.com/jiaor17/DiffCSP.git|' .gitmodules\n",
        "sed -i 's|git@github.com:crhysc/cdvae.git|https://github.com/crhysc/cdvae.git|' .gitmodules\n",
        "sed -i 's|git@github.com:crhysc/riemannian-fm.git|https://github.com/crhysc/riemannian-fm.git|' .gitmodules\n",
        "git submodule sync\n",
        "git submodule update --init --recursive\n",
        "echo \"Done\""
      ],
      "metadata": {
        "id": "xQy_gJDV3hGz"
      },
      "id": "xQy_gJDV3hGz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Switch Colab Runtime to GPU\n",
        "At the top menu by the Colab logo, select **Runtime** -> **Change runtime type** -> **Any GPU**    \n",
        "\n",
        "It is not necessary to run on GPU, but the code will complete faster.\n",
        "\n"
      ],
      "metadata": {
        "id": "RKNI_pfiYKez"
      },
      "id": "RKNI_pfiYKez"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create conda environment for FlowMM\n",
        "Making the conda environment takes 20 minutes\n"
      ],
      "metadata": {
        "id": "I5U2uH3HYGYA"
      },
      "id": "I5U2uH3HYGYA"
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "%cd /content/flowmm\n",
        "!mamba env create -p /usr/local/envs/flowmm_env -f environment.yml\n",
        "!conda run -p /usr/local/envs/flowmm_env --live-stream\\\n",
        "    pip install uv\n",
        "!conda run -p /usr/local/envs/flowmm_env --live-stream\\\n",
        "    uv pip install \"jarvis-tools>=2024.5\" \"pymatgen>=2024.1\" pandas numpy tqdm\n",
        "!conda run -p /usr/local/envs/flowmm_env --live-stream\\\n",
        "    uv pip install -e . \\\n",
        "                   -e remote/riemannian-fm \\\n",
        "                   -e remote/cdvae \\\n",
        "                   -e remote/DiffCSP-official\n",
        "print(\"Done\")"
      ],
      "metadata": {
        "id": "A5IcN8lTF_rv",
        "collapsed": true
      },
      "id": "A5IcN8lTF_rv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add __ init __.py to manifm and reinstall"
      ],
      "metadata": {
        "id": "u1EcSG2nh2r5"
      },
      "id": "u1EcSG2nh2r5"
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/flowmm/\n",
        "import os\n",
        "if not os.path.exists('remote/riemannian-fm/manifm/__init.py__'):\n",
        "    !wget -q https://raw.githubusercontent.com/crhysc/utilities/refs/heads/main/__init__.py\n",
        "    !mv __init__.py /content/flowmm/remote/riemannian-fm/manifm/\n",
        "!conda run -p /usr/local/envs/flowmm_env --live-stream\\\n",
        "    pip install -e /content/flowmm/remote/riemannian-fm/i\n",
        "!conda run -p /usr/local/envs/flowmm_env --live-stream\\\n",
        "    python -c \"import manifm; print('manifm version:', manifm.__version__)\""
      ],
      "metadata": {
        "id": "7puO0mzJqtIV"
      },
      "id": "7puO0mzJqtIV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install Other dependencies\n"
      ],
      "metadata": {
        "id": "-S-tghd_r5at"
      },
      "id": "-S-tghd_r5at"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (3) DATASET ETL (Extract-Transform-Load)\n"
      ],
      "metadata": {
        "id": "U0r5S-jNYNje"
      },
      "id": "U0r5S-jNYNje"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download data pre-processor"
      ],
      "metadata": {
        "id": "w0bEujxyydMx"
      },
      "id": "w0bEujxyydMx"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data was generated using this [script](https://github.com/crhysc/utilities/blob/main/supercon_preprocess.py). It compiles a set of around 1000 structures and their superconducting critical temperatures into the format required for FlowMM training."
      ],
      "metadata": {
        "id": "yA221iCNZyh-"
      },
      "id": "yA221iCNZyh-"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a01b9fa5",
      "metadata": {
        "id": "a01b9fa5",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "%cd /content/flowmm\n",
        "import os\n",
        "if not os.path.exists('supercon_preprocess.py'):\n",
        "  !wget -q https://raw.githubusercontent.com/crhysc/utilities/refs/heads/main/supercon_preprocess.py\n",
        "%cat supercon_preprocess.py"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run data pre-processor"
      ],
      "metadata": {
        "id": "0QyFCXnQyh1u"
      },
      "id": "0QyFCXnQyh1u"
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/flowmm\n",
        "!conda run -p /usr/local/envs/flowmm_env --live-stream \\\n",
        "    python supercon_preprocess.py \\\n",
        "        --dataset dft_3d \\\n",
        "        --id-key jid \\\n",
        "        --target Tc_supercon \\\n",
        "        --train-ratio 0.8 --val-ratio 0.1 --test-ratio 0.1 \\\n",
        "        --seed 123 \\\n",
        "        --max-size 25\n",
        "print(\"Done\")"
      ],
      "metadata": {
        "id": "10tlt-F9hOkC"
      },
      "id": "10tlt-F9hOkC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Move train/test/val data to the correct spot"
      ],
      "metadata": {
        "id": "c-lJ4YZRylJW"
      },
      "id": "c-lJ4YZRylJW"
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "%mkdir /content/flowmm/data/supercon\n",
        "%mv /content/flowmm/train.csv /content/flowmm/data/supercon/\n",
        "%mv /content/flowmm/val.csv /content/flowmm/data/supercon/\n",
        "%mv /content/flowmm/test.csv /content/flowmm/data/supercon/\n",
        "print(\"Done\")"
      ],
      "metadata": {
        "id": "EDghvbM-oSi6"
      },
      "id": "EDghvbM-oSi6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pull the supercon Hydra config YAML from GitHub"
      ],
      "metadata": {
        "id": "gXIfC4ZZIN5y"
      },
      "id": "gXIfC4ZZIN5y"
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/flowmm/scripts_model/conf/data/\n",
        "!wget https://raw.githubusercontent.com/crhysc/utilities/refs/heads/main/supercon.yaml\n",
        "%cat supercon.yaml"
      ],
      "metadata": {
        "id": "tnBU6MCdIT9e"
      },
      "id": "tnBU6MCdIT9e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modify FlowMM hardcode to accept our supercon dataset"
      ],
      "metadata": {
        "id": "XP9mA1542KMZ"
      },
      "id": "XP9mA1542KMZ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, open **Files** in the left sidebar and navigate to **/Content/flowmm/src/flowmm/**. Click **cfg_utils.py**, and on line 15, add \"supercon\" to the *dataset_options* literal and delete all other strings in the tuple."
      ],
      "metadata": {
        "id": "oGES28ePM1Jx"
      },
      "id": "oGES28ePM1Jx"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, open **Files** again and navigate to /Content/flowmm/src/flowmm/rfm/manifolds/. Click **spd.py**, and then navigate to the \"if __ name __ = __ main __\" block. Uncomment lines 449 through 466 (we are turning on \"compute_stats\". Next, on line 468, set \"compute_stats = True\". Next, on line 489, set \"compute_stats = True\" again. Next, on line 461, change \"\"std\": std.cpu().tolist()\" to \"\"logmap_std\": std.cpu().tolist(),\". Next, on line 236, change the \"std\" string to \"logmap_std\". Next, on line 431, in the \".std()\" function, add \"unbiased=False\" in between the parentheses so that the whole line reads \"std_coefs.append((log_noise_samples.std(unbiased=False) ** (3 / 2)) / n)\n",
        "\"."
      ],
      "metadata": {
        "id": "HIlAyUrkld69"
      },
      "id": "HIlAyUrkld69"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, open Files again and navigate to /Content/flowmm/src/flowmm/rfm/manifolds/. Click **spd.py**, and then replace all code including and after line 531, which is a comment saying \"# do some testing for SPDNonIsotropicRandom\""
      ],
      "metadata": {
        "id": "sWOLJeUwxHa1"
      },
      "id": "sWOLJeUwxHa1"
    },
    {
      "cell_type": "markdown",
      "source": [
        "    pL_stats = OmegaConf.load(Path(__file__).parent / \"spd_pLTL_stats.yaml\")  # ← new line\n",
        "\n",
        "    for dataset in tqdm(list(dataset_options.__args__)):\n",
        "          mean_vec = torch.tensor(pL_stats[dataset][\"mean\"])           # now using pL_stats\n",
        "          std_vec  = torch.tensor(pL_stats[dataset][\"logmap_std\"])     # correct key name\n",
        "\n",
        "          # optional sanity check\n",
        "          if mean_vec.ndim == 0:\n",
        "              raise ValueError(\n",
        "                  f\"Loaded mean for {dataset} is scalar—wrong YAML? shape {mean_vec.shape}\"\n",
        "              )\n",
        "\n",
        "          s = manifm_SPD(Riem_geodesic=True, Riem_norm=True)\n",
        "          spd = SPDNonIsotropicRandom(mean_vec, std_vec)\n",
        "          r   = spd.random_base(10, mean_vec.size(-1))\n",
        "          lp  = spd.base_logprob(r)\n",
        "          print(r, lp)\n",
        "\n",
        "          r  = spd.random_base(3, 10, mean_vec.size(-1))\n",
        "          lp = spd.base_logprob(r)\n",
        "          print(r, lp)"
      ],
      "metadata": {
        "id": "8nst0kL8xJst"
      },
      "id": "8nst0kL8xJst"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate necessary YAML files for training"
      ],
      "metadata": {
        "id": "TgDT_QRk1LtU"
      },
      "id": "TgDT_QRk1LtU"
    },
    {
      "cell_type": "code",
      "source": [
        "%rm /content/flowmm/src/flowmm/rfm/manifolds/atom_density.yaml\n",
        "%rm /content/flowmm/src/flowmm/rfm/manifolds/spd_pLTL_stats.yaml\n",
        "%rm /content/flowmm/src/flowmm/rfm/manifolds/spd_std_coef.yaml"
      ],
      "metadata": {
        "id": "Wf2CMJChQDOe"
      },
      "id": "Wf2CMJChQDOe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/flowmm\n",
        "!bash create_env_file.sh && \\\n",
        " echo \"successfully ran create_env_file.sh\" && \\\n",
        " HYDRA_FULL_ERROR=1 \\\n",
        " FLOWMM_DEBUG=1 \\\n",
        " conda run -p /usr/local/envs/flowmm_env --live-stream \\\n",
        "    python -u -m flowmm.rfm.manifolds.spd"
      ],
      "metadata": {
        "collapsed": true,
        "id": "-zY7EpeZ1Y8m"
      },
      "id": "-zY7EpeZ1Y8m",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create lattice_params_stats.yaml"
      ],
      "metadata": {
        "id": "b4KcshWPqYuX"
      },
      "id": "b4KcshWPqYuX"
    },
    {
      "cell_type": "code",
      "source": [
        "!rm /content/flowmm/src/flowmm/rfm/manifolds/lattice_params_stats.yaml"
      ],
      "metadata": {
        "id": "ER9tCF56qhQ3"
      },
      "id": "ER9tCF56qhQ3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/flowmm\n",
        "!bash create_env_file.sh && \\\n",
        " echo \"successfully ran create_env_file.sh\" && \\\n",
        " HYDRA_FULL_ERROR=1 \\\n",
        " conda run -p /usr/local/envs/flowmm_env --live-stream \\\n",
        "    python -u -m flowmm.rfm.manifolds.lattice_params"
      ],
      "metadata": {
        "id": "mH7tDlGTqbx-"
      },
      "id": "mH7tDlGTqbx-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create the required affine stats YAML for the dataset"
      ],
      "metadata": {
        "id": "nuaxNOR5FTF8"
      },
      "id": "nuaxNOR5FTF8"
    },
    {
      "cell_type": "code",
      "source": [
        "%rm /content/flowmm/src/flowmm/model/stats_supercon*"
      ],
      "metadata": {
        "id": "GflTiCivR1OV"
      },
      "id": "GflTiCivR1OV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/flowmm\n",
        "!bash create_env_file.sh && \\\n",
        " echo \"successfully ran create_env_file.sh\" && \\\n",
        " HYDRA_FULL_ERROR=1 \\\n",
        " conda run -p /usr/local/envs/flowmm_env --live-stream \\\n",
        "    python -u -m flowmm.model.standardize \\\n",
        "                 data=supercon"
      ],
      "metadata": {
        "id": "hbr5_rFN8vyq"
      },
      "id": "hbr5_rFN8vyq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (4) TRAINING\n",
        "# Manifolds\n",
        "\n",
        "\n",
        "- FlowMM allows the user to select a variety of manifolds via the keyword argument   \n",
        "`model={atom_type_manifold}_{lattice_manifold}`  \n",
        "when using `scripts_model/run.py`.  \n",
        "\n",
        "- Atom type manifolds and lattice type manifolds can be found in `scripts_model/conf/model`."
      ],
      "metadata": {
        "id": "G7RtzMrfZ16h"
      },
      "id": "G7RtzMrfZ16h"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Unconditional Training"
      ],
      "metadata": {
        "id": "k2NUXjT_A718"
      },
      "id": "k2NUXjT_A718"
    },
    {
      "cell_type": "code",
      "source": [
        "%pwd"
      ],
      "metadata": {
        "id": "5kk4YLU2Qyky"
      },
      "id": "5kk4YLU2Qyky",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/flowmm\n",
        "!bash create_env_file.sh && \\\n",
        "  HYDRA_FULL_ERROR=1 \\\n",
        "  WANDB_MODE=disabled \\\n",
        "  conda run -p /usr/local/envs/flowmm_env \\\n",
        "    python -u -m scripts_model.run \\\n",
        "      data=supercon \\\n",
        "      model=abits_params \\\n",
        "      train.pl_trainer.accelerator=cpu \\\n",
        "      train.pl_trainer.devices=1 \\\n",
        "      train.model_checkpoints.save_last=True \\\n",
        "      logging.val_check_interval=1  \\\n",
        "      train.pl_trainer.max_epochs=1"
      ],
      "metadata": {
        "collapsed": true,
        "id": "HzvxQufsW02F"
      },
      "id": "HzvxQufsW02F",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conditional Training"
      ],
      "metadata": {
        "id": "BdD4OYhiZ6RR"
      },
      "id": "BdD4OYhiZ6RR"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b4bd253",
      "metadata": {
        "id": "1b4bd253",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "%cd /content/flowmm\n",
        "!bash create_env_file.sh && \\\n",
        " echo \"successfully ran create_env_file.sh\" && \\\n",
        " HYDRA_FULL_ERROR=1 \\\n",
        " conda run -p /usr/local/envs/flowmm_env --live-stream \\\n",
        "    python -u -m scripts_model.run data=supercon model=null_params"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FlowLLM Training"
      ],
      "metadata": {
        "id": "7w1-2_bTg2JE"
      },
      "id": "7w1-2_bTg2JE"
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/flowmm\n",
        "!bash create_env_file.sh && \\\n",
        " echo \"successfully ran create_env_file.sh\" && \\\n",
        " HYDRA_FULL_ERROR=1 \\\n",
        " conda run -p /usr/local/envs/flowmm_env --live-stream \\\n",
        "    python -u -m scripts_model.run data=mp20_llama model=null_params \\\n",
        "      base_distribution_from_data=True"
      ],
      "metadata": {
        "id": "4Yp_mWsEg01N"
      },
      "id": "4Yp_mWsEg01N",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (5) INFERENCE\n",
        "# Unconditional Evaluation - De Novo Generation\n",
        "\n"
      ],
      "metadata": {
        "id": "82OOqQ49aAgQ"
      },
      "id": "82OOqQ49aAgQ"
    },
    {
      "cell_type": "code",
      "source": [
        "!bash create_env_file.sh && \\\n",
        " echo \"successfully ran create_env_file.sh\" && \\\n",
        " ckpt=PATH_TO_CHECKPOINT \\\n",
        " subdir=NAME_OF_SUBDIRECTORY_AT_CHECKPOINT \\\n",
        " slope=SLOPE_OF_INFERENCE_ANTI_ANNEALING \\\n",
        " conda run -p /usr/local/envs/flowmm_env --live-stream \\\n",
        "    python scripts_model/evaluate.py generate ${ckpt} --subdir ${subdir} \\\n",
        "      --inference_anneal_slope ${slope} --stage test && \\\n",
        "    python scripts_model/evaluate.py consolidate ${ckpt} --subdir ${subdir} && \\\n",
        "    python scripts_model/evaluate.py old_eval_metrics ${ckpt} --subdir ${subdir} \\\n",
        "      --stage test && \\\n",
        "    python scripts_model/evaluate.py lattice_metrics ${ckpt} --subdir ${subdir} \\\n",
        "      --stage test"
      ],
      "metadata": {
        "id": "36yfncwoIjTG"
      },
      "id": "36yfncwoIjTG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from pprint import pprint\n",
        "path = \"/content/cdvae/hydra_outputs/singlerun/2025-05-27/supercon/eval_recon.pt\"\n",
        "data = torch.load(path, map_location=\"cpu\", weights_only=False)\n",
        "pprint(data, width=120, indent=2)"
      ],
      "metadata": {
        "id": "OU1Tnz-jEIGH"
      },
      "id": "OU1Tnz-jEIGH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conditional Evaluation - Crystal Structure Prediction - Reconstruction"
      ],
      "metadata": {
        "id": "mLqYqyMOffIa"
      },
      "id": "mLqYqyMOffIa"
    },
    {
      "cell_type": "code",
      "source": [
        "!bash create_env_file.sh && \\\n",
        " echo \"successfully ran create_env_file.sh\" && \\\n",
        " ckpt=PATH_TO_CHECKPOINT \\\n",
        " subdir=NAME_OF_SUBDIRECTORY_AT_CHECKPOINT \\\n",
        " slope=SLOPE_OF_INFERENCE_ANTI_ANNEALING \\\n",
        " conda run -p /usr/local/envs/flowmm_env --live-stream \\\n",
        "    python scripts_model/evaluate.py reconstruct ${ckpt} --subdir ${subdir} \\\n",
        "      --inference_anneal_slope ${slope} --stage test && \\\n",
        "    python scripts_model/evaluate.py consolidate ${ckpt} --subdir ${subdir} && \\\n",
        "    python scripts_model/evaluate.py old_eval_metrics ${ckpt} --subdir ${subdir} \\\n",
        "      --stage test && \\\n",
        "    python scripts_model/evaluate.py lattice_metrics ${ckpt} --subdir ${subdir} \\\n",
        "      --stage test"
      ],
      "metadata": {
        "id": "Nt5aa6zwfpjw"
      },
      "id": "Nt5aa6zwfpjw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from pprint import pprint\n",
        "path = \"/content/cdvae/hydra_outputs/singlerun/2025-05-27/supercon/eval_recon.pt\"\n",
        "data = torch.load(path, map_location=\"cpu\", weights_only=False)\n",
        "pprint(data, width=120, indent=2)"
      ],
      "metadata": {
        "id": "fHke2Kl8gkqa"
      },
      "id": "fHke2Kl8gkqa",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "jupytext": {
      "cell_metadata_filter": "-all",
      "encoding": "# -*- coding: utf-8 -*-",
      "main_language": "python",
      "notebook_metadata_filter": "-all"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}