{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/crhysc/jarvis-tools-notebooks/blob/master/jarvis-tools-notebooks/flowmm_example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Tutorial**: FlowMM & FlowLLM\n",
        "\n",
        "\n",
        "\n",
        "**Authors**: Charles \"Rhys\" Campbell (crc00042@mix.wvu.edu)"
      ],
      "metadata": {
        "id": "MUMuDXuhXvRE"
      },
      "id": "MUMuDXuhXvRE"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TABLE OF CONTENTS\n",
        "\n",
        "- Background and Central Goal\n",
        "- Installation, Configuration, and Dependencies\n",
        "- Dataset ETL\n",
        "- Training\n",
        "  - Manifolds\n",
        "  - Unconditional Training\n",
        "  - Conditional Training\n",
        "  - FlowLLM\n",
        "- Inference\n",
        "  - De Novo Generation / Unconditional Evalation\n",
        "  - Reconstruction / Conditional Evaluation\n",
        "- Next Steps & References"
      ],
      "metadata": {
        "id": "dMNVDRFTNM12"
      },
      "id": "dMNVDRFTNM12"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (1) BACKGROUND AND CENTRAL GOAL\n"
      ],
      "metadata": {
        "id": "GHy9RobiX6HO"
      },
      "id": "GHy9RobiX6HO"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Background\n",
        "### FlowMM\n",
        "**FlowMM** uses Riemannian flow matching to learn how to transform simple base noise into full periodic crystal structures by jointly modeling fractional atomic coordinates and lattice parameters on the manifold defined by crystal symmetries. It tackles both **Crystal Structure Prediction** (finding the stable arrangement for a known composition) and **De Novo Generation** (proposing entirely new materials), doing so with about three times fewer integration steps than comparable diffusion-based approaches.  \n",
        "\n",
        "### FlowLLM\n",
        "**FlowLLM** builds on FlowMM by swapping out the simple analytic noise prior for samples from a pretrained CrystalLLM (a LLaMA‐style model fine-tuned on crystal data). You generate initial “noisy” structures with the LLM, then use the same Riemannian flow-matching steps to refine those into accurate crystal geometries.\n",
        "\n",
        "\n",
        "# Central Goal\n",
        "Show viewers how to install, train, and use FlowMM and FlowLLM.\n",
        "  \n"
      ],
      "metadata": {
        "id": "-j5wcOCnLGsZ"
      },
      "id": "-j5wcOCnLGsZ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (2) INSTALLATION, CONFIGURATION, AND DEPENDENCIES\n"
      ],
      "metadata": {
        "id": "RxCe6MOhX8wW"
      },
      "id": "RxCe6MOhX8wW"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install Conda"
      ],
      "metadata": {
        "id": "ZFu1FE4zxU_G"
      },
      "id": "ZFu1FE4zxU_G"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "d40fa633",
      "metadata": {
        "id": "d40fa633",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7b5041c-b598-4cf5-ab84-a188eb3eceb2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⏬ Downloading https://github.com/jaimergp/miniforge/releases/download/24.11.2-1_colab/Miniforge3-colab-24.11.2-1_colab-Linux-x86_64.sh...\n",
            "📦 Installing...\n",
            "📌 Adjusting configuration...\n",
            "🩹 Patching environment...\n",
            "⏲ Done in 0:00:15\n",
            "🔁 Restarting kernel...\n",
            "Done\n"
          ]
        }
      ],
      "source": [
        "!pip install -q condacolab\n",
        "import condacolab, os, sys\n",
        "condacolab.install()\n",
        "print(\"Done\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note**: Colab and FlowMM have hard pins for different Python and CUDA versions. To bypass this, the \"!conda run\" command will be used to run most code in this notebook. This bypasses the hard pinned Colab Python version by spinning up a conda subprocess that runs its own Python kernel with the correct version required by FlowMM."
      ],
      "metadata": {
        "id": "e14fotvTP8C7"
      },
      "id": "e14fotvTP8C7"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install FlowMM"
      ],
      "metadata": {
        "id": "RxnmdEiyX-3s"
      },
      "id": "RxnmdEiyX-3s"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "87930ce0",
      "metadata": {
        "id": "87930ce0",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b5c5b01-94b3-475c-c41f-e46f2457e230"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Done\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "%cd /content\n",
        "if not os.path.exists('flowmm'):\n",
        "  !git clone https://github.com/crhysc/flowmm.git\n",
        "print(\"Done\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load FlowMM submodules"
      ],
      "metadata": {
        "id": "zcCZJKnD9QxI"
      },
      "id": "zcCZJKnD9QxI"
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "cd /content/flowmm\n",
        "sed -i 's|git@github.com:bkmi/DiffCSP-official.git|https://github.com/bkmi/DiffCSP-official.git|' .gitmodules\n",
        "sed -i 's|git@github.com:bkmi/cdvae.git|https://github.com/bkmi/cdvae.git|' .gitmodules\n",
        "sed -i 's|git@github.com:crhysc/riemannian-fm.git|https://github.com/crhysc/riemannian-fm.git|' .gitmodules\n",
        "git submodule sync\n",
        "git submodule update --init --recursive\n",
        "echo \"Done\""
      ],
      "metadata": {
        "id": "xQy_gJDV3hGz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "899c03d0-d288-4566-d43f-c2606cf13869"
      },
      "id": "xQy_gJDV3hGz",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synchronizing submodule url for 'remote/DiffCSP-official'\n",
            "Synchronizing submodule url for 'remote/cdvae'\n",
            "Synchronizing submodule url for 'remote/riemannian-fm'\n",
            "Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Switch Colab Runtime to GPU\n",
        "At the top menu by the Colab logo, select **Runtime** -> **Change runtime type** -> **Any GPU**    \n",
        "\n",
        "It is not necessary to run on GPU, but the code will complete faster.\n",
        "\n"
      ],
      "metadata": {
        "id": "RKNI_pfiYKez"
      },
      "id": "RKNI_pfiYKez"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create conda environment for FlowMM\n",
        "Making the conda environment takes 20 minutes\n"
      ],
      "metadata": {
        "id": "I5U2uH3HYGYA"
      },
      "id": "I5U2uH3HYGYA"
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "%cd /content/flowmm\n",
        "!mamba env create -p /usr/local/envs/flowmm_env -f environment.yml\n",
        "!conda run -p /usr/local/envs/flowmm_env --live-stream\\\n",
        "    pip install uv\n",
        "!conda run -p /usr/local/envs/flowmm_env --live-stream\\\n",
        "    uv pip install \"jarvis-tools>=2024.5\" \"pymatgen>=2024.1\" pandas numpy tqdm\n",
        "!conda run -p /usr/local/envs/flowmm_env --live-stream\\\n",
        "    uv pip install -e . \\\n",
        "                   -e remote/riemannian-fm \\\n",
        "                   -e remote/cdvae \\\n",
        "                   -e remote/DiffCSP-official\n",
        "print(\"Done\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A5IcN8lTF_rv",
        "outputId": "424e03c3-9ff1-447a-b118-496840b075db",
        "collapsed": true
      },
      "id": "A5IcN8lTF_rv",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-cupti-11.8.87   | 25.3 MB   | :  86% 0.8597379419120353/1 [00:30<00:00,  6.83s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.0        | 1.46 GB   | :  29% 0.2942930125572212/1 [00:30<00:49, 70.36s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-cupti-11.8.87   | 25.3 MB   | :  96% 0.9648101562362955/1 [00:30<00:00,  4.93s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.9.0         | 28.7 MB   | :  96% 0.9634502797691149/1 [00:30<00:00,  3.46s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.0        | 1.46 GB   | :  30% 0.2957569488050186/1 [00:30<00:50, 71.60s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.0        | 1.46 GB   | :  30% 0.29728362517772167/1 [00:31<00:49, 70.83s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.0        | 1.46 GB   | :  30% 0.2989148684252674/1 [00:31<00:47, 67.91s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.0        | 1.46 GB   | :  30% 0.3006402218601715/1 [00:31<00:46, 67.12s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.0        | 1.46 GB   | :  30% 0.302145984857906/1 [00:31<00:46, 66.99s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.0        | 1.46 GB   | :  30% 0.30400727523010557/1 [00:31<00:44, 63.55s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.0        | 1.46 GB   | :  31% 0.30637048660155/1 [00:31<00:38, 55.86s/it]   \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.0        | 1.46 GB   | :  31% 0.30817949353632823/1 [00:31<00:39, 56.95s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pandoc-3.7.0.2       | 20.7 MB   | :  93% 0.9269947717620785/1 [00:31<00:00,  6.65s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.0        | 1.46 GB   | :  31% 0.31016626415833903/1 [00:31<00:38, 55.60s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.9.0         | 28.7 MB   | : 100% 1.0/1 [00:31<00:00,  3.46s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libclang-11.1.0      | 19.2 MB   | :   0% 0.0008126793856810496/1 [00:31<10:51:57, 39149.82s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.0        | 1.46 GB   | :  31% 0.31215303478034984/1 [00:31<00:37, 54.13s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libclang-11.1.0      | 19.2 MB   | :  18% 0.18285286177823615/1 [00:31<01:40, 122.55s/it]       \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.0        | 1.46 GB   | :  31% 0.31401432515254946/1 [00:32<00:37, 54.04s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libclang-11.1.0      | 19.2 MB   | :  35% 0.3527028533855755/1 [00:32<00:34, 53.03s/it]  \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.0        | 1.46 GB   | :  32% 0.315875615524749/1 [00:32<00:37, 54.95s/it]  \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libclang-11.1.0      | 19.2 MB   | :  50% 0.5046738985079318/1 [00:32<00:15, 31.17s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.0        | 1.46 GB   | :  32% 0.31770553583449584/1 [00:32<00:44, 64.84s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.0        | 1.46 GB   | :  32% 0.31949362939430553/1 [00:32<00:42, 62.29s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pandoc-3.7.0.2       | 20.7 MB   | : 100% 1.0/1 [00:32<00:00,  6.65s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nvrtc-11.8.89   | 19.1 MB   | :  76% 0.7551200625054777/1 [00:32<00:04, 17.20s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.0        | 1.46 GB   | :  32% 0.32130263632908385/1 [00:32<00:40, 60.23s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nvrtc-11.8.89   | 19.1 MB   | :  91% 0.9069604210200927/1 [00:32<00:01, 11.95s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "poppler-21.09.0      | 17.1 MB   | :   0% 0.0009141482859663843/1 [00:32<9:52:07, 35560.09s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.0        | 1.46 GB   | :  32% 0.3232057534512205/1 [00:32<00:39, 58.19s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.0        | 1.46 GB   | :  33% 0.32567353169750757/1 [00:32<00:34, 51.87s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.0        | 1.46 GB   | :  33% 0.3300862538158684/1 [00:32<00:32, 48.38s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.0        | 1.46 GB   | :  33% 0.3321775913127219/1 [00:32<00:32, 48.81s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.0        | 1.46 GB   | :  33% 0.33424801543460686/1 [00:33<00:36, 54.12s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libclang-11.1.0      | 19.2 MB   | : 100% 1.0/1 [00:33<00:00,  8.71s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.0        | 1.46 GB   | :  34% 0.3371131478052961/1 [00:33<00:31, 47.96s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.0        | 1.46 GB   | :  34% 0.3394240757393192/1 [00:33<00:31, 47.00s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "boost-cpp-1.74.0     | 16.3 MB   | :   0% 0.0009572845651068607/1 [00:33<9:39:42, 34815.62s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.0        | 1.46 GB   | :  34% 0.3427179322968634/1 [00:33<00:26, 40.72s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "boost-cpp-1.74.0     | 16.3 MB   | :  14% 0.1416781156358154/1 [00:33<02:22, 165.71s/it]       \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "poppler-21.09.0      | 17.1 MB   | : 100% 1.0/1 [00:33<00:00, 15.67s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "boost-cpp-1.74.0     | 16.3 MB   | :  35% 0.3455797280035767/1 [00:33<00:35, 54.53s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.0        | 1.46 GB   | :  35% 0.3452275372930876/1 [00:33<00:31, 47.91s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "boost-cpp-1.74.0     | 16.3 MB   | :  53% 0.5303356490692008/1 [00:33<00:13, 29.40s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.0        | 1.46 GB   | :  35% 0.347747598976796/1 [00:33<00:29, 45.56s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "boost-cpp-1.74.0     | 16.3 MB   | :  74% 0.7438101070880307/1 [00:33<00:04, 16.83s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.0        | 1.46 GB   | :  35% 0.35004807022333484/1 [00:33<00:29, 45.89s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "scipy-1.13.1         | 15.8 MB   | : 100% 0.9995026414231064/1 [00:33<00:00, 10.04s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.0        | 1.46 GB   | :  35% 0.3523067147199366/1 [00:33<00:29, 46.26s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.0        | 1.46 GB   | :  35% 0.3545235324666013/1 [00:34<00:30, 47.65s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.0        | 1.46 GB   | :  36% 0.3568135470256558/1 [00:34<00:29, 46.59s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.0        | 1.46 GB   | :  36% 0.36101713539433133/1 [00:34<00:34, 54.38s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "boost-cpp-1.74.0     | 16.3 MB   | : 100% 1.0/1 [00:34<00:00, 10.75s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.0        | 1.46 GB   | :  37% 0.36531483395036524/1 [00:34<00:35, 56.22s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.0        | 1.46 GB   | :  40% 0.4024360745195144/1 [00:36<00:29, 49.87s/it]\n",
            "pytorch-2.1.0        | 1.46 GB   | : 100% 1.0/1 [01:07<00:00, 19.33s/it]               \n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  | : 100% 1.0/1 [01:31<00:00,  6.44s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | : 100% 1.0/1 [01:41<00:00,  8.96s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | : 100% 1.0/1 [02:32<00:00,  5.75s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "mkl-2022.1.0         | 199.6 MB  | : 100% 1.0/1 [02:59<00:00, 10.77s/it]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | : 100% 1.0/1 [03:20<00:00,  5.22s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "qt-5.12.9            | 99.5 MB   | : 100% 1.0/1 [03:46<00:00,  4.52s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchtriton-2.1.0    | 90.8 MB   | : 100% 1.0/1 [03:58<00:00,  3.24s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libllvm11-11.1.0     | 28.8 MB   | : 100% 1.0/1 [03:58<00:00,  4.66s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcurand-10.3.10.19 | 44.0 MB   | : 100% 1.0/1 [03:59<00:00,  2.66s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-cupti-11.8.87   | 25.3 MB   | : 100% 1.0/1 [04:09<00:00,  4.93s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pandoc-3.7.0.2       | 20.7 MB   | : 100% 1.0/1 [04:10<00:00,  6.65s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.9.0         | 28.7 MB   | : 100% 1.0/1 [04:11<00:00,  3.46s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libclang-11.1.0      | 19.2 MB   | : 100% 1.0/1 [04:19<00:00,  8.71s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nvrtc-11.8.89   | 19.1 MB   | : 100% 1.0/1 [04:20<00:00, 11.95s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "scipy-1.13.1         | 15.8 MB   | : 100% 1.0/1 [04:21<00:00, 10.04s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "poppler-21.09.0      | 17.1 MB   | : 100% 1.0/1 [04:26<00:00, 15.67s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "boost-cpp-1.74.0     | 16.3 MB   | : 100% 1.0/1 [04:40<00:00, 10.75s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.1.0        | 1.46 GB   | : 100% 1.0/1 [12:13<00:00, 19.33s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \n",
            "                                                                        \u001b[A\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Preparing transaction: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Verifying transaction: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Executing transaction: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Installing pip dependencies: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ Ran pip subprocess with arguments:\n",
            "['/usr/local/envs/flowmm_env/bin/python', '-m', 'pip', 'install', '-U', '-r', '/content/flowmm/condaenv.hbq_si3g.requirements.txt', '--exists-action=b']\n",
            "Pip subprocess output:\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.1.0+cu118.html\n",
            "Obtaining file:///content/flowmm/remote/cdvae (from -r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 34))\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Obtaining file:///content/flowmm/remote/DiffCSP-official (from -r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 35))\n",
            "  Installing build dependencies: started\n",
            "  Installing build dependencies: finished with status 'done'\n",
            "  Checking if build backend supports build_editable: started\n",
            "  Checking if build backend supports build_editable: finished with status 'done'\n",
            "  Getting requirements to build editable: started\n",
            "  Getting requirements to build editable: finished with status 'done'\n",
            "  Installing backend dependencies: started\n",
            "  Installing backend dependencies: finished with status 'done'\n",
            "  Preparing editable metadata (pyproject.toml): started\n",
            "  Preparing editable metadata (pyproject.toml): finished with status 'done'\n",
            "Obtaining file:///content/flowmm/remote/riemannian-fm (from -r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 36))\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Obtaining file:///content/flowmm (from -r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 37))\n",
            "  Installing build dependencies: started\n",
            "  Installing build dependencies: finished with status 'done'\n",
            "  Checking if build backend supports build_editable: started\n",
            "  Checking if build backend supports build_editable: finished with status 'done'\n",
            "  Getting requirements to build editable: started\n",
            "  Getting requirements to build editable: finished with status 'done'\n",
            "  Installing backend dependencies: started\n",
            "  Installing backend dependencies: finished with status 'done'\n",
            "  Preparing editable metadata (pyproject.toml): started\n",
            "  Preparing editable metadata (pyproject.toml): finished with status 'done'\n",
            "Collecting submitit==1.5.1 (from -r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 1))\n",
            "  Downloading submitit-1.5.1-py3-none-any.whl.metadata (8.0 kB)\n",
            "Collecting pre-commit==3.6.1 (from -r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 2))\n",
            "  Downloading pre_commit-3.6.1-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting black==22.6.0 (from -r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 3))\n",
            "  Downloading black-22.6.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (46 kB)\n",
            "Collecting ipykernel==6.29.2 (from -r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 4))\n",
            "  Downloading ipykernel-6.29.2-py3-none-any.whl.metadata (6.0 kB)\n",
            "Collecting torchdiffeq==0.2.3 (from -r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 5))\n",
            "  Downloading torchdiffeq-0.2.3-py3-none-any.whl.metadata (488 bytes)\n",
            "Collecting scikit-learn==1.4.0 (from -r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 6))\n",
            "  Downloading scikit_learn-1.4.0-1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting pytorch-lightning==1.8.5.post0 (from -r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 7))\n",
            "  Downloading pytorch_lightning-1.8.5.post0-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting hydra-core==1.2.0 (from -r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 8))\n",
            "  Downloading hydra_core-1.2.0-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting hydra-submitit-launcher==1.2.0 (from -r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 9))\n",
            "  Downloading hydra_submitit_launcher-1.2.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting hydra_colorlog==1.2.0 (from -r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 10))\n",
            "  Downloading hydra_colorlog-1.2.0-py3-none-any.whl.metadata (949 bytes)\n",
            "Collecting click==8.1.7 (from -r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 11))\n",
            "  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting wandb (from -r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 12))\n",
            "  Downloading wandb-0.20.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Collecting geoopt==0.5.0 (from -r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 13))\n",
            "  Downloading geoopt-0.5.0-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting biopython==1.83 (from -r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 14))\n",
            "  Downloading biopython-1.83-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Collecting pyevtk==1.6.0 (from -r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 15))\n",
            "  Downloading pyevtk-1.6.0-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting ipympl==0.9.3 (from -r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 16))\n",
            "  Downloading ipympl-0.9.3-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting smact==2.2.1 (from -r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 17))\n",
            "  Downloading SMACT-2.2.1-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting pytest==8.0.0 (from -r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 18))\n",
            "  Downloading pytest-8.0.0-py3-none-any.whl.metadata (7.8 kB)\n",
            "Collecting python-dotenv==1.0.1 (from -r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 19))\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting p-tqdm==1.3.3 (from -r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 20))\n",
            "  Downloading p_tqdm-1.3.3.tar.gz (4.3 kB)\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Collecting pyshtools==4.10.4 (from -r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 21))\n",
            "  Downloading pyshtools-4.10.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.8 kB)\n",
            "Collecting pyxtal==0.6.1 (from -r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 22))\n",
            "  Downloading pyxtal-0.6.1.tar.gz (2.7 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.7/2.7 MB 6.1 MB/s eta 0:00:00\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Collecting chemparse==0.1.3 (from -r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 23))\n",
            "  Downloading chemparse-0.1.3-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting einops==0.7.0 (from -r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 24))\n",
            "  Downloading einops-0.7.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting ratelimit==2.2.1 (from -r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 25))\n",
            "  Downloading ratelimit-2.2.1.tar.gz (5.3 kB)\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Collecting matbench-discovery==1.0.0 (from -r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 26))\n",
            "  Downloading matbench_discovery-1.0.0-py2.py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting pymatviz==0.8.1 (from -r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 27))\n",
            "  Downloading pymatviz-0.8.1-py2.py3-none-any.whl.metadata (20 kB)\n",
            "Collecting chgnet==0.3.1 (from -r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 28))\n",
            "  Downloading chgnet-0.3.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Collecting toolz==0.12.1 (from -r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 29))\n",
            "  Downloading toolz-0.12.1-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting POT==0.9.3 (from -r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 30))\n",
            "  Downloading POT-0.9.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (30 kB)\n",
            "Collecting e3nn==0.5.1 (from -r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 31))\n",
            "  Downloading e3nn-0.5.1-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting mp-api==0.39.5 (from -r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 32))\n",
            "  Downloading mp_api-0.39.5-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting matminer (from -r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 33))\n",
            "  Downloading matminer-0.9.3-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting pyg_lib (from -r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 39))\n",
            "  Downloading https://data.pyg.org/whl/torch-2.1.0%2Bcu118/pyg_lib-0.4.0%2Bpt21cu118-cp39-cp39-linux_x86_64.whl (2.6 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.6/2.6 MB 6.6 MB/s eta 0:00:00\n",
            "Collecting cloudpickle>=1.2.1 (from submitit==1.5.1->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 1))\n",
            "  Downloading cloudpickle-3.1.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: typing_extensions>=3.7.4.2 in /usr/local/envs/flowmm_env/lib/python3.9/site-packages (from submitit==1.5.1->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 1)) (4.14.0)\n",
            "Collecting cfgv>=2.0.0 (from pre-commit==3.6.1->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 2))\n",
            "  Downloading cfgv-3.4.0-py2.py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting identify>=1.0.0 (from pre-commit==3.6.1->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 2))\n",
            "  Downloading identify-2.6.12-py2.py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting nodeenv>=0.11.1 (from pre-commit==3.6.1->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 2))\n",
            "  Downloading nodeenv-1.9.1-py2.py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/envs/flowmm_env/lib/python3.9/site-packages (from pre-commit==3.6.1->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 2)) (6.0.2)\n",
            "Collecting virtualenv>=20.10.0 (from pre-commit==3.6.1->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 2))\n",
            "  Downloading virtualenv-20.31.2-py3-none-any.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: platformdirs>=2 in /usr/local/envs/flowmm_env/lib/python3.9/site-packages (from black==22.6.0->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 3)) (4.3.8)\n",
            "Collecting pathspec>=0.9.0 (from black==22.6.0->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 3))\n",
            "  Using cached pathspec-0.12.1-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting mypy-extensions>=0.4.3 (from black==22.6.0->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 3))\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/envs/flowmm_env/lib/python3.9/site-packages (from black==22.6.0->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 3)) (2.2.1)\n",
            "Requirement already satisfied: comm>=0.1.1 in /usr/local/envs/flowmm_env/lib/python3.9/site-packages (from ipykernel==6.29.2->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 4)) (0.2.2)\n",
            "Requirement already satisfied: debugpy>=1.6.5 in /usr/local/envs/flowmm_env/lib/python3.9/site-packages (from ipykernel==6.29.2->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 4)) (1.8.14)\n",
            "Requirement already satisfied: ipython>=7.23.1 in /usr/local/envs/flowmm_env/lib/python3.9/site-packages (from ipykernel==6.29.2->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 4)) (8.18.1)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/envs/flowmm_env/lib/python3.9/site-packages (from ipykernel==6.29.2->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 4)) (8.6.3)\n",
            "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/envs/flowmm_env/lib/python3.9/site-packages (from ipykernel==6.29.2->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 4)) (5.8.1)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/envs/flowmm_env/lib/python3.9/site-packages (from ipykernel==6.29.2->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 4)) (0.1.7)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/envs/flowmm_env/lib/python3.9/site-packages (from ipykernel==6.29.2->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 4)) (1.6.0)\n",
            "Requirement already satisfied: packaging in /usr/local/envs/flowmm_env/lib/python3.9/site-packages (from ipykernel==6.29.2->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 4)) (25.0)\n",
            "Requirement already satisfied: psutil in /usr/local/envs/flowmm_env/lib/python3.9/site-packages (from ipykernel==6.29.2->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 4)) (7.0.0)\n",
            "Requirement already satisfied: pyzmq>=24 in /usr/local/envs/flowmm_env/lib/python3.9/site-packages (from ipykernel==6.29.2->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 4)) (26.2.0)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/envs/flowmm_env/lib/python3.9/site-packages (from ipykernel==6.29.2->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 4)) (6.5.1)\n",
            "Requirement already satisfied: traitlets>=5.4.0 in /usr/local/envs/flowmm_env/lib/python3.9/site-packages (from ipykernel==6.29.2->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 4)) (5.14.3)\n",
            "Requirement already satisfied: torch>=1.3.0 in /usr/local/envs/flowmm_env/lib/python3.9/site-packages (from torchdiffeq==0.2.3->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 5)) (2.1.0)\n",
            "Requirement already satisfied: scipy>=1.4.0 in /usr/local/envs/flowmm_env/lib/python3.9/site-packages (from torchdiffeq==0.2.3->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 5)) (1.13.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.19.5 in /usr/local/envs/flowmm_env/lib/python3.9/site-packages (from scikit-learn==1.4.0->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 6)) (1.26.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/envs/flowmm_env/lib/python3.9/site-packages (from scikit-learn==1.4.0->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 6)) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/envs/flowmm_env/lib/python3.9/site-packages (from scikit-learn==1.4.0->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 6)) (3.6.0)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/envs/flowmm_env/lib/python3.9/site-packages (from pytorch-lightning==1.8.5.post0->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 7)) (4.66.2)\n",
            "Collecting fsspec>2021.06.0 (from fsspec[http]>2021.06.0->pytorch-lightning==1.8.5.post0->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 7))\n",
            "  Downloading fsspec-2025.5.1-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting tensorboardX>=2.2 (from pytorch-lightning==1.8.5.post0->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 7))\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: torchmetrics>=0.7.0 in /usr/local/envs/flowmm_env/lib/python3.9/site-packages (from pytorch-lightning==1.8.5.post0->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 7)) (1.2.1)\n",
            "Requirement already satisfied: lightning-utilities!=0.4.0,>=0.3.0 in /usr/local/envs/flowmm_env/lib/python3.9/site-packages (from pytorch-lightning==1.8.5.post0->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 7)) (0.14.3)\n",
            "Collecting omegaconf~=2.2 (from hydra-core==1.2.0->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 8))\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from hydra-core==1.2.0->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 8))\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Collecting colorlog (from hydra_colorlog==1.2.0->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 10))\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting ipython-genutils (from ipympl==0.9.3->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 16))\n",
            "  Downloading ipython_genutils-0.2.0-py2.py3-none-any.whl.metadata (755 bytes)\n",
            "Requirement already satisfied: pillow in /usr/local/envs/flowmm_env/lib/python3.9/site-packages (from ipympl==0.9.3->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 16)) (11.0.0)\n",
            "Requirement already satisfied: ipywidgets<9,>=7.6.0 in /usr/local/envs/flowmm_env/lib/python3.9/site-packages (from ipympl==0.9.3->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 16)) (8.1.7)\n",
            "Requirement already satisfied: matplotlib<4,>=3.4.0 in /usr/local/envs/flowmm_env/lib/python3.9/site-packages (from ipympl==0.9.3->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 16)) (3.9.1)\n",
            "Requirement already satisfied: spglib in /usr/local/envs/flowmm_env/lib/python3.9/site-packages (from smact==2.2.1->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 17)) (2.6.0)\n",
            "Requirement already satisfied: pymatgen in /usr/local/envs/flowmm_env/lib/python3.9/site-packages (from smact==2.2.1->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 17)) (2023.10.11)\n",
            "Requirement already satisfied: ase in /usr/local/envs/flowmm_env/lib/python3.9/site-packages (from smact==2.2.1->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 17)) (3.22.1)\n",
            "Requirement already satisfied: pandas in /usr/local/envs/flowmm_env/lib/python3.9/site-packages (from smact==2.2.1->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 17)) (2.2.0)\n",
            "Collecting pathos (from smact==2.2.1->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 17))\n",
            "  Downloading pathos-0.3.4-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting iniconfig (from pytest==8.0.0->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 18))\n",
            "  Downloading iniconfig-2.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting pluggy<2.0,>=1.3.0 (from pytest==8.0.0->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 18))\n",
            "  Using cached pluggy-1.6.0-py3-none-any.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/envs/flowmm_env/lib/python3.9/site-packages (from pytest==8.0.0->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 18)) (1.3.0)\n",
            "Requirement already satisfied: six in /usr/local/envs/flowmm_env/lib/python3.9/site-packages (from p-tqdm==1.3.3->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 20)) (1.17.0)\n",
            "Collecting astropy>=4.0 (from pyshtools==4.10.4->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 21))\n",
            "  Downloading astropy-6.0.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.8 kB)\n",
            "Collecting xarray (from pyshtools==4.10.4->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 21))\n",
            "  Downloading xarray-2024.7.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: requests in /usr/local/envs/flowmm_env/lib/python3.9/site-packages (from pyshtools==4.10.4->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 21)) (2.32.4)\n",
            "Collecting pooch>=1.1 (from pyshtools==4.10.4->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 21))\n",
            "  Downloading pooch-1.8.2-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: networkx>=2.3 in /usr/local/envs/flowmm_env/lib/python3.9/site-packages (from pyxtal==0.6.1->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 22)) (3.2.1)\n",
            "Requirement already satisfied: importlib_metadata>=1.4 in /usr/local/envs/flowmm_env/lib/python3.9/site-packages (from pyxtal==0.6.1->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 22)) (8.7.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/envs/flowmm_env/lib/python3.9/site-packages (from matbench-discovery==1.0.0->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 26)) (3.1.6)\n",
            "Requirement already satisfied: plotly in /usr/local/envs/flowmm_env/lib/python3.9/site-packages (from matbench-discovery==1.0.0->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 26)) (6.1.2)\n",
            "Collecting cython>=0.29.26 (from chgnet==0.3.1->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 28))\n",
            "  Downloading cython-3.1.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.9 kB)\n",
            "Collecting nvidia-ml-py3>=7.352.0 (from chgnet==0.3.1->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 28))\n",
            "  Downloading nvidia-ml-py3-7.352.0.tar.gz (19 kB)\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Requirement already satisfied: sympy in /usr/local/envs/flowmm_env/lib/python3.9/site-packages (from e3nn==0.5.1->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 31)) (1.14.0)\n",
            "Collecting opt-einsum-fx>=0.1.4 (from e3nn==0.5.1->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 31))\n",
            "  Downloading opt_einsum_fx-0.1.4-py3-none-any.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/envs/flowmm_env/lib/python3.9/site-packages (from mp-api==0.39.5->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 32)) (80.9.0)\n",
            "Collecting msgpack (from mp-api==0.39.5->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 32))\n",
            "  Downloading msgpack-1.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.4 kB)\n",
            "Collecting maggma>=0.57.1 (from mp-api==0.39.5->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 32))\n",
            "  Downloading maggma-0.71.5-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: monty>=2023.9.25 in /usr/local/envs/flowmm_env/lib/python3.9/site-packages (from mp-api==0.39.5->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 32)) (2024.12.10)\n",
            "Collecting emmet-core>=0.74.2 (from mp-api==0.39.5->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 32))\n",
            "  Downloading emmet_core-0.84.5-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/envs/flowmm_env/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel==6.29.2->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 4)) (5.2.1)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/envs/flowmm_env/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel==6.29.2->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 4)) (0.19.2)\n",
            "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /usr/local/envs/flowmm_env/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel==6.29.2->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 4)) (3.0.51)\n",
            "Requirement already satisfied: pygments>=2.4.0 in /usr/local/envs/flowmm_env/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel==6.29.2->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 4)) (2.19.1)\n",
            "Requirement already satisfied: stack-data in /usr/local/envs/flowmm_env/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel==6.29.2->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 4)) (0.6.3)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/envs/flowmm_env/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel==6.29.2->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 4)) (4.9.0)\n",
            "Requirement already satisfied: widgetsnbextension~=4.0.14 in /usr/local/envs/flowmm_env/lib/python3.9/site-packages (from ipywidgets<9,>=7.6.0->ipympl==0.9.3->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 16)) (4.0.14)\n",
            "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in /usr/local/envs/flowmm_env/lib/python3.9/site-packages (from ipywidgets<9,>=7.6.0->ipympl==0.9.3->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 16)) (3.0.15)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/envs/flowmm_env/lib/python3.9/site-packages (from matplotlib<4,>=3.4.0->ipympl==0.9.3->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 16)) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/envs/flowmm_env/lib/python3.9/site-packages (from matplotlib<4,>=3.4.0->ipympl==0.9.3->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 16)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/envs/flowmm_env/lib/python3.9/site-packages (from matplotlib<4,>=3.4.0->ipympl==0.9.3->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 16)) (4.58.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/envs/flowmm_env/lib/python3.9/site-packages (from matplotlib<4,>=3.4.0->ipympl==0.9.3->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 16)) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/envs/flowmm_env/lib/python3.9/site-packages (from matplotlib<4,>=3.4.0->ipympl==0.9.3->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 16)) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/envs/flowmm_env/lib/python3.9/site-packages (from matplotlib<4,>=3.4.0->ipympl==0.9.3->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 16)) (2.9.0.post0)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/envs/flowmm_env/lib/python3.9/site-packages (from matplotlib<4,>=3.4.0->ipympl==0.9.3->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 16)) (6.5.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/envs/flowmm_env/lib/python3.9/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel==6.29.2->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 4)) (0.2.13)\n",
            "Collecting eval-type-backport (from wandb->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 12))\n",
            "  Downloading eval_type_backport-0.2.2-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting gitpython!=3.1.29,>=1.0.0 (from wandb->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 12))\n",
            "  Downloading GitPython-3.1.44-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting protobuf!=4.21.0,!=5.28.0,<7,>=3.15.0 (from wandb->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 12))\n",
            "  Downloading protobuf-6.31.1-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
            "Collecting pydantic<3 (from wandb->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 12))\n",
            "  Downloading pydantic-2.11.5-py3-none-any.whl.metadata (67 kB)\n",
            "Collecting sentry-sdk>=2.0.0 (from wandb->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 12))\n",
            "  Downloading sentry_sdk-2.29.1-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Collecting setproctitle (from wandb->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 12))\n",
            "  Downloading setproctitle-1.3.6-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Collecting annotated-types>=0.6.0 (from pydantic<3->wandb->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 12))\n",
            "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting pydantic-core==2.33.2 (from pydantic<3->wandb->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 12))\n",
            "  Downloading pydantic_core-2.33.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting typing-inspection>=0.4.0 (from pydantic<3->wandb->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 12))\n",
            "  Downloading typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/envs/flowmm_env/lib/python3.9/site-packages (from requests->pyshtools==4.10.4->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 21)) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/envs/flowmm_env/lib/python3.9/site-packages (from requests->pyshtools==4.10.4->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 21)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/envs/flowmm_env/lib/python3.9/site-packages (from requests->pyshtools==4.10.4->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 21)) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/envs/flowmm_env/lib/python3.9/site-packages (from requests->pyshtools==4.10.4->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 21)) (2025.4.26)\n",
            "Collecting pymongo~=4.5 (from matminer->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 33))\n",
            "  Downloading pymongo-4.13.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/envs/flowmm_env/lib/python3.9/site-packages (from pandas->smact==2.2.1->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 17)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/envs/flowmm_env/lib/python3.9/site-packages (from pandas->smact==2.2.1->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 17)) (2025.2)\n",
            "Collecting dnspython<3.0.0,>=1.16.0 (from pymongo~=4.5->matminer->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 33))\n",
            "  Downloading dnspython-2.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/envs/flowmm_env/lib/python3.9/site-packages (from sympy->e3nn==0.5.1->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 31)) (1.3.0)\n",
            "Collecting pyerfa>=2.0.1.1 (from astropy>=4.0->pyshtools==4.10.4->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 21))\n",
            "  Downloading pyerfa-2.0.1.5-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.7 kB)\n",
            "Collecting astropy-iers-data>=0.2024.2.26.0.28.55 (from astropy>=4.0->pyshtools==4.10.4->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 21))\n",
            "  Downloading astropy_iers_data-0.2025.6.9.14.9.37-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting pymatgen (from smact==2.2.1->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 17))\n",
            "  Downloading pymatgen-2024.8.9-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Collecting pydantic-settings>=2.0 (from emmet-core>=0.74.2->mp-api==0.39.5->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 32))\n",
            "  Downloading pydantic_settings-2.9.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: pybtex~=0.24 in /usr/local/envs/flowmm_env/lib/python3.9/site-packages (from emmet-core>=0.74.2->mp-api==0.39.5->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 32)) (0.24.0)\n",
            "Requirement already satisfied: latexcodec>=1.0.4 in /usr/local/envs/flowmm_env/lib/python3.9/site-packages (from pybtex~=0.24->emmet-core>=0.74.2->mp-api==0.39.5->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 32)) (2.0.1)\n",
            "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]>2021.06.0->pytorch-lightning==1.8.5.post0->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 7))\n",
            "  Downloading aiohttp-3.12.12-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.6 kB)\n",
            "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.8.5.post0->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 7))\n",
            "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting aiosignal>=1.1.2 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.8.5.post0->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 7))\n",
            "  Downloading aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting async-timeout<6.0,>=4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.8.5.post0->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 7))\n",
            "  Downloading async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/envs/flowmm_env/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.8.5.post0->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 7)) (25.3.0)\n",
            "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.8.5.post0->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 7))\n",
            "  Downloading frozenlist-1.7.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.8.5.post0->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 7))\n",
            "  Downloading multidict-6.4.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
            "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.8.5.post0->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 7))\n",
            "  Downloading propcache-0.3.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.8.5.post0->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 7))\n",
            "  Downloading yarl-1.20.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (73 kB)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 12))\n",
            "  Downloading gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 12))\n",
            "  Downloading smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/envs/flowmm_env/lib/python3.9/site-packages (from importlib_metadata>=1.4->pyxtal==0.6.1->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 22)) (3.23.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/envs/flowmm_env/lib/python3.9/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel==6.29.2->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 4)) (0.8.4)\n",
            "Requirement already satisfied: ruamel.yaml>=0.17 in /usr/local/envs/flowmm_env/lib/python3.9/site-packages (from maggma>=0.57.1->mp-api==0.39.5->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 32)) (0.18.14)\n",
            "Collecting pymongo~=4.5 (from matminer->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 33))\n",
            "  Downloading pymongo-4.10.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
            "Collecting mongomock>=3.10.0 (from maggma>=0.57.1->mp-api==0.39.5->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 32))\n",
            "  Downloading mongomock-4.3.0-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Collecting pydash>=4.1.0 (from maggma>=0.57.1->mp-api==0.39.5->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 32))\n",
            "  Downloading pydash-8.0.5-py3-none-any.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: jsonschema>=3.1.1 in /usr/local/envs/flowmm_env/lib/python3.9/site-packages (from maggma>=0.57.1->mp-api==0.39.5->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 32)) (4.24.0)\n",
            "Collecting jsonlines>=4.0.0 (from maggma>=0.57.1->mp-api==0.39.5->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 32))\n",
            "  Downloading jsonlines-4.0.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting aioitertools>=0.5.1 (from maggma>=0.57.1->mp-api==0.39.5->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 32))\n",
            "  Downloading aioitertools-0.12.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting sshtunnel>=0.1.5 (from maggma>=0.57.1->mp-api==0.39.5->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 32))\n",
            "  Downloading sshtunnel-0.4.0-py2.py3-none-any.whl.metadata (19 kB)\n",
            "Collecting orjson>=3.9.0 (from maggma>=0.57.1->mp-api==0.39.5->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 32))\n",
            "  Downloading orjson-3.10.18-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (41 kB)\n",
            "Collecting boto3>=1.20.41 (from maggma>=0.57.1->mp-api==0.39.5->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 32))\n",
            "  Downloading boto3-1.38.33-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting botocore<1.39.0,>=1.38.33 (from boto3>=1.20.41->maggma>=0.57.1->mp-api==0.39.5->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 32))\n",
            "  Downloading botocore-1.38.33-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3>=1.20.41->maggma>=0.57.1->mp-api==0.39.5->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 32))\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.14.0,>=0.13.0 (from boto3>=1.20.41->maggma>=0.57.1->mp-api==0.39.5->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 32))\n",
            "  Downloading s3transfer-0.13.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests->pyshtools==4.10.4->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 21))\n",
            "  Downloading urllib3-1.26.20-py2.py3-none-any.whl.metadata (50 kB)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/envs/flowmm_env/lib/python3.9/site-packages (from jsonschema>=3.1.1->maggma>=0.57.1->mp-api==0.39.5->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 32)) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/envs/flowmm_env/lib/python3.9/site-packages (from jsonschema>=3.1.1->maggma>=0.57.1->mp-api==0.39.5->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 32)) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/envs/flowmm_env/lib/python3.9/site-packages (from jsonschema>=3.1.1->maggma>=0.57.1->mp-api==0.39.5->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 32)) (0.25.1)\n",
            "Collecting sentinels (from mongomock>=3.10.0->maggma>=0.57.1->mp-api==0.39.5->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 32))\n",
            "  Downloading sentinels-1.0.0.tar.gz (4.1 kB)\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Collecting opt-einsum (from opt-einsum-fx>=0.1.4->e3nn==0.5.1->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 31))\n",
            "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: tabulate>=0.9.0 in /usr/local/envs/flowmm_env/lib/python3.9/site-packages (from pandas[output_formatting]>=2.0.0->matbench-discovery==1.0.0->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 26)) (0.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/envs/flowmm_env/lib/python3.9/site-packages (from jinja2->matbench-discovery==1.0.0->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 26)) (3.0.2)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/envs/flowmm_env/lib/python3.9/site-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel==6.29.2->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 4)) (0.7.0)\n",
            "Requirement already satisfied: palettable>=3.3.3 in /usr/local/envs/flowmm_env/lib/python3.9/site-packages (from pymatgen->smact==2.2.1->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 17)) (3.3.3)\n",
            "Requirement already satisfied: uncertainties>=3.1.4 in /usr/local/envs/flowmm_env/lib/python3.9/site-packages (from pymatgen->smact==2.2.1->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 17)) (3.2.3)\n",
            "Requirement already satisfied: narwhals>=1.15.1 in /usr/local/envs/flowmm_env/lib/python3.9/site-packages (from plotly->matbench-discovery==1.0.0->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 26)) (1.42.0)\n",
            "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in /usr/local/envs/flowmm_env/lib/python3.9/site-packages (from ruamel.yaml>=0.17->maggma>=0.57.1->mp-api==0.39.5->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 32)) (0.2.8)\n",
            "Collecting paramiko>=2.7.2 (from sshtunnel>=0.1.5->maggma>=0.57.1->mp-api==0.39.5->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 32))\n",
            "  Downloading paramiko-3.5.1-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting bcrypt>=3.2 (from paramiko>=2.7.2->sshtunnel>=0.1.5->maggma>=0.57.1->mp-api==0.39.5->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 32))\n",
            "  Downloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\n",
            "Collecting cryptography>=3.3 (from paramiko>=2.7.2->sshtunnel>=0.1.5->maggma>=0.57.1->mp-api==0.39.5->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 32))\n",
            "  Downloading cryptography-43.0.3-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (5.4 kB)\n",
            "Collecting pynacl>=1.5 (from paramiko>=2.7.2->sshtunnel>=0.1.5->maggma>=0.57.1->mp-api==0.39.5->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 32))\n",
            "  Downloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl.metadata (8.6 kB)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/envs/flowmm_env/lib/python3.9/site-packages (from cryptography>=3.3->paramiko>=2.7.2->sshtunnel>=0.1.5->maggma>=0.57.1->mp-api==0.39.5->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 32)) (1.14.6)\n",
            "Requirement already satisfied: pycparser in /usr/local/envs/flowmm_env/lib/python3.9/site-packages (from cffi>=1.12->cryptography>=3.3->paramiko>=2.7.2->sshtunnel>=0.1.5->maggma>=0.57.1->mp-api==0.39.5->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 32)) (2.22)\n",
            "Requirement already satisfied: filelock in /usr/local/envs/flowmm_env/lib/python3.9/site-packages (from torch>=1.3.0->torchdiffeq==0.2.3->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 5)) (3.18.0)\n",
            "Collecting distlib<1,>=0.3.7 (from virtualenv>=20.10.0->pre-commit==3.6.1->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 2))\n",
            "  Downloading distlib-0.3.9-py2.py3-none-any.whl.metadata (5.2 kB)\n",
            "Collecting ppft>=1.7.7 (from pathos->smact==2.2.1->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 17))\n",
            "  Downloading ppft-1.7.7-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting dill>=0.4.0 (from pathos->smact==2.2.1->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 17))\n",
            "  Downloading dill-0.4.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting pox>=0.3.6 (from pathos->smact==2.2.1->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 17))\n",
            "  Downloading pox-0.3.6-py3-none-any.whl.metadata (8.0 kB)\n",
            "Collecting multiprocess>=0.70.18 (from pathos->smact==2.2.1->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 17))\n",
            "  Downloading multiprocess-0.70.18-py39-none-any.whl.metadata (7.5 kB)\n",
            "Collecting kaleido (from pymatviz[export-figs]->matbench-discovery==1.0.0->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 26))\n",
            "  Downloading kaleido-0.2.1-py2.py3-none-manylinux1_x86_64.whl.metadata (15 kB)\n",
            "Requirement already satisfied: executing>=1.2.0 in /usr/local/envs/flowmm_env/lib/python3.9/site-packages (from stack-data->ipython>=7.23.1->ipykernel==6.29.2->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 4)) (2.2.0)\n",
            "Requirement already satisfied: asttokens>=2.1.0 in /usr/local/envs/flowmm_env/lib/python3.9/site-packages (from stack-data->ipython>=7.23.1->ipykernel==6.29.2->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 4)) (3.0.0)\n",
            "Requirement already satisfied: pure_eval in /usr/local/envs/flowmm_env/lib/python3.9/site-packages (from stack-data->ipython>=7.23.1->ipykernel==6.29.2->-r /content/flowmm/condaenv.hbq_si3g.requirements.txt (line 4)) (0.2.3)\n",
            "Downloading submitit-1.5.1-py3-none-any.whl (74 kB)\n",
            "Downloading pre_commit-3.6.1-py2.py3-none-any.whl (204 kB)\n",
            "Downloading black-22.6.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.5 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.5/1.5 MB 4.6 MB/s eta 0:00:00\n",
            "Downloading ipykernel-6.29.2-py3-none-any.whl (116 kB)\n",
            "Downloading torchdiffeq-0.2.3-py3-none-any.whl (31 kB)\n",
            "Downloading scikit_learn-1.4.0-1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 12.1/12.1 MB 102.5 MB/s eta 0:00:00\n",
            "Downloading pytorch_lightning-1.8.5.post0-py3-none-any.whl (800 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 800.5/800.5 kB 15.8 MB/s eta 0:00:00\n",
            "Downloading hydra_core-1.2.0-py3-none-any.whl (151 kB)\n",
            "Downloading hydra_submitit_launcher-1.2.0-py3-none-any.whl (5.2 kB)\n",
            "Downloading hydra_colorlog-1.2.0-py3-none-any.whl (3.6 kB)\n",
            "Downloading click-8.1.7-py3-none-any.whl (97 kB)\n",
            "Downloading geoopt-0.5.0-py3-none-any.whl (90 kB)\n",
            "Downloading biopython-1.83-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.1/3.1 MB 5.6 MB/s eta 0:00:00\n",
            "Downloading pyevtk-1.6.0-py3-none-any.whl (20 kB)\n",
            "Downloading ipympl-0.9.3-py2.py3-none-any.whl (511 kB)\n",
            "Downloading SMACT-2.2.1-py3-none-any.whl (113 kB)\n",
            "Downloading pytest-8.0.0-py3-none-any.whl (334 kB)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading pyshtools-4.10.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.9 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 12.9/12.9 MB 3.6 MB/s eta 0:00:00\n",
            "Downloading chemparse-0.1.3-py3-none-any.whl (3.9 kB)\n",
            "Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
            "Downloading matbench_discovery-1.0.0-py2.py3-none-any.whl (32 kB)\n",
            "Downloading pymatviz-0.8.1-py2.py3-none-any.whl (70 kB)\n",
            "Downloading chgnet-0.3.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.2 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 9.2/9.2 MB 2.9 MB/s eta 0:00:00\n",
            "Downloading toolz-0.12.1-py3-none-any.whl (56 kB)\n",
            "Downloading POT-0.9.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (822 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 822.0/822.0 kB 26.0 MB/s eta 0:00:00\n",
            "Downloading e3nn-0.5.1-py3-none-any.whl (118 kB)\n",
            "Downloading mp_api-0.39.5-py3-none-any.whl (96 kB)\n",
            "Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "Using cached pluggy-1.6.0-py3-none-any.whl (20 kB)\n",
            "Downloading wandb-0.20.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23.2 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 23.2/23.2 MB 135.8 MB/s eta 0:00:00\n",
            "Downloading protobuf-6.31.1-cp39-abi3-manylinux2014_x86_64.whl (321 kB)\n",
            "Downloading pydantic-2.11.5-py3-none-any.whl (444 kB)\n",
            "Downloading pydantic_core-2.33.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.0/2.0 MB 68.6 MB/s eta 0:00:00\n",
            "Downloading matminer-0.9.3-py3-none-any.whl (5.5 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.5/5.5 MB 91.3 MB/s eta 0:00:00\n",
            "Downloading dnspython-2.7.0-py3-none-any.whl (313 kB)\n",
            "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
            "Downloading astropy-6.0.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.1 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 10.1/10.1 MB 76.0 MB/s eta 0:00:00\n",
            "Downloading astropy_iers_data-0.2025.6.9.14.9.37-py3-none-any.whl (2.0 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.0/2.0 MB 64.7 MB/s eta 0:00:00\n",
            "Downloading cfgv-3.4.0-py2.py3-none-any.whl (7.2 kB)\n",
            "Downloading cloudpickle-3.1.1-py3-none-any.whl (20 kB)\n",
            "Downloading cython-3.1.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.3/3.3 MB 74.0 MB/s eta 0:00:00\n",
            "Downloading emmet_core-0.84.5-py3-none-any.whl (212 kB)\n",
            "Downloading fsspec-2025.5.1-py3-none-any.whl (199 kB)\n",
            "Downloading aiohttp-3.12.12-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.6/1.6 MB 52.2 MB/s eta 0:00:00\n",
            "Downloading async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
            "Downloading multidict-6.4.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (216 kB)\n",
            "Downloading yarl-1.20.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (327 kB)\n",
            "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
            "Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
            "Downloading frozenlist-1.7.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (225 kB)\n",
            "Downloading GitPython-3.1.44-py3-none-any.whl (207 kB)\n",
            "Downloading gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
            "Downloading smmap-5.0.2-py3-none-any.whl (24 kB)\n",
            "Downloading identify-2.6.12-py2.py3-none-any.whl (99 kB)\n",
            "Downloading maggma-0.71.5-py3-none-any.whl (122 kB)\n",
            "Downloading pymongo-4.10.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 3.6 MB/s eta 0:00:00\n",
            "Downloading aioitertools-0.12.0-py3-none-any.whl (24 kB)\n",
            "Downloading boto3-1.38.33-py3-none-any.whl (139 kB)\n",
            "Downloading botocore-1.38.33-py3-none-any.whl (13.6 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 13.6/13.6 MB 38.6 MB/s eta 0:00:00\n",
            "Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading s3transfer-0.13.0-py3-none-any.whl (85 kB)\n",
            "Downloading urllib3-1.26.20-py2.py3-none-any.whl (144 kB)\n",
            "Downloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\n",
            "Downloading mongomock-4.3.0-py2.py3-none-any.whl (64 kB)\n",
            "Downloading msgpack-1.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (377 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Downloading nodeenv-1.9.1-py2.py3-none-any.whl (22 kB)\n",
            "Downloading opt_einsum_fx-0.1.4-py3-none-any.whl (13 kB)\n",
            "Downloading orjson-3.10.18-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (132 kB)\n",
            "Using cached pathspec-0.12.1-py3-none-any.whl (31 kB)\n",
            "Downloading pooch-1.8.2-py3-none-any.whl (64 kB)\n",
            "Downloading propcache-0.3.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (200 kB)\n",
            "Downloading pydantic_settings-2.9.1-py3-none-any.whl (44 kB)\n",
            "Downloading pydash-8.0.5-py3-none-any.whl (102 kB)\n",
            "Downloading pyerfa-2.0.1.5-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (738 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 738.7/738.7 kB 26.2 MB/s eta 0:00:00\n",
            "Downloading pymatgen-2024.8.9-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.9/4.9 MB 12.7 MB/s eta 0:00:00\n",
            "Downloading sentry_sdk-2.29.1-py2.py3-none-any.whl (341 kB)\n",
            "Downloading sshtunnel-0.4.0-py2.py3-none-any.whl (24 kB)\n",
            "Downloading paramiko-3.5.1-py3-none-any.whl (227 kB)\n",
            "Downloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl (284 kB)\n",
            "Downloading cryptography-43.0.3-cp39-abi3-manylinux_2_28_x86_64.whl (4.0 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.0/4.0 MB 108.1 MB/s eta 0:00:00\n",
            "Downloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (856 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 856.7/856.7 kB 30.2 MB/s eta 0:00:00\n",
            "Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "Downloading typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
            "Downloading virtualenv-20.31.2-py3-none-any.whl (6.1 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.1/6.1 MB 92.3 MB/s eta 0:00:00\n",
            "Downloading distlib-0.3.9-py2.py3-none-any.whl (468 kB)\n",
            "Downloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Downloading eval_type_backport-0.2.2-py3-none-any.whl (5.8 kB)\n",
            "Downloading iniconfig-2.1.0-py3-none-any.whl (6.0 kB)\n",
            "Downloading ipython_genutils-0.2.0-py2.py3-none-any.whl (26 kB)\n",
            "Downloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
            "Downloading pathos-0.3.4-py3-none-any.whl (82 kB)\n",
            "Downloading dill-0.4.0-py3-none-any.whl (119 kB)\n",
            "Downloading multiprocess-0.70.18-py39-none-any.whl (133 kB)\n",
            "Downloading pox-0.3.6-py3-none-any.whl (29 kB)\n",
            "Downloading ppft-1.7.7-py3-none-any.whl (56 kB)\n",
            "Downloading kaleido-0.2.1-py2.py3-none-manylinux1_x86_64.whl (79.9 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 79.9/79.9 MB 57.1 MB/s eta 0:00:00\n",
            "Downloading setproctitle-1.3.6-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Downloading xarray-2024.7.0-py3-none-any.whl (1.2 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 42.0 MB/s eta 0:00:00\n",
            "Building wheels for collected packages: diffcsp, flowmm, p-tqdm, pyxtal, ratelimit, antlr4-python3-runtime, nvidia-ml-py3, sentinels\n",
            "  Building editable for diffcsp (pyproject.toml): started\n",
            "  Building editable for diffcsp (pyproject.toml): finished with status 'done'\n",
            "  Created wheel for diffcsp: filename=diffcsp-0.1.dev28+g199539f-py3-none-any.whl size=3344 sha256=c67dbd3900dfab0a8f899826f928ef864d6d9ffb330b794aa4a0f2a6209a000d\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-qgq7w6zy/wheels/bc/bb/44/e70e144903c0a166e4bd4aa69e5d3172c89492b902ec25372c\n",
            "  Building editable for flowmm (pyproject.toml): started\n",
            "  Building editable for flowmm (pyproject.toml): finished with status 'done'\n",
            "  Created wheel for flowmm: filename=flowmm-0.1.dev10+g6a96aec.d20250610-py3-none-any.whl size=11577 sha256=6a4afe266253708c0990b4c982680491bb89105228c8e65dd7225ec80b7c02b0\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-qgq7w6zy/wheels/6f/e3/df/293ccf511ed829f142e4ed0e8720002f360c162f43a4fde517\n",
            "  Building wheel for p-tqdm (setup.py): started\n",
            "  Building wheel for p-tqdm (setup.py): finished with status 'done'\n",
            "  Created wheel for p-tqdm: filename=p_tqdm-1.3.3-py3-none-any.whl size=4034 sha256=67fa3f7f3b11a13386e0bdc034019b49c7d0a8e7427e66bc81a46535ea9b77c6\n",
            "  Stored in directory: /root/.cache/pip/wheels/cb/2b/fc/e7a280334c4a646f68179040f362e8ed8e451cc4b2ad152fb8\n",
            "  Building wheel for pyxtal (setup.py): started\n",
            "  Building wheel for pyxtal (setup.py): finished with status 'done'\n",
            "  Created wheel for pyxtal: filename=pyxtal-0.6.1-py3-none-any.whl size=2805966 sha256=db29b8505455b78e048c52d40b24aabc3c80eb4ec1eaad0f10cb99c349bc9cb8\n",
            "  Stored in directory: /root/.cache/pip/wheels/1d/d4/1f/28bce55fb72ccf74c58c8d16fbd6aa87a41259dc237528a581\n",
            "  Building wheel for ratelimit (setup.py): started\n",
            "  Building wheel for ratelimit (setup.py): finished with status 'done'\n",
            "  Created wheel for ratelimit: filename=ratelimit-2.2.1-py3-none-any.whl size=5972 sha256=e57d37aa9a18d0e6d1212e44475e58192c7dd4fcc4b13e2eec133f12af6cbf9d\n",
            "  Stored in directory: /root/.cache/pip/wheels/14/1e/97/126009a0884bdf7e26436cace73d9a4f4596dada4fdc4950ce\n",
            "  Building wheel for antlr4-python3-runtime (setup.py): started\n",
            "  Building wheel for antlr4-python3-runtime (setup.py): finished with status 'done'\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144591 sha256=52531cd8bc6ff550eb57555c057411fcb104b7cfa3ef70941508d455d4f431c8\n",
            "  Stored in directory: /root/.cache/pip/wheels/23/cf/80/f3efa822e6ab23277902ee9165fe772eeb1dfb8014f359020a\n",
            "  Building wheel for nvidia-ml-py3 (setup.py): started\n",
            "  Building wheel for nvidia-ml-py3 (setup.py): finished with status 'done'\n",
            "  Created wheel for nvidia-ml-py3: filename=nvidia_ml_py3-7.352.0-py3-none-any.whl size=19208 sha256=622c74d9e55d126ab657eb515a900bef23b1b7a7ed0ec6f60f6260d926dae817\n",
            "  Stored in directory: /root/.cache/pip/wheels/f6/d8/b0/15cfd7805d39250ac29318105f09b1750683387630d68423e1\n",
            "  Building wheel for sentinels (setup.py): started\n",
            "  Building wheel for sentinels (setup.py): finished with status 'done'\n",
            "  Created wheel for sentinels: filename=sentinels-1.0.0-py3-none-any.whl size=3229 sha256=289a3d5b017daa3aca4561afb4332f3603cf9de471a94ba4508c65a037274d14\n",
            "  Stored in directory: /root/.cache/pip/wheels/39/4c/05/90d81b81899bc2fd244e072d9b323422128e69a99328e712a5\n",
            "Successfully built diffcsp flowmm p-tqdm pyxtal ratelimit antlr4-python3-runtime nvidia-ml-py3 sentinels\n",
            "Installing collected packages: sentinels, ratelimit, nvidia-ml-py3, manifm, kaleido, ipython-genutils, distlib, cdvae, antlr4-python3-runtime, virtualenv, urllib3, typing-inspection, toolz, smmap, setproctitle, python-dotenv, pyg_lib, pyevtk, pyerfa, pydash, pydantic-core, protobuf, propcache, ppft, pox, pluggy, pathspec, orjson, opt-einsum, omegaconf, nodeenv, mypy-extensions, multidict, msgpack, mongomock, jsonlines, jmespath, iniconfig, identify, fsspec, frozenlist, flowmm, eval-type-backport, einops, dnspython, dill, diffcsp, cython, colorlog, cloudpickle, click, chemparse, cfgv, biopython, bcrypt, async-timeout, astropy-iers-data, annotated-types, aioitertools, aiohappyeyeballs, yarl, tensorboardX, submitit, sentry-sdk, scikit-learn, pytest, pynacl, pymongo, pydantic, pre-commit, POT, multiprocess, hydra-core, gitdb, cryptography, botocore, black, astropy, aiosignal, xarray, torchdiffeq, s3transfer, pymatgen, pydantic-settings, pooch, pathos, paramiko, opt-einsum-fx, ipykernel, hydra-submitit-launcher, hydra_colorlog, gitpython, geoopt, aiohttp, wandb, sshtunnel, smact, pyshtools, pymatviz, p-tqdm, matminer, ipympl, emmet-core, e3nn, chgnet, boto3, pyxtal, pytorch-lightning, maggma, mp-api, matbench-discovery\n",
            "  Running setup.py develop for manifm\n",
            "  Running setup.py develop for cdvae\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.4.0\n",
            "    Uninstalling urllib3-2.4.0:\n",
            "      Successfully uninstalled urllib3-2.4.0\n",
            "  Attempting uninstall: click\n",
            "    Found existing installation: click 8.1.8\n",
            "    Uninstalling click-8.1.8:\n",
            "      Successfully uninstalled click-8.1.8\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.6.1\n",
            "    Uninstalling scikit-learn-1.6.1:\n",
            "      Successfully uninstalled scikit-learn-1.6.1\n",
            "  Attempting uninstall: pymatgen\n",
            "    Found existing installation: pymatgen 2023.10.11\n",
            "    Uninstalling pymatgen-2023.10.11:\n",
            "      Successfully uninstalled pymatgen-2023.10.11\n",
            "  Attempting uninstall: ipykernel\n",
            "    Found existing installation: ipykernel 6.29.5\n",
            "    Uninstalling ipykernel-6.29.5:\n",
            "      Successfully uninstalled ipykernel-6.29.5\n",
            "\n",
            "Successfully installed POT-0.9.3 aiohappyeyeballs-2.6.1 aiohttp-3.12.12 aioitertools-0.12.0 aiosignal-1.3.2 annotated-types-0.7.0 antlr4-python3-runtime-4.9.3 astropy-6.0.1 astropy-iers-data-0.2025.6.9.14.9.37 async-timeout-5.0.1 bcrypt-4.3.0 biopython-1.83 black-22.6.0 boto3-1.38.33 botocore-1.38.33 cdvae-0.0.1 cfgv-3.4.0 chemparse-0.1.3 chgnet-0.3.1 click-8.1.7 cloudpickle-3.1.1 colorlog-6.9.0 cryptography-43.0.3 cython-3.1.2 diffcsp-0.1.dev28+g199539f dill-0.4.0 distlib-0.3.9 dnspython-2.7.0 e3nn-0.5.1 einops-0.7.0 emmet-core-0.84.5 eval-type-backport-0.2.2 flowmm-0.1.dev10+g6a96aec.d20250610 frozenlist-1.7.0 fsspec-2025.5.1 geoopt-0.5.0 gitdb-4.0.12 gitpython-3.1.44 hydra-core-1.2.0 hydra-submitit-launcher-1.2.0 hydra_colorlog-1.2.0 identify-2.6.12 iniconfig-2.1.0 ipykernel-6.29.2 ipympl-0.9.3 ipython-genutils-0.2.0 jmespath-1.0.1 jsonlines-4.0.0 kaleido-0.2.1 maggma-0.71.5 manifm-1.0.0 matbench-discovery-1.0.0 matminer-0.9.3 mongomock-4.3.0 mp-api-0.39.5 msgpack-1.1.0 multidict-6.4.4 multiprocess-0.70.18 mypy-extensions-1.1.0 nodeenv-1.9.1 nvidia-ml-py3-7.352.0 omegaconf-2.3.0 opt-einsum-3.4.0 opt-einsum-fx-0.1.4 orjson-3.10.18 p-tqdm-1.3.3 paramiko-3.5.1 pathos-0.3.4 pathspec-0.12.1 pluggy-1.6.0 pooch-1.8.2 pox-0.3.6 ppft-1.7.7 pre-commit-3.6.1 propcache-0.3.2 protobuf-6.31.1 pydantic-2.11.5 pydantic-core-2.33.2 pydantic-settings-2.9.1 pydash-8.0.5 pyerfa-2.0.1.5 pyevtk-1.6.0 pyg_lib-0.4.0+pt21cu118 pymatgen-2024.8.9 pymatviz-0.8.1 pymongo-4.10.1 pynacl-1.5.0 pyshtools-4.10.4 pytest-8.0.0 python-dotenv-1.0.1 pytorch-lightning-1.8.5.post0 pyxtal-0.6.1 ratelimit-2.2.1 s3transfer-0.13.0 scikit-learn-1.4.0 sentinels-1.0.0 sentry-sdk-2.29.1 setproctitle-1.3.6 smact-2.2.1 smmap-5.0.2 sshtunnel-0.4.0 submitit-1.5.1 tensorboardX-2.6.2.2 toolz-0.12.1 torchdiffeq-0.2.3 typing-inspection-0.4.1 urllib3-1.26.20 virtualenv-20.31.2 wandb-0.20.1 xarray-2024.7.0 yarl-1.20.1\n",
            "\b\b| \n",
            "\b\bdone\n",
            "#\n",
            "# To activate this environment, use\n",
            "#\n",
            "#     $ conda activate /usr/local/envs/flowmm_env\n",
            "#\n",
            "# To deactivate an active environment, use\n",
            "#\n",
            "#     $ conda deactivate\n",
            "\n",
            "Collecting uv\n",
            "  Downloading uv-0.7.12-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Downloading uv-0.7.12-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.8/17.8 MB\u001b[0m \u001b[31m48.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: uv\n",
            "Successfully installed uv-0.7.12\n",
            "\u001b[2mUsing Python 3.9.0 environment at: /usr/local/envs/flowmm_env\u001b[0m\n",
            "\u001b[2K\u001b[2mResolved \u001b[1m46 packages\u001b[0m \u001b[2min 893ms\u001b[0m\u001b[0m\n",
            "\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/3)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/3)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/3)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/3)\n",
            "\u001b[2mxmltodict           \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 9.75 KiB/9.75 KiB\n",
            "\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/3)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/3)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/3)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/3)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/3)\n",
            "\u001b[2mmonty               \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 32.00 KiB/50.71 KiB\n",
            "\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/3)\n",
            "\u001b[2mmonty               \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 32.00 KiB/50.71 KiB\n",
            "\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/3)\n",
            "\u001b[2mmonty               \u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 48.00 KiB/50.71 KiB\n",
            "\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/3)\n",
            "\u001b[2mmonty               \u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 48.00 KiB/50.71 KiB\n",
            "\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/3)\n",
            "\u001b[2mmonty               \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 50.71 KiB/50.71 KiB\n",
            "\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/3)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/3)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/3)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/3)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/3)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/3)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/3)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/3)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/3)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (2/3)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (2/3)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (2/3)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (2/3)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (2/3)\n",
            "\u001b[2K\u001b[2mPrepared \u001b[1m3 packages\u001b[0m \u001b[2min 440ms\u001b[0m\u001b[0m\n",
            "\u001b[2mUninstalled \u001b[1m1 package\u001b[0m \u001b[2min 2ms\u001b[0m\u001b[0m\n",
            "\u001b[2K\u001b[2mInstalled \u001b[1m3 packages\u001b[0m \u001b[2min 13ms\u001b[0m\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mjarvis-tools\u001b[0m\u001b[2m==2024.10.30\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mmonty\u001b[0m\u001b[2m==2024.12.10 (from file:///home/conda/feedstock_root/build_artifacts/monty_1733965090958/work)\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mmonty\u001b[0m\u001b[2m==2025.3.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mxmltodict\u001b[0m\u001b[2m==0.14.2\u001b[0m\n",
            "\u001b[2mUsing Python 3.9.0 environment at: /usr/local/envs/flowmm_env\u001b[0m\n",
            "\u001b[2K   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m diffcsp\u001b[2m @ file:///content/flowmm/remote/DiffCSP-official\u001b[0m\n",
            "\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m diffcsp\u001b[2m @ file:///content/flowmm/remote/DiffCSP-official\u001b[0m\n",
            "\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m diffcsp\u001b[2m @ file:///content/flowmm/remote/DiffCSP-official\u001b[0m\n",
            "\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m diffcsp\u001b[2m @ file:///content/flowmm/remote/DiffCSP-official\u001b[0m\n",
            "\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m diffcsp\u001b[2m @ file:///content/flowmm/remote/DiffCSP-official\u001b[0m\n",
            "\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m diffcsp\u001b[2m @ file:///content/flowmm/remote/DiffCSP-official\u001b[0m\n",
            "\u001b[2K\u001b[1A      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m diffcsp\u001b[2m @ file:///content/flowmm/remote/DiffCSP-official\u001b[0m\n",
            "\u001b[2K\u001b[2mResolved \u001b[1m4 packages\u001b[0m \u001b[2min 4.26s\u001b[0m\u001b[0m\n",
            "\u001b[2K   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m flowmm\u001b[2m @ file:///content/flowmm\u001b[0m\n",
            "\u001b[2K\u001b[1A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m flowmm\u001b[2m @ file:///content/flowmm\u001b[0m\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m manifm\u001b[2m @ file:///content/flowmm/remote/riemannian-fm\u001b[0m\n",
            "\u001b[2K\u001b[2A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m flowmm\u001b[2m @ file:///content/flowmm\u001b[0m\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m manifm\u001b[2m @ file:///content/flowmm/remote/riemannian-fm\u001b[0m\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m cdvae\u001b[2m @ file:///content/flowmm/remote/cdvae\u001b[0m\n",
            "\u001b[2K\u001b[3A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m flowmm\u001b[2m @ file:///content/flowmm\u001b[0m\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m manifm\u001b[2m @ file:///content/flowmm/remote/riemannian-fm\u001b[0m\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m cdvae\u001b[2m @ file:///content/flowmm/remote/cdvae\u001b[0m\n",
            "\u001b[2K\u001b[3A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m flowmm\u001b[2m @ file:///content/flowmm\u001b[0m\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m manifm\u001b[2m @ file:///content/flowmm/remote/riemannian-fm\u001b[0m\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m cdvae\u001b[2m @ file:///content/flowmm/remote/cdvae\u001b[0m\n",
            "\u001b[2K\u001b[3A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m flowmm\u001b[2m @ file:///content/flowmm\u001b[0m\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m manifm\u001b[2m @ file:///content/flowmm/remote/riemannian-fm\u001b[0m\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m cdvae\u001b[2m @ file:///content/flowmm/remote/cdvae\u001b[0m\n",
            "\u001b[2K\u001b[3A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m flowmm\u001b[2m @ file:///content/flowmm\u001b[0m\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m manifm\u001b[2m @ file:///content/flowmm/remote/riemannian-fm\u001b[0m\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m cdvae\u001b[2m @ file:///content/flowmm/remote/cdvae\u001b[0m\n",
            "\u001b[2K\u001b[3A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m flowmm\u001b[2m @ file:///content/flowmm\u001b[0m\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m manifm\u001b[2m @ file:///content/flowmm/remote/riemannian-fm\u001b[0m\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m cdvae\u001b[2m @ file:///content/flowmm/remote/cdvae\u001b[0m\n",
            "\u001b[2K\u001b[3A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m flowmm\u001b[2m @ file:///content/flowmm\u001b[0m\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m manifm\u001b[2m @ file:///content/flowmm/remote/riemannian-fm\u001b[0m\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m cdvae\u001b[2m @ file:///content/flowmm/remote/cdvae\u001b[0m\n",
            "\u001b[2K\u001b[3A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m flowmm\u001b[2m @ file:///content/flowmm\u001b[0m\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m manifm\u001b[2m @ file:///content/flowmm/remote/riemannian-fm\u001b[0m\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m cdvae\u001b[2m @ file:///content/flowmm/remote/cdvae\u001b[0m\n",
            "\u001b[2K\u001b[3A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m flowmm\u001b[2m @ file:///content/flowmm\u001b[0m\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m manifm\u001b[2m @ file:///content/flowmm/remote/riemannian-fm\u001b[0m\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m cdvae\u001b[2m @ file:///content/flowmm/remote/cdvae\u001b[0m\n",
            "\u001b[2K\u001b[3A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m flowmm\u001b[2m @ file:///content/flowmm\u001b[0m\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m manifm\u001b[2m @ file:///content/flowmm/remote/riemannian-fm\u001b[0m\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m cdvae\u001b[2m @ file:///content/flowmm/remote/cdvae\u001b[0m\n",
            "\u001b[2K\u001b[3A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m flowmm\u001b[2m @ file:///content/flowmm\u001b[0m\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m manifm\u001b[2m @ file:///content/flowmm/remote/riemannian-fm\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m cdvae\u001b[2m @ file:///content/flowmm/remote/cdvae\u001b[0m\n",
            "\u001b[2K\u001b[3A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m flowmm\u001b[2m @ file:///content/flowmm\u001b[0m\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m manifm\u001b[2m @ file:///content/flowmm/remote/riemannian-fm\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m cdvae\u001b[2m @ file:///content/flowmm/remote/cdvae\u001b[0m\n",
            "\u001b[2K\u001b[3A      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m flowmm\u001b[2m @ file:///content/flowmm\u001b[0m\n",
            "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m manifm\u001b[2m @ file:///content/flowmm/remote/riemannian-fm\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m cdvae\u001b[2m @ file:///content/flowmm/remote/cdvae\u001b[0m\n",
            "\u001b[2K\u001b[2A      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m manifm\u001b[2m @ file:///content/flowmm/remote/riemannian-fm\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m cdvae\u001b[2m @ file:///content/flowmm/remote/cdvae\u001b[0m\n",
            "\u001b[2K\u001b[1A      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m cdvae\u001b[2m @ file:///content/flowmm/remote/cdvae\u001b[0m\n",
            "\u001b[2K\u001b[2mPrepared \u001b[1m4 packages\u001b[0m \u001b[2min 2.10s\u001b[0m\u001b[0m\n",
            "\u001b[2mUninstalled \u001b[1m4 packages\u001b[0m \u001b[2min 2ms\u001b[0m\u001b[0m\n",
            "\u001b[2K\u001b[2mInstalled \u001b[1m4 packages\u001b[0m \u001b[2min 2ms\u001b[0m\u001b[0m\n",
            " \u001b[33m~\u001b[39m \u001b[1mcdvae\u001b[0m\u001b[2m==0.0.1 (from file:///content/flowmm/remote/cdvae)\u001b[0m\n",
            " \u001b[33m~\u001b[39m \u001b[1mdiffcsp\u001b[0m\u001b[2m==0.1.dev28+g199539f (from file:///content/flowmm/remote/DiffCSP-official)\u001b[0m\n",
            " \u001b[33m~\u001b[39m \u001b[1mflowmm\u001b[0m\u001b[2m==0.1.dev10+g6a96aec.d20250610 (from file:///content/flowmm)\u001b[0m\n",
            " \u001b[33m~\u001b[39m \u001b[1mmanifm\u001b[0m\u001b[2m==1.0.0 (from file:///content/flowmm/remote/riemannian-fm)\u001b[0m\n",
            "Done\n",
            "CPU times: user 12 s, sys: 1.95 s, total: 13.9 s\n",
            "Wall time: 23min 53s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add __ init __.py to manifm and reinstall"
      ],
      "metadata": {
        "id": "u1EcSG2nh2r5"
      },
      "id": "u1EcSG2nh2r5"
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/flowmm/\n",
        "import os\n",
        "if not os.path.exists('remote/riemannian-fm/manifm/__init.py__'):\n",
        "    !wget -q https://raw.githubusercontent.com/crhysc/utilities/refs/heads/main/__init__.py\n",
        "    !mv __init__.py /content/flowmm/remote/riemannian-fm/manifm/\n",
        "!conda run -p /usr/local/envs/flowmm_env --live-stream\\\n",
        "    pip install -e /content/flowmm/remote/riemannian-fm/i\n",
        "!conda run -p /usr/local/envs/flowmm_env --live-stream\\\n",
        "    python -c \"import manifm; print('manifm version:', manifm.__version__)\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7puO0mzJqtIV",
        "outputId": "606ef427-35d4-485d-99f4-2d5d7554b802"
      },
      "id": "7puO0mzJqtIV",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/flowmm\n",
            "Obtaining file:///content/flowmm/remote/riemannian-fm\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Installing collected packages: manifm\n",
            "  Attempting uninstall: manifm\n",
            "    Found existing installation: manifm 1.0.0\n",
            "    Uninstalling manifm-1.0.0:\n",
            "      Successfully uninstalled manifm-1.0.0\n",
            "\u001b[33m  DEPRECATION: Legacy editable install of manifm==1.0.0 from file:///content/flowmm/remote/riemannian-fm (setup.py develop) is deprecated. pip 25.3 will enforce this behaviour change. A possible replacement is to add a pyproject.toml or enable --use-pep517, and use setuptools >= 64. If the resulting installation is not behaving as expected, try using --config-settings editable_mode=compat. Please consult the setuptools documentation for more information. Discussion can be found at https://github.com/pypa/pip/issues/11457\u001b[0m\u001b[33m\n",
            "\u001b[0m  Running setup.py develop for manifm\n",
            "Successfully installed manifm-1.0.0\n",
            "manifm version: 1.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install Other dependencies\n"
      ],
      "metadata": {
        "id": "-S-tghd_r5at"
      },
      "id": "-S-tghd_r5at"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (3) DATASET ETL (Extract-Transform-Load)\n"
      ],
      "metadata": {
        "id": "U0r5S-jNYNje"
      },
      "id": "U0r5S-jNYNje"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download data pre-processor"
      ],
      "metadata": {
        "id": "w0bEujxyydMx"
      },
      "id": "w0bEujxyydMx"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data was generated using this [script](https://github.com/crhysc/utilities/blob/main/supercon_preprocess.py). It compiles a set of around 1000 structures and their superconducting critical temperatures into the format required for FlowMM training."
      ],
      "metadata": {
        "id": "yA221iCNZyh-"
      },
      "id": "yA221iCNZyh-"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a01b9fa5",
      "metadata": {
        "id": "a01b9fa5",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d71199e-0617-46d0-a1db-7dcd395958cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/flowmm\n",
            "#!/usr/bin/env python\n",
            "\"\"\"\n",
            "supercon_preprocess.py  –  Python 3.9 compatible\n",
            "\n",
            "Example\n",
            "-------\n",
            "python supercon_preprocess.py \\\n",
            "    --dataset dft_3d --id-key jid --target Tc_supercon \\\n",
            "    --train-ratio 0.8 --val-ratio 0.1 --test-ratio 0.1 \\\n",
            "    --seed 123 --max-size 1000\n",
            "\"\"\"\n",
            "from __future__ import annotations\n",
            "\n",
            "import argparse, random, json, hashlib\n",
            "from pathlib import Path\n",
            "from typing import Optional, List, Tuple\n",
            "\n",
            "import numpy as np\n",
            "import pandas as pd\n",
            "from tqdm import tqdm\n",
            "\n",
            "from jarvis.db.figshare import data as jarvis_data\n",
            "from jarvis.core.atoms import Atoms\n",
            "from pymatgen.core import Structure\n",
            "from pymatgen.symmetry.analyzer import SpacegroupAnalyzer\n",
            "\n",
            "\n",
            "# ---------- helpers ----------------------------------------------------------\n",
            "def canonicalise(pmg_struct: Structure, symprec: float = 0.1) -> Tuple[str, int, int]:\n",
            "    \"\"\"Return (cif_conv, spg_num, spg_num_conv).  Never raises.\"\"\"\n",
            "    try:\n",
            "        sga = SpacegroupAnalyzer(pmg_struct, symprec=symprec)\n",
            "        spg_num = sga.get_space_group_number()\n",
            "        conv = sga.get_conventional_standard_structure()\n",
            "        spg_conv = SpacegroupAnalyzer(conv, symprec=symprec).get_space_group_number()\n",
            "        return conv.to(fmt=\"cif\"), spg_num, spg_conv\n",
            "    except Exception:\n",
            "        return \"\", -1, -1\n",
            "\n",
            "\n",
            "def make_dataframe(\n",
            "    dataset_name: str,\n",
            "    id_key: str,\n",
            "    target_key: str,\n",
            "    max_size: Optional[int],\n",
            ") -> pd.DataFrame:\n",
            "    \"\"\"Download JARVIS records and keep those with a defined target.\n",
            "\n",
            "    If --max-size is given, we **stop as soon as we have exactly that many\n",
            "    valid structures** (i.e. after filtering out `\"na\"` / `None` targets).\n",
            "    \"\"\"\n",
            "    records: List[dict] = []\n",
            "    for item in tqdm(jarvis_data(dataset_name), desc=\"Downloading/JARVIS\"):\n",
            "        target_val = item.get(target_key, \"na\")\n",
            "        if target_val in (\"na\", None):\n",
            "            continue  # skip invalid target\n",
            "\n",
            "        pmg = Atoms.from_dict(item[\"atoms\"]).pymatgen_converter()\n",
            "        try:\n",
            "            cif_raw = pmg.to(fmt=\"cif\")\n",
            "        except Exception:\n",
            "            continue  # bad CIF – behave like the reference script\n",
            "\n",
            "        cif_conv, spg, spg_conv = canonicalise(pmg)\n",
            "\n",
            "        records.append(\n",
            "            {\n",
            "                \"material_id\": item[id_key],\n",
            "                \"pretty_formula\": pmg.composition.reduced_formula,\n",
            "                \"elements\": json.dumps([el.symbol for el in pmg.species]),\n",
            "                \"cif\": cif_raw,\n",
            "                \"spacegroup.number\": spg,\n",
            "                \"spacegroup.number.conv\": spg_conv,\n",
            "                \"cif.conv\": cif_conv,\n",
            "                target_key: target_val,\n",
            "            }\n",
            "        )\n",
            "\n",
            "        # --- stop exactly at the requested cap -------------------------------\n",
            "        if max_size is not None and len(records) == max_size:\n",
            "            break\n",
            "\n",
            "    return pd.DataFrame(records)\n",
            "\n",
            "\n",
            "def split_indices(\n",
            "    n: int,\n",
            "    train_ratio: float,\n",
            "    val_ratio: float,\n",
            "    test_ratio: float,\n",
            "    seed: int,\n",
            ") -> Tuple[List[int], List[int], List[int]]:\n",
            "    \"\"\"Replicates the reference get_id_train_val_test().\"\"\"\n",
            "    indices = list(range(n))\n",
            "    random.seed(seed)\n",
            "    random.shuffle(indices)\n",
            "\n",
            "    n_train = int(train_ratio * n)\n",
            "    n_test = int(test_ratio * n)\n",
            "    n_val = int(val_ratio * n)\n",
            "\n",
            "    if n_train + n_val + n_test > n:\n",
            "        raise ValueError(\"Check total number of samples\")\n",
            "\n",
            "    id_train = indices[:n_train]\n",
            "    id_val = indices[-(n_val + n_test) : -n_test]  # noqa: E203\n",
            "    id_test = indices[-n_test:]\n",
            "    return id_train, id_val, id_test\n",
            "\n",
            "\n",
            "def sha(lst) -> str:\n",
            "    m = hashlib.sha256()\n",
            "    for x in lst:\n",
            "        m.update(str(x).encode())\n",
            "        m.update(b\",\")\n",
            "    return m.hexdigest()[:10]\n",
            "\n",
            "\n",
            "# ---------- CLI --------------------------------------------------------------\n",
            "def main() -> None:\n",
            "    ap = argparse.ArgumentParser()\n",
            "    ap.add_argument(\"--dataset\", required=True)\n",
            "    ap.add_argument(\"--id-key\", default=\"jid\")\n",
            "    ap.add_argument(\"--target\", dest=\"target_key\", default=\"Tc_supercon\")\n",
            "    ap.add_argument(\"--train-ratio\", type=float, default=0.8)\n",
            "    ap.add_argument(\"--val-ratio\", type=float, default=0.1)\n",
            "    ap.add_argument(\"--test-ratio\", type=float, default=0.1)\n",
            "    ap.add_argument(\"--seed\", type=int, default=123)\n",
            "    ap.add_argument(\"--max-size\", type=int, default=None,\n",
            "                    help=\"Cap on the number of *valid* structures\")\n",
            "    args = ap.parse_args()\n",
            "\n",
            "    assert abs(args.train_ratio + args.val_ratio + args.test_ratio - 1) < 1e-6\n",
            "\n",
            "    df = make_dataframe(args.dataset, args.id_key, args.target_key, args.max_size)\n",
            "    print(f\"Collected {len(df)} records (max-size={args.max_size})\")\n",
            "\n",
            "    id_train, id_val, id_test = split_indices(\n",
            "        len(df), args.train_ratio, args.val_ratio, args.test_ratio, args.seed\n",
            "    )\n",
            "\n",
            "    Path(\".\").mkdir(exist_ok=True)\n",
            "    df.iloc[id_train].to_csv(\"train.csv\", index=False)\n",
            "    df.iloc[id_val].to_csv(\"val.csv\", index=False)\n",
            "    df.iloc[id_test].to_csv(\"test.csv\", index=False)\n",
            "\n",
            "    print(\"✓ Wrote train.csv, val.csv, test.csv\")\n",
            "    print(f\"hashes  train:{sha(df.iloc[id_train]['material_id'])} \"\n",
            "          f\"val:{sha(df.iloc[id_val]['material_id'])} \"\n",
            "          f\"test:{sha(df.iloc[id_test]['material_id'])}\")\n",
            "\n",
            "\n",
            "if __name__ == \"__main__\":\n",
            "    main()\n"
          ]
        }
      ],
      "source": [
        "%cd /content/flowmm\n",
        "import os\n",
        "if not os.path.exists('supercon_preprocess.py'):\n",
        "  !wget -q https://raw.githubusercontent.com/crhysc/utilities/refs/heads/main/supercon_preprocess.py\n",
        "%cat supercon_preprocess.py"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run data pre-processor"
      ],
      "metadata": {
        "id": "0QyFCXnQyh1u"
      },
      "id": "0QyFCXnQyh1u"
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/flowmm\n",
        "!conda run -p /usr/local/envs/flowmm_env --live-stream \\\n",
        "    python supercon_preprocess.py \\\n",
        "        --dataset dft_3d \\\n",
        "        --id-key jid \\\n",
        "        --target Tc_supercon \\\n",
        "        --train-ratio 0.8 --val-ratio 0.1 --test-ratio 0.1 \\\n",
        "        --seed 123 \\\n",
        "        --max-size 25\n",
        "print(\"Done\")"
      ],
      "metadata": {
        "id": "10tlt-F9hOkC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7d9c08d-c074-4466-d772-acd653ac6f65"
      },
      "id": "10tlt-F9hOkC",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/flowmm\n",
            "/content/flowmm/supercon_preprocess.py:19: DeprecationWarning: \n",
            "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
            "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
            "but was not found to be installed on your system.\n",
            "If this would cause problems for you,\n",
            "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
            "        \n",
            "  import pandas as pd\n",
            "Obtaining 3D dataset 76k ...\n",
            "Reference:https://www.nature.com/articles/s41524-020-00440-1\n",
            "Other versions:https://doi.org/10.6084/m9.figshare.6815699\n",
            "100% 40.8M/40.8M [00:02<00:00, 18.4MiB/s]\n",
            "Loading the zipfile...\n",
            "Loading completed.\n",
            "Downloading/JARVIS:   5% 3678/75993 [00:00<00:17, 4177.79it/s]\n",
            "Collected 25 records (max-size=25)\n",
            "✓ Wrote train.csv, val.csv, test.csv\n",
            "hashes  train:2883830c37 val:a7b15dfc05 test:05f4f13f52\n",
            "Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Move train/test/val data to the correct spot"
      ],
      "metadata": {
        "id": "c-lJ4YZRylJW"
      },
      "id": "c-lJ4YZRylJW"
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "%mkdir /content/flowmm/data/supercon\n",
        "%mv /content/flowmm/train.csv /content/flowmm/data/supercon/\n",
        "%mv /content/flowmm/val.csv /content/flowmm/data/supercon/\n",
        "%mv /content/flowmm/test.csv /content/flowmm/data/supercon/\n",
        "print(\"Done\")"
      ],
      "metadata": {
        "id": "EDghvbM-oSi6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b07e75f-0db4-4575-dd9c-760ae8d6a55e"
      },
      "id": "EDghvbM-oSi6",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pull the supercon Hydra config YAML from GitHub"
      ],
      "metadata": {
        "id": "gXIfC4ZZIN5y"
      },
      "id": "gXIfC4ZZIN5y"
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/flowmm/scripts_model/conf/data/\n",
        "!wget https://raw.githubusercontent.com/crhysc/utilities/refs/heads/main/supercon.yaml\n",
        "%cat supercon.yaml"
      ],
      "metadata": {
        "id": "tnBU6MCdIT9e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd5ff78f-a32d-48a5-e017-2e2c9f6044e9"
      },
      "id": "tnBU6MCdIT9e",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/flowmm/scripts_model/conf/data\n",
            "--2025-05-30 14:14:52--  https://raw.githubusercontent.com/crhysc/utilities/refs/heads/main/supercon.yaml\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2359 (2.3K) [text/plain]\n",
            "Saving to: ‘supercon.yaml’\n",
            "\n",
            "supercon.yaml       100%[===================>]   2.30K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-05-30 14:14:52 (13.5 MB/s) - ‘supercon.yaml’ saved [2359/2359]\n",
            "\n",
            "dataset_name: supercon\n",
            "dim_coords: 3\n",
            "root_path: ${oc.env:PROJECT_ROOT}/data/supercon\n",
            "prop: Tc_supercon\n",
            "num_targets: 1\n",
            "# prop: scaled_lattice\n",
            "# num_targets: 6\n",
            "niggli: true\n",
            "primitive: false\n",
            "graph_method: crystalnn\n",
            "lattice_scale_method: scale_length\n",
            "preprocess_workers: 30\n",
            "readout: mean\n",
            "max_atoms: 24\n",
            "otf_graph: false\n",
            "eval_model_name: supercon\n",
            "tolerance: 0.1\n",
            "\n",
            "use_space_group: false\n",
            "use_pos_index: false\n",
            "train_max_epochs: 1\n",
            "early_stopping_patience: 1\n",
            "teacher_forcing_max_epoch: 1\n",
            "\n",
            "\n",
            "datamodule:\n",
            "  _target_: diffcsp.pl_data.datamodule.CrystDataModule\n",
            "\n",
            "  datasets:\n",
            "    train:\n",
            "      _target_: diffcsp.pl_data.dataset.CrystDataset\n",
            "      name: Tc_supercon train\n",
            "      path: ${data.root_path}/train.csv\n",
            "      save_path: ${data.root_path}/train_ori.pt\n",
            "      prop: ${data.prop}\n",
            "      niggli: ${data.niggli}\n",
            "      primitive: ${data.primitive}\n",
            "      graph_method: ${data.graph_method}\n",
            "      tolerance: ${data.tolerance}\n",
            "      use_space_group: ${data.use_space_group}\n",
            "      use_pos_index: ${data.use_pos_index}\n",
            "      lattice_scale_method: ${data.lattice_scale_method}\n",
            "      preprocess_workers: ${data.preprocess_workers}\n",
            "\n",
            "    val:\n",
            "      - _target_: diffcsp.pl_data.dataset.CrystDataset\n",
            "        name: Tc_supercon train val\n",
            "        path: ${data.root_path}/val.csv\n",
            "        save_path: ${data.root_path}/val_ori.pt\n",
            "        prop: ${data.prop}\n",
            "        niggli: ${data.niggli}\n",
            "        primitive: ${data.primitive}\n",
            "        graph_method: ${data.graph_method}\n",
            "        tolerance: ${data.tolerance}\n",
            "        use_space_group: ${data.use_space_group}\n",
            "        use_pos_index: ${data.use_pos_index}\n",
            "        lattice_scale_method: ${data.lattice_scale_method}\n",
            "        preprocess_workers: ${data.preprocess_workers}\n",
            "\n",
            "    test:\n",
            "      - _target_: diffcsp.pl_data.dataset.CrystDataset\n",
            "        name: Tc_supercon train test\n",
            "        path: ${data.root_path}/test.csv\n",
            "        save_path: ${data.root_path}/test_ori.pt\n",
            "        prop: ${data.prop}\n",
            "        niggli: ${data.niggli}\n",
            "        primitive: ${data.primitive}\n",
            "        graph_method: ${data.graph_method}\n",
            "        tolerance: ${data.tolerance}\n",
            "        use_space_group: ${data.use_space_group}\n",
            "        use_pos_index: ${data.use_pos_index}\n",
            "        lattice_scale_method: ${data.lattice_scale_method}\n",
            "        preprocess_workers: ${data.preprocess_workers}\n",
            "\n",
            "  num_workers:\n",
            "    train: 1\n",
            "    val: 1\n",
            "    test: 1\n",
            "\n",
            "  batch_size:\n",
            "    train: 8\n",
            "    val: 16\n",
            "    test: 16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modify FlowMM hardcode to accept our supercon dataset"
      ],
      "metadata": {
        "id": "XP9mA1542KMZ"
      },
      "id": "XP9mA1542KMZ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, open **Files** in the left sidebar and navigate to **/Content/flowmm/src/flowmm/**. Click **cfg_utils.py**, and on line 15, add \"supercon\" to the *dataset_options* literal and delete all other strings in the tuple."
      ],
      "metadata": {
        "id": "oGES28ePM1Jx"
      },
      "id": "oGES28ePM1Jx"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, open **Files** again and navigate to /Content/flowmm/src/flowmm/rfm/manifolds/. Click **spd.py**, and then navigate to the \"if __ name __ = __ main __\" block. Uncomment lines 449 through 466 (we are turning on \"compute_stats\". Next, on line 468, set \"compute_stats = True\". Next, on line 489, set \"compute_stats = True\" again. Next, on line 461, change \"\"std\": std.cpu().tolist()\" to \"\"logmap_std\": std.cpu().tolist(),\". Next, on line 236, change the \"std\" string to \"logmap_std\". Next, on line 431, in the \".std()\" function, add \"unbiased=False\" in between the parentheses so that the whole line reads \"std_coefs.append((log_noise_samples.std(unbiased=False) ** (3 / 2)) / n)\n",
        "\"."
      ],
      "metadata": {
        "id": "HIlAyUrkld69"
      },
      "id": "HIlAyUrkld69"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, open Files again and navigate to /Content/flowmm/src/flowmm/rfm/manifolds/. Click **spd.py**, and then replace all code including and after line 531, which is a comment saying \"# do some testing for SPDNonIsotropicRandom\""
      ],
      "metadata": {
        "id": "sWOLJeUwxHa1"
      },
      "id": "sWOLJeUwxHa1"
    },
    {
      "cell_type": "markdown",
      "source": [
        "    pL_stats = OmegaConf.load(Path(__file__).parent / \"spd_pLTL_stats.yaml\")  # ← new line\n",
        "\n",
        "    for dataset in tqdm(list(dataset_options.__args__)):\n",
        "          mean_vec = torch.tensor(pL_stats[dataset][\"mean\"])           # now using pL_stats\n",
        "          std_vec  = torch.tensor(pL_stats[dataset][\"logmap_std\"])     # correct key name\n",
        "\n",
        "          # optional sanity check\n",
        "          if mean_vec.ndim == 0:\n",
        "              raise ValueError(\n",
        "                  f\"Loaded mean for {dataset} is scalar—wrong YAML? shape {mean_vec.shape}\"\n",
        "              )\n",
        "\n",
        "          s = manifm_SPD(Riem_geodesic=True, Riem_norm=True)\n",
        "          spd = SPDNonIsotropicRandom(mean_vec, std_vec)\n",
        "          r   = spd.random_base(10, mean_vec.size(-1))\n",
        "          lp  = spd.base_logprob(r)\n",
        "          print(r, lp)\n",
        "\n",
        "          r  = spd.random_base(3, 10, mean_vec.size(-1))\n",
        "          lp = spd.base_logprob(r)\n",
        "          print(r, lp)"
      ],
      "metadata": {
        "id": "8nst0kL8xJst"
      },
      "id": "8nst0kL8xJst"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate necessary YAML files for training"
      ],
      "metadata": {
        "id": "TgDT_QRk1LtU"
      },
      "id": "TgDT_QRk1LtU"
    },
    {
      "cell_type": "code",
      "source": [
        "%rm /content/flowmm/src/flowmm/rfm/manifolds/atom_density.yaml\n",
        "%rm /content/flowmm/src/flowmm/rfm/manifolds/spd_pLTL_stats.yaml\n",
        "%rm /content/flowmm/src/flowmm/rfm/manifolds/spd_std_coef.yaml"
      ],
      "metadata": {
        "id": "Wf2CMJChQDOe"
      },
      "id": "Wf2CMJChQDOe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/flowmm\n",
        "!bash create_env_file.sh && \\\n",
        " echo \"successfully ran create_env_file.sh\" && \\\n",
        " HYDRA_FULL_ERROR=1 \\\n",
        " FLOWMM_DEBUG=1 \\\n",
        " conda run -p /usr/local/envs/flowmm_env --live-stream \\\n",
        "    python -u -m flowmm.rfm.manifolds.spd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "-zY7EpeZ1Y8m",
        "outputId": "044101f4-7441-404d-bd9c-a70d0c8e022b"
      },
      "id": "-zY7EpeZ1Y8m",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/flowmm\n",
            "successfully ran create_env_file.sh\n",
            "calculate the overall stats of p(L) for each dataset\n",
            "dataset='supercon': 100% 1/1 [00:01<00:00,  1.24s/it]\n",
            "calculate the density atoms to volume\n",
            "dataset='supercon': 100% 1/1 [00:00<00:00,  2.51it/s]\n",
            "calculate the stats of p(L | N) for each dataset\n",
            "dataset='supercon': 100% 1/1 [00:00<00:00,  2.40it/s]\n",
            "  0% 0/1 [00:00<?, ?it/s]/usr/local/envs/flowmm_env/lib/python3.9/site-packages/torch/autograd/__init__.py:394: UserWarning: There is a performance drop because we have not yet implemented the batching rule for aten::matrix_exp. Please file us an issue on GitHub so that we can prioritize its implementation. (Triggered internally at /opt/conda/conda-bld/pytorch_1695392022560/work/aten/src/ATen/functorch/BatchedFallback.cpp:82.)\n",
            "  result = Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "tensor([[ 1.3256e+01, -3.6469e+00, -1.0556e+00,  2.7924e+01,  3.9923e+01,\n",
            "          1.6027e+02],\n",
            "        [ 1.4155e+01, -1.6675e+00,  4.7316e+00,  1.8261e+01, -1.7753e-01,\n",
            "          3.6445e+01],\n",
            "        [ 1.1741e+01, -1.7383e+00,  5.4313e+00,  6.6268e+00,  3.4052e+00,\n",
            "          1.6635e+02],\n",
            "        [ 3.0791e+01, -6.1934e+00, -7.4658e+00,  8.6902e+01, -1.6411e+00,\n",
            "          5.1165e+01],\n",
            "        [ 1.3460e+01,  1.7631e+00,  2.6000e+00,  2.4370e+01,  1.2450e+01,\n",
            "          2.7402e+01],\n",
            "        [ 1.9541e+01, -8.5409e+00,  5.4054e+00,  5.2500e+01,  6.4400e+00,\n",
            "          9.7961e+01],\n",
            "        [ 1.4901e+01, -3.8610e-02, -6.6204e-01,  1.4579e+01, -1.6366e+00,\n",
            "          2.2440e+01],\n",
            "        [ 3.2402e+01, -1.0155e+01, -5.2545e-01,  1.9723e+01,  6.9201e+00,\n",
            "          1.6027e+01],\n",
            "        [ 1.2146e+01, -6.0882e-01,  4.1597e+00,  3.3678e+01, -3.8082e+00,\n",
            "          2.0587e+01],\n",
            "        [ 3.5617e+01, -4.0501e+00, -1.4052e+01,  1.0525e+01,  8.4021e+00,\n",
            "          3.4465e+01]]) tensor([-70.5578, -41.5796, -59.4461, -69.1132, -41.7033, -55.3241, -40.6488,\n",
            "        -40.9866, -41.9999, -44.2550])\n",
            "tensor([[[ 1.2072e+01,  7.7957e+00,  2.7291e+01,  1.3913e+01,  2.2644e+01,\n",
            "           1.1853e+02],\n",
            "         [ 2.4236e+01, -6.8105e+00, -8.1539e-03,  2.3168e+01,  8.4731e-01,\n",
            "           3.6519e+01],\n",
            "         [ 1.7181e+01, -2.9056e+00,  1.1456e+01,  1.1271e+01, -3.2588e+00,\n",
            "           1.7143e+01],\n",
            "         [ 1.2807e+01,  1.1491e+00,  3.0359e+00,  1.3213e+01,  4.1003e+00,\n",
            "           1.7879e+01],\n",
            "         [ 1.7947e+01,  1.0100e+01, -9.1969e+00,  1.1378e+01, -4.6644e+00,\n",
            "           8.5682e+01],\n",
            "         [ 1.6722e+01, -7.2077e-01, -1.0839e+00,  6.4833e+00,  6.9697e+00,\n",
            "           3.5699e+01],\n",
            "         [ 4.4175e+01,  7.1957e+00, -3.4470e+00,  2.9254e+01, -8.4743e+00,\n",
            "           2.8471e+01],\n",
            "         [ 1.5836e+01,  7.0348e-01,  2.9619e-01,  9.3122e+00,  5.8247e+00,\n",
            "           3.3503e+01],\n",
            "         [ 1.2952e+01,  2.9865e+00,  2.2231e+00,  2.2488e+01,  1.2517e+00,\n",
            "           1.2389e+02],\n",
            "         [ 2.9109e+01,  1.3002e+01, -5.4961e+00,  2.9432e+01, -5.2220e+00,\n",
            "           2.0044e+01]],\n",
            "\n",
            "        [[ 1.7874e+01, -8.9974e+00,  8.3542e+00,  2.8246e+01, -2.9825e+00,\n",
            "           1.3461e+01],\n",
            "         [ 2.8880e+01, -1.4864e+00,  2.2124e+01,  8.5682e+00, -8.7441e+00,\n",
            "           1.1823e+02],\n",
            "         [ 1.6011e+01, -2.2908e+00,  9.7475e+00,  5.7233e+00,  4.5174e+00,\n",
            "           4.6585e+01],\n",
            "         [ 1.5323e+01,  6.7058e-01, -1.9209e+00,  1.0251e+01, -4.6564e+00,\n",
            "           5.7620e+01],\n",
            "         [ 1.7274e+01, -8.6082e-01,  4.0538e-01,  4.8615e+01, -7.4633e+00,\n",
            "           1.8389e+01],\n",
            "         [ 2.6394e+01, -4.4185e-01,  1.5342e+01,  6.6836e+00, -2.7244e+00,\n",
            "           5.6168e+01],\n",
            "         [ 8.1550e+00,  2.7749e+00,  1.0458e+01,  5.3622e+00,  9.5818e+00,\n",
            "           5.5695e+01],\n",
            "         [ 1.2438e+01,  4.0199e+00,  7.5441e+00,  3.4020e+01, -1.1931e+01,\n",
            "           3.7658e+01],\n",
            "         [ 3.0152e+01,  2.5403e+00,  1.0558e+00,  9.4151e+00,  1.0101e+01,\n",
            "           2.7548e+01],\n",
            "         [ 1.0735e+01, -1.8494e-01, -6.4159e+00,  9.0931e+00, -1.0758e+00,\n",
            "           5.5964e+01]],\n",
            "\n",
            "        [[ 2.0615e+01,  7.8851e+00,  9.0625e+00,  4.7386e+01,  3.2970e+00,\n",
            "           7.2574e+01],\n",
            "         [ 6.3212e+00,  1.5717e+00,  4.0396e+00,  1.4901e+01, -1.4477e+00,\n",
            "           3.4062e+01],\n",
            "         [ 1.9898e+01, -3.3595e+00,  8.5853e+00,  1.5502e+01, -4.6995e+00,\n",
            "           2.4063e+01],\n",
            "         [ 5.8281e+00,  3.6961e+00,  3.5887e+00,  2.6888e+01,  8.0183e+00,\n",
            "           1.1797e+01],\n",
            "         [ 1.8403e+01, -3.2530e+00, -3.2358e+00,  1.3122e+01,  1.4952e+00,\n",
            "           2.5935e+01],\n",
            "         [ 5.0162e+01,  6.2401e+00,  1.9095e+01,  1.1384e+01,  5.6771e+00,\n",
            "           2.2827e+01],\n",
            "         [ 1.2673e+01,  6.8169e+00, -3.4417e+00,  3.0219e+01, -1.3004e+01,\n",
            "           3.4825e+01],\n",
            "         [ 3.0378e+01, -1.1903e-01, -1.1139e+01,  1.3092e+01, -2.1981e+00,\n",
            "           2.8365e+01],\n",
            "         [ 3.4957e+01,  5.1006e-02, -6.2417e+00,  2.2685e+01,  5.9738e+00,\n",
            "           1.9625e+01],\n",
            "         [ 2.0760e+01, -3.5201e+00,  2.2583e+00,  1.6366e+01, -4.0267e+00,\n",
            "           1.6510e+01]]]) tensor([[-55.2096, -43.3318, -39.5128, -39.2089, -45.9522, -40.3156, -47.9178,\n",
            "         -40.3174, -50.5721, -45.5845],\n",
            "        [-41.4809, -52.9116, -41.5160, -41.8868, -47.5863, -43.4156, -40.5453,\n",
            "         -40.7182, -41.9871, -41.5476],\n",
            "        [-45.8601, -40.2660, -41.2400, -40.1734, -41.1839, -48.5800, -39.0118,\n",
            "         -42.6248, -43.3315, -41.4762]])\n",
            "100% 1/1 [00:00<00:00, 20.95it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create lattice_params_stats.yaml"
      ],
      "metadata": {
        "id": "b4KcshWPqYuX"
      },
      "id": "b4KcshWPqYuX"
    },
    {
      "cell_type": "code",
      "source": [
        "!rm /content/flowmm/src/flowmm/rfm/manifolds/lattice_params_stats.yaml"
      ],
      "metadata": {
        "id": "ER9tCF56qhQ3",
        "outputId": "54f358df-6215-4d70-9db4-355409b7b83e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "ER9tCF56qhQ3",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove '/content/flowmm/src/flowmm/rfm/manifolds/lattice_params_stats.yaml': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/flowmm\n",
        "!bash create_env_file.sh && \\\n",
        " echo \"successfully ran create_env_file.sh\" && \\\n",
        " HYDRA_FULL_ERROR=1 \\\n",
        " conda run -p /usr/local/envs/flowmm_env --live-stream \\\n",
        "    python -u -m flowmm.rfm.manifolds.lattice_params"
      ],
      "metadata": {
        "id": "mH7tDlGTqbx-",
        "outputId": "1fa7a621-60d1-47ca-ac73-d609d0d6becd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "mH7tDlGTqbx-",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/flowmm\n",
            "successfully ran create_env_file.sh\n",
            "calculate the stats of p(L) for each dataset\n",
            "dataset='supercon': 100% 1/1 [00:05<00:00,  5.94s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create the required affine stats YAML for the dataset"
      ],
      "metadata": {
        "id": "nuaxNOR5FTF8"
      },
      "id": "nuaxNOR5FTF8"
    },
    {
      "cell_type": "code",
      "source": [
        "%rm /content/flowmm/src/flowmm/model/stats_supercon*"
      ],
      "metadata": {
        "id": "GflTiCivR1OV"
      },
      "id": "GflTiCivR1OV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/flowmm\n",
        "!bash create_env_file.sh && \\\n",
        " echo \"successfully ran create_env_file.sh\" && \\\n",
        " HYDRA_FULL_ERROR=1 \\\n",
        " conda run -p /usr/local/envs/flowmm_env --live-stream \\\n",
        "    python -u -m flowmm.model.standardize \\\n",
        "                 data=supercon"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hbr5_rFN8vyq",
        "outputId": "9144592d-d6f4-4647-a0b6-b1a50417e5bd"
      },
      "id": "hbr5_rFN8vyq",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/flowmm\n",
            "successfully ran create_env_file.sh\n",
            "  0% 0/1 [00:00<?, ?it/s]\n",
            "  0% 0/5 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[Aaspa_x_t.mean=tensor([0.4896, 0.4749, 0.5241]), aspa_x_t.std=tensor([0.2866, 0.2889, 0.2988]); aspa_u_t.mean=tensor([ 1.2164e-09, -3.0411e-09,  2.4328e-09]), aspa_u_t.std=tensor([0.2657, 0.2508, 0.2319])\n",
            "\n",
            "\n",
            "100% 1/1 [00:00<00:00,  3.06it/s]\n",
            "\n",
            " 20% 1/5 [00:00<00:01,  3.05it/s]\u001b[A\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[Aaspa_x_t.mean=tensor([0.4803, 0.4913, 0.5013]), aspa_x_t.std=tensor([0.2847, 0.2934, 0.2946]); aspa_u_t.mean=tensor([ 0.0000e+00, -1.5205e-10, -2.2808e-10]), aspa_u_t.std=tensor([0.2560, 0.2511, 0.2397])\n",
            "\n",
            "\n",
            "100% 1/1 [00:00<00:00,  7.86it/s]\n",
            "\n",
            " 40% 2/5 [00:00<00:00,  4.76it/s]\u001b[A\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[Aaspa_x_t.mean=tensor([0.5014, 0.4997, 0.4981]), aspa_x_t.std=tensor([0.2859, 0.2897, 0.2913]); aspa_u_t.mean=tensor([ 0.0000e+00, -5.0684e-10,  6.5889e-10]), aspa_u_t.std=tensor([0.2556, 0.2516, 0.2459])\n",
            "100% 1/1 [00:00<00:00,  8.90it/s]\n",
            "\n",
            " 60% 3/5 [00:00<00:00,  6.03it/s]\u001b[A\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[Aaspa_x_t.mean=tensor([0.4941, 0.4966, 0.4997]), aspa_x_t.std=tensor([0.2826, 0.2916, 0.2900]); aspa_u_t.mean=tensor([ 3.0411e-10, -6.8424e-10,  4.9417e-10]), aspa_u_t.std=tensor([0.2623, 0.2527, 0.2473])\n",
            "\n",
            "\n",
            "100% 1/1 [00:00<00:00,  1.76it/s]\n",
            "\n",
            " 80% 4/5 [00:01<00:00,  3.08it/s]\u001b[A\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[Aaspa_x_t.mean=tensor([0.4989, 0.4976, 0.5022]), aspa_x_t.std=tensor([0.2846, 0.2932, 0.2930]); aspa_u_t.mean=tensor([-8.5149e-10,  2.4328e-10,  3.9534e-10]), aspa_u_t.std=tensor([0.2599, 0.2592, 0.2537])\n",
            "\n",
            "\n",
            "100% 1/1 [00:00<00:00,  8.04it/s]\n",
            "\n",
            "100% 5/5 [00:01<00:00,  3.96it/s]\n",
            "\n",
            "  0% 0/5 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[Aaspa_x_t.mean=tensor([0.4979, 0.5457, 0.5725]), aspa_x_t.std=tensor([0.3550, 0.3478, 0.3512]); aspa_u_t.mean=tensor([ 3.6493e-09,  1.2164e-09, -3.0411e-09]), aspa_u_t.std=tensor([0.2871, 0.2844, 0.2824])\n",
            "\n",
            "\n",
            "100% 1/1 [00:00<00:00,  7.90it/s]\n",
            "\n",
            " 20% 1/5 [00:00<00:00,  7.87it/s]\u001b[A\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[Aaspa_x_t.mean=tensor([0.4827, 0.5405, 0.5197]), aspa_x_t.std=tensor([0.3582, 0.3558, 0.3666]); aspa_u_t.mean=tensor([1.6726e-09, 9.1232e-10, 9.1232e-10]), aspa_u_t.std=tensor([0.2770, 0.2797, 0.2785])\n",
            "\n",
            "\n",
            "100% 1/1 [00:00<00:00,  6.60it/s]\n",
            "\n",
            " 40% 2/5 [00:00<00:00,  7.02it/s]\u001b[A\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[Aaspa_x_t.mean=tensor([0.4882, 0.5124, 0.5067]), aspa_x_t.std=tensor([0.3624, 0.3654, 0.3704]); aspa_u_t.mean=tensor([-5.0684e-10,  0.0000e+00, -2.0274e-10]), aspa_u_t.std=tensor([0.2702, 0.2825, 0.2767])\n",
            "\n",
            "\n",
            "100% 1/1 [00:00<00:00,  8.10it/s]\n",
            "\n",
            " 60% 3/5 [00:00<00:00,  7.44it/s]\u001b[A\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[Aaspa_x_t.mean=tensor([0.4696, 0.5103, 0.5053]), aspa_x_t.std=tensor([0.3606, 0.3651, 0.3698]); aspa_u_t.mean=tensor([-6.8424e-10,  9.1232e-10,  1.6726e-09]), aspa_u_t.std=tensor([0.2700, 0.2794, 0.2780])\n",
            "\n",
            "\n",
            "100% 1/1 [00:00<00:00,  7.52it/s]\n",
            "\n",
            " 80% 4/5 [00:00<00:00,  7.46it/s]\u001b[A\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[Aaspa_x_t.mean=tensor([0.4810, 0.5192, 0.4971]), aspa_x_t.std=tensor([0.3644, 0.3673, 0.3717]); aspa_u_t.mean=tensor([-6.0821e-11,  6.0821e-10,  1.1556e-09]), aspa_u_t.std=tensor([0.2738, 0.2778, 0.2748])\n",
            "\n",
            "\n",
            "100% 1/1 [00:00<00:00,  7.87it/s]\n",
            "\n",
            "100% 5/5 [00:00<00:00,  7.50it/s]\n",
            "\n",
            "  0% 0/5 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[Aaspa_x_t.mean=tensor([0.4258, 0.4432, 0.4494]), aspa_x_t.std=tensor([0.3218, 0.3205, 0.3114]); aspa_u_t.mean=tensor([1.2164e-09, 0.0000e+00, 1.2164e-09]), aspa_u_t.std=tensor([0.2434, 0.2386, 0.2327])\n",
            "\n",
            "\n",
            "100% 1/1 [00:00<00:00,  7.51it/s]\n",
            "\n",
            " 20% 1/5 [00:00<00:00,  7.48it/s]\u001b[A\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[Aaspa_x_t.mean=tensor([0.4365, 0.4389, 0.4488]), aspa_x_t.std=tensor([0.3196, 0.3222, 0.3220]); aspa_u_t.mean=tensor([1.2164e-09, 1.2164e-09, 6.0821e-10]), aspa_u_t.std=tensor([0.2379, 0.2239, 0.2395])\n",
            "\n",
            "\n",
            "100% 1/1 [00:00<00:00,  6.89it/s]\n",
            "\n",
            " 40% 2/5 [00:00<00:00,  7.08it/s]\u001b[A\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[Aaspa_x_t.mean=tensor([0.4222, 0.4320, 0.4395]), aspa_x_t.std=tensor([0.3208, 0.3200, 0.3149]); aspa_u_t.mean=tensor([7.0958e-10, 1.2164e-09, 4.0547e-10]), aspa_u_t.std=tensor([0.2353, 0.2231, 0.2402])\n",
            "\n",
            "\n",
            "100% 1/1 [00:00<00:00,  7.75it/s]\n",
            "\n",
            " 60% 3/5 [00:00<00:00,  7.35it/s]\u001b[A\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[Aaspa_x_t.mean=tensor([0.4190, 0.4318, 0.4369]), aspa_x_t.std=tensor([0.3179, 0.3167, 0.3133]); aspa_u_t.mean=tensor([-6.8424e-10,  1.3685e-09,  6.0821e-10]), aspa_u_t.std=tensor([0.2349, 0.2217, 0.2404])\n",
            "\n",
            "\n",
            "100% 1/1 [00:00<00:00,  7.86it/s]\n",
            "\n",
            " 80% 4/5 [00:00<00:00,  7.53it/s]\u001b[A\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[Aaspa_x_t.mean=tensor([0.4277, 0.4351, 0.4344]), aspa_x_t.std=tensor([0.3234, 0.3204, 0.3150]); aspa_u_t.mean=tensor([-5.4739e-10,  1.0948e-09,  7.2985e-10]), aspa_u_t.std=tensor([0.2324, 0.2233, 0.2336])\n",
            "\n",
            "\n",
            "100% 1/1 [00:00<00:00,  7.44it/s]\n",
            "\n",
            "100% 5/5 [00:00<00:00,  7.42it/s]\n",
            "\n",
            "  0% 0/5 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[Aaspa_x_t.mean=tensor([0.3789, 0.3443, 0.3617]), aspa_x_t.std=tensor([0.3297, 0.3262, 0.3638]); aspa_u_t.mean=tensor([0.0000e+00, 9.1232e-10, 2.4328e-09]), aspa_u_t.std=tensor([0.2704, 0.2461, 0.2886])\n",
            "\n",
            "\n",
            "100% 1/1 [00:00<00:00,  7.50it/s]\n",
            "\n",
            " 20% 1/5 [00:00<00:00,  7.46it/s]\u001b[A\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[Aaspa_x_t.mean=tensor([0.3761, 0.3661, 0.3967]), aspa_x_t.std=tensor([0.3377, 0.3372, 0.3608]); aspa_u_t.mean=tensor([-3.0411e-10,  3.8013e-10,  2.4328e-09]), aspa_u_t.std=tensor([0.2607, 0.2556, 0.2828])\n",
            "\n",
            "\n",
            "100% 1/1 [00:00<00:00,  7.93it/s]\n",
            "\n",
            " 40% 2/5 [00:00<00:00,  7.70it/s]\u001b[A\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[Aaspa_x_t.mean=tensor([0.3827, 0.3680, 0.3944]), aspa_x_t.std=tensor([0.3437, 0.3384, 0.3584]); aspa_u_t.mean=tensor([ 2.0274e-10, -3.5479e-10,  3.6493e-09]), aspa_u_t.std=tensor([0.2705, 0.2579, 0.2791])\n",
            "\n",
            "\n",
            "100% 1/1 [00:00<00:00,  7.74it/s]\n",
            "\n",
            " 60% 3/5 [00:00<00:00,  7.70it/s]\u001b[A\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[Aaspa_x_t.mean=tensor([0.3876, 0.3751, 0.4030]), aspa_x_t.std=tensor([0.3490, 0.3387, 0.3596]); aspa_u_t.mean=tensor([-1.1404e-10,  3.4212e-10,  3.3452e-09]), aspa_u_t.std=tensor([0.2709, 0.2606, 0.2741])\n",
            "\n",
            "\n",
            "100% 1/1 [00:00<00:00,  6.48it/s]\n",
            "\n",
            " 80% 4/5 [00:00<00:00,  7.15it/s]\u001b[A\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[Aaspa_x_t.mean=tensor([0.3905, 0.3904, 0.4062]), aspa_x_t.std=tensor([0.3534, 0.3480, 0.3616]); aspa_u_t.mean=tensor([5.1698e-10, 3.9534e-10, 2.4328e-09]), aspa_u_t.std=tensor([0.2698, 0.2650, 0.2703])\n",
            "\n",
            "\n",
            "100% 1/1 [00:00<00:00,  7.74it/s]\n",
            "\n",
            "100% 5/5 [00:00<00:00,  7.39it/s]\n",
            "\n",
            "  0% 0/5 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A/content/flowmm/remote/riemannian-fm/manifm/manifolds/spd.py:261: UserWarning: There is a performance drop because we have not yet implemented the batching rule for aten::linalg_eigh. Please file us an issue on GitHub so that we can prioritize its implementation. (Triggered internally at /opt/conda/conda-bld/pytorch_1695392022560/work/aten/src/ATen/functorch/BatchedFallback.cpp:82.)\n",
            "  L, Q = torch.linalg.eigh(A)\n",
            "/content/flowmm/remote/riemannian-fm/manifm/manifolds/spd.py:162: UserWarning: There is a performance drop because we have not yet implemented the batching rule for aten::linalg_eigh. Please file us an issue on GitHub so that we can prioritize its implementation. (Triggered internally at /opt/conda/conda-bld/pytorch_1695392022560/work/aten/src/ATen/functorch/BatchedFallback.cpp:82.)\n",
            "  L, Q = torch.linalg.eigh(A)\n",
            "aspa_x_t.mean=tensor([16.2011,  0.3353,  1.2148, 15.9234,  1.0316, 21.3960]), aspa_x_t.std=tensor([ 6.2588,  1.5299,  3.6410,  6.0936,  3.1225, 10.0108]); aspa_u_t.mean=tensor([-0.8860,  1.3442,  4.2068, -1.4244,  1.5586, 14.9329]), aspa_u_t.std=tensor([ 7.0369,  3.9988,  7.2285,  6.0912,  5.3172, 22.2765])\n",
            "\n",
            "\n",
            "100% 1/1 [00:00<00:00,  6.68it/s]\n",
            "\n",
            " 20% 1/5 [00:00<00:00,  6.66it/s]\u001b[A\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[Aaspa_x_t.mean=tensor([16.2841,  0.6081,  1.5586, 15.9958,  1.1641, 23.4439]), aspa_x_t.std=tensor([ 6.4270,  2.1667,  4.2767,  6.5489,  3.4352, 15.7682]); aspa_u_t.mean=tensor([-0.8444,  0.9317,  3.7843, -1.2046,  1.7441, 15.2674]), aspa_u_t.std=tensor([ 6.8496,  3.9316,  6.9862,  6.3464,  5.2258, 22.6002])\n",
            "\n",
            "\n",
            "100% 1/1 [00:00<00:00,  7.54it/s]\n",
            "\n",
            " 40% 2/5 [00:00<00:00,  7.13it/s]\u001b[A\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[Aaspa_x_t.mean=tensor([16.0099,  0.4672,  1.4399, 15.6255,  0.8204, 22.6292]), aspa_x_t.std=tensor([ 6.2572,  1.9476,  3.8140,  6.4441,  3.1789, 13.9535]); aspa_u_t.mean=tensor([-0.8562,  1.1090,  3.7694, -1.1677,  1.9583, 15.3175]), aspa_u_t.std=tensor([ 7.0649,  3.9132,  6.8491,  6.1475,  5.2828, 22.3823])\n",
            "\n",
            "\n",
            "100% 1/1 [00:00<00:00,  8.06it/s]\n",
            "\n",
            " 60% 3/5 [00:00<00:00,  7.51it/s]\u001b[A\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[Aaspa_x_t.mean=tensor([15.9352,  0.4986,  1.4715, 15.5155,  0.7923, 22.8686]), aspa_x_t.std=tensor([ 6.2860,  1.9608,  3.7935,  6.4166,  3.2210, 14.0272]); aspa_u_t.mean=tensor([-0.8060,  0.9513,  3.5675, -1.1891,  1.9045, 15.2204]), aspa_u_t.std=tensor([ 7.0257,  4.0620,  6.8816,  5.8640,  5.2470, 22.3221])\n",
            "\n",
            "\n",
            "100% 1/1 [00:00<00:00,  6.73it/s]\n",
            "\n",
            " 80% 4/5 [00:00<00:00,  7.16it/s]\u001b[A\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[Aaspa_x_t.mean=tensor([15.7070,  0.5215,  1.4082, 15.3738,  0.7848, 22.6080]), aspa_x_t.std=tensor([ 6.1869,  1.8687,  3.4774,  6.3012,  3.0919, 13.5218]); aspa_u_t.mean=tensor([-0.5866,  0.7850,  3.4619, -1.0509,  1.8750, 15.1880]), aspa_u_t.std=tensor([ 6.9882,  3.9740,  7.0643,  5.8642,  5.1596, 22.1482])\n",
            "\n",
            "\n",
            "100% 1/1 [00:00<00:00,  7.72it/s]\n",
            "\n",
            "100% 5/5 [00:00<00:00,  7.26it/s]\n",
            "\n",
            "  0% 0/5 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A/content/flowmm/remote/riemannian-fm/manifm/manifolds/spd.py:261: UserWarning: There is a performance drop because we have not yet implemented the batching rule for aten::linalg_eigh. Please file us an issue on GitHub so that we can prioritize its implementation. (Triggered internally at /opt/conda/conda-bld/pytorch_1695392022560/work/aten/src/ATen/functorch/BatchedFallback.cpp:82.)\n",
            "  L, Q = torch.linalg.eigh(A)\n",
            "/content/flowmm/remote/riemannian-fm/manifm/manifolds/spd.py:162: UserWarning: There is a performance drop because we have not yet implemented the batching rule for aten::linalg_eigh. Please file us an issue on GitHub so that we can prioritize its implementation. (Triggered internally at /opt/conda/conda-bld/pytorch_1695392022560/work/aten/src/ATen/functorch/BatchedFallback.cpp:82.)\n",
            "  L, Q = torch.linalg.eigh(A)\n",
            "aspa_x_t.mean=tensor([ 1.5634e+01, -1.0390e-03,  1.4231e+00,  1.5171e+01,  4.9905e-01,\n",
            "         2.2195e+01]), aspa_x_t.std=tensor([ 6.3635,  1.9882,  2.9651,  6.2466,  2.3960, 13.2706]); aspa_u_t.mean=tensor([-1.5381,  0.9002,  2.2448, -1.6316,  1.7810, 15.3084]), aspa_u_t.std=tensor([ 7.2278,  4.0206,  5.8178,  6.5299,  4.5949, 29.1938])\n",
            "\n",
            "\n",
            "100% 1/1 [00:00<00:00,  6.79it/s]\n",
            "\n",
            " 20% 1/5 [00:00<00:00,  6.76it/s]\u001b[A\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[Aaspa_x_t.mean=tensor([15.4256,  0.0407,  1.1803, 15.2940,  0.6637, 21.5645]), aspa_x_t.std=tensor([ 5.8898,  1.8515,  2.8005,  6.1253,  2.0807, 11.7658]); aspa_u_t.mean=tensor([-0.8644,  0.8740,  2.9619, -1.8361,  1.7760, 14.2186]), aspa_u_t.std=tensor([ 6.3642,  3.7308,  6.1065,  5.9912,  4.9301, 24.2933])\n",
            "\n",
            "\n",
            "100% 1/1 [00:00<00:00,  6.33it/s]\n",
            "\n",
            " 40% 2/5 [00:00<00:00,  6.48it/s]\u001b[A\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[Aaspa_x_t.mean=tensor([15.1831, -0.1646,  0.9123, 15.1585,  0.5908, 22.2312]), aspa_x_t.std=tensor([ 5.7859,  1.9119,  2.6228,  6.2766,  2.0226, 14.7675]); aspa_u_t.mean=tensor([-0.7100,  1.0436,  2.8638, -1.7173,  1.5045, 15.4289]), aspa_u_t.std=tensor([ 6.1119,  3.6335,  5.9177,  5.3766,  4.6092, 29.2082])\n",
            "\n",
            "\n",
            "100% 1/1 [00:00<00:00,  7.05it/s]\n",
            "\n",
            " 60% 3/5 [00:00<00:00,  6.71it/s]\u001b[A\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[Aaspa_x_t.mean=tensor([15.4240, -0.0521,  1.1416, 15.2002,  0.6664, 22.6947]), aspa_x_t.std=tensor([ 5.9720,  2.2120,  3.0387,  6.3308,  2.3328, 15.4646]); aspa_u_t.mean=tensor([-0.7206,  1.3189,  3.1011, -1.5323,  1.8717, 16.3181]), aspa_u_t.std=tensor([ 6.4637,  3.9773,  6.4023,  6.0476,  5.4070, 31.1089])\n",
            "\n",
            "\n",
            "100% 1/1 [00:00<00:00,  6.34it/s]\n",
            "\n",
            " 80% 4/5 [00:00<00:00,  6.54it/s]\u001b[A\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[Aaspa_x_t.mean=tensor([15.4812,  0.0858,  1.1673, 15.2354,  0.7119, 22.4966]), aspa_x_t.std=tensor([ 6.0770,  2.0962,  3.0203,  6.4447,  2.3565, 14.4558]); aspa_u_t.mean=tensor([-0.6850,  1.1247,  3.1805, -1.5522,  1.9311, 15.6751]), aspa_u_t.std=tensor([ 6.6255,  4.0715,  6.7001,  5.9248,  5.7324, 29.1446])\n",
            "\n",
            "\n",
            "100% 1/1 [00:00<00:00,  7.06it/s]\n",
            "\n",
            "100% 5/5 [00:00<00:00,  6.66it/s]\n",
            "\n",
            "  0% 0/5 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[Aaspa_x_t.mean=tensor([ 3.9778,  4.0078,  4.8930, -0.7152, -0.8152, -0.7132]), aspa_x_t.std=tensor([0.8566, 0.8561, 1.3278, 2.4227, 1.8297, 1.9457]); aspa_u_t.mean=tensor([ 0.1029, -0.0484,  0.0278, -1.5620, -2.0708, -1.6820]), aspa_u_t.std=tensor([1.2991, 1.5439, 2.2513, 3.4425, 3.2525, 3.7894])\n",
            "\n",
            "\n",
            "100% 1/1 [00:00<00:00,  6.84it/s]\n",
            "\n",
            " 20% 1/5 [00:00<00:00,  6.81it/s]\u001b[A\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[Aaspa_x_t.mean=tensor([ 4.0175,  4.1306,  5.0677, -0.5493, -0.7966, -0.6322]), aspa_x_t.std=tensor([0.7889, 0.7585, 1.4321, 2.4524, 2.0061, 2.0243]); aspa_u_t.mean=tensor([-0.0025, -0.2052, -0.3093, -1.6529, -1.9520, -1.6377]), aspa_u_t.std=tensor([1.4069, 1.6910, 2.2488, 3.4658, 3.0185, 3.7624])\n",
            "\n",
            "\n",
            "100% 1/1 [00:00<00:00,  6.55it/s]\n",
            "\n",
            " 40% 2/5 [00:00<00:00,  6.64it/s]\u001b[A\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[Aaspa_x_t.mean=tensor([ 3.9774,  4.0274,  4.8807, -0.4910, -0.8675, -0.7494]), aspa_x_t.std=tensor([0.7495, 0.7650, 1.3275, 2.3817, 2.0224, 2.0629]); aspa_u_t.mean=tensor([-0.0358, -0.1014, -0.0156, -1.8119, -1.8881, -1.6699]), aspa_u_t.std=tensor([1.4251, 1.7374, 2.4228, 3.6206, 3.0917, 3.6318])\n",
            "\n",
            "\n",
            "100% 1/1 [00:00<00:00,  7.66it/s]\n",
            "\n",
            " 60% 3/5 [00:00<00:00,  7.05it/s]\u001b[A\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[Aaspa_x_t.mean=tensor([ 4.0129,  4.0584,  4.8696, -0.5480, -0.9458, -0.7736]), aspa_x_t.std=tensor([0.7942, 0.7769, 1.3843, 2.3620, 1.9512, 1.9914]); aspa_u_t.mean=tensor([-0.0974, -0.1412,  0.1555, -1.7476, -1.7563, -1.6153]), aspa_u_t.std=tensor([1.4656, 1.6049, 2.4768, 3.5265, 3.1087, 3.5256])\n",
            "\n",
            "\n",
            "100% 1/1 [00:00<00:00,  7.55it/s]\n",
            "\n",
            " 80% 4/5 [00:00<00:00,  7.23it/s]\u001b[A\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[Aaspa_x_t.mean=tensor([ 4.0095,  4.0141,  4.9100, -0.6238, -0.9382, -0.7645]), aspa_x_t.std=tensor([0.7887, 0.7598, 1.3798, 2.3703, 1.9154, 2.0396]); aspa_u_t.mean=tensor([-0.1063, -0.0302,  0.1115, -1.6162, -1.8413, -1.7909]), aspa_u_t.std=tensor([1.4052, 1.5844, 2.6713, 3.6883, 3.3007, 3.4751])\n",
            "\n",
            "\n",
            "100% 1/1 [00:00<00:00,  6.99it/s]\n",
            "\n",
            "100% 5/5 [00:00<00:00,  7.06it/s]\n",
            "\n",
            "  0% 0/5 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[Aaspa_x_t.mean=tensor([ 2.2632,  2.1546,  2.5594, 42.7508, 41.9004, 42.4580]), aspa_x_t.std=tensor([ 1.3403,  1.4363,  1.5407, 23.8876, 21.6917, 22.6409]); aspa_u_t.mean=tensor([ 3.6525,  4.0407,  4.9327, 84.0173, 81.6277, 83.5252]), aspa_u_t.std=tensor([ 1.2241,  1.4506,  2.4087, 17.3092, 15.5189, 17.9041])\n",
            "\n",
            "\n",
            "100% 1/1 [00:00<00:00,  7.74it/s]\n",
            "\n",
            " 20% 1/5 [00:00<00:00,  7.71it/s]\u001b[A\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[Aaspa_x_t.mean=tensor([ 2.0855,  2.0072,  2.5622, 42.3068, 41.2095, 41.9308]), aspa_x_t.std=tensor([ 1.2217,  1.4307,  1.7854, 26.4259, 23.9323, 24.8218]); aspa_u_t.mean=tensor([ 3.7219,  4.0295,  4.9039, 83.8112, 81.6722, 83.3775]), aspa_u_t.std=tensor([ 1.1892,  1.3618,  2.2844, 17.2254, 15.2137, 17.3891])\n",
            "\n",
            "\n",
            "100% 1/1 [00:00<00:00,  7.33it/s]\n",
            "\n",
            " 40% 2/5 [00:00<00:00,  7.45it/s]\u001b[A\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[Aaspa_x_t.mean=tensor([ 1.9028,  1.9525,  2.4554, 40.3277, 39.1464, 40.1047]), aspa_x_t.std=tensor([ 1.4497,  1.5524,  1.9759, 25.5931, 23.4816, 24.9362]); aspa_u_t.mean=tensor([ 3.9213,  4.0406,  4.9319, 83.7217, 81.8843, 83.4118]), aspa_u_t.std=tensor([ 1.3202,  1.3229,  2.2159, 17.1250, 15.2256, 17.2222])\n",
            "\n",
            "\n",
            "100% 1/1 [00:00<00:00,  8.18it/s]\n",
            "\n",
            " 60% 3/5 [00:00<00:00,  7.75it/s]\u001b[A\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[Aaspa_x_t.mean=tensor([ 2.0505,  2.0913,  2.6182, 43.8624, 42.5752, 43.3946]), aspa_x_t.std=tensor([ 1.3643,  1.4456,  1.8141, 26.1967, 24.0588, 24.9710]); aspa_u_t.mean=tensor([ 3.9042,  4.0263,  4.8505, 83.6396, 81.9471, 83.4167]), aspa_u_t.std=tensor([ 1.3049,  1.3227,  2.1401, 17.1140, 15.1621, 17.0858])\n",
            "\n",
            "\n",
            "100% 1/1 [00:00<00:00,  7.00it/s]\n",
            "\n",
            " 80% 4/5 [00:00<00:00,  7.41it/s]\u001b[A\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[Aaspa_x_t.mean=tensor([ 2.0167,  2.0262,  2.5525, 43.4839, 42.1746, 42.8986]), aspa_x_t.std=tensor([ 1.3657,  1.4876,  1.7692, 27.1829, 25.1595, 25.7987]); aspa_u_t.mean=tensor([ 3.9309,  4.0575,  4.8890, 83.6338, 81.9975, 83.4313]), aspa_u_t.std=tensor([ 1.3680,  1.3650,  2.1171, 17.1086, 15.1444, 16.9896])\n",
            "\n",
            "\n",
            "100% 1/1 [00:00<00:00,  7.45it/s]\n",
            "\n",
            "100% 5/5 [00:00<00:00,  7.47it/s]\n",
            "100% 1/1 [00:08<00:00,  8.73s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (4) TRAINING\n",
        "# Manifolds\n",
        "\n",
        "\n",
        "- FlowMM allows the user to select a variety of manifolds via the keyword argument   \n",
        "`model={atom_type_manifold}_{lattice_manifold}`  \n",
        "when using `scripts_model/run.py`.  \n",
        "\n",
        "- Atom type manifolds and lattice type manifolds can be found in `scripts_model/conf/model`."
      ],
      "metadata": {
        "id": "G7RtzMrfZ16h"
      },
      "id": "G7RtzMrfZ16h"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Unconditional Training"
      ],
      "metadata": {
        "id": "k2NUXjT_A718"
      },
      "id": "k2NUXjT_A718"
    },
    {
      "cell_type": "code",
      "source": [
        "%pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "5kk4YLU2Qyky",
        "outputId": "382f3b70-2c7e-40b7-e967-e548abfddc1b"
      },
      "id": "5kk4YLU2Qyky",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/flowmm'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/flowmm\n",
        "!bash create_env_file.sh && \\\n",
        "  HYDRA_FULL_ERROR=1 \\\n",
        "  WANDB_MODE=disabled \\\n",
        "  conda run -p /usr/local/envs/flowmm_env \\\n",
        "    python -u -m scripts_model.run \\\n",
        "      data=supercon \\\n",
        "      model=abits_params \\\n",
        "      train.pl_trainer.accelerator=cpu \\\n",
        "      train.pl_trainer.devices=1 \\\n",
        "      train.model_checkpoints.save_last=True \\\n",
        "      logging.val_check_interval=1  \\\n",
        "      train.pl_trainer.max_epochs=1"
      ],
      "metadata": {
        "collapsed": true,
        "id": "HzvxQufsW02F",
        "outputId": "6fd363ca-2fe5-43b9-d0d0-aaa68f37cb70",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "HzvxQufsW02F",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/flowmm\n",
            "[2025-05-30 19:49:50,792][hydra.utils][INFO] - Hydra Directory is /content/flowmm/runs/trash/2025-05-30/19-49-50/abits_params-rfm_cspnet-sr7kny01\n",
            "[2025-05-30 19:49:50,792][hydra.utils][INFO] - Instantiating <diffcsp.pl_data.datamodule.CrystDataModule>\n",
            "[2025-05-30 19:49:50,835][hydra.utils][INFO] - Instantiating <<class 'flowmm.model.model_pl.MaterialsRFMLitModule'>>\n",
            "[2025-05-30 19:49:51,055][hydra.utils][INFO] - Adding callback <ModelCheckpoint>\n",
            "[2025-05-30 19:49:51,060][hydra.utils][INFO] - Adding callback <ModelCheckpoint> for every 100 epochs\n",
            "[2025-05-30 19:49:51,075][hydra.utils][INFO] - Instantiating the Trainer\n",
            "[2025-05-30 19:49:51,124][hydra.utils][INFO] - Starting training!\n",
            "\n",
            "Sanity Checking: 0it [00:00, ?it/s]\n",
            "Sanity Checking:   0%|          | 0/1 [00:00<?, ?it/s]\n",
            "Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n",
            "Sanity Checking DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  3.67it/s]\n",
            "                                                                           \n",
            "\n",
            "Training: 0it [00:00, ?it/s]\n",
            "Training:   0%|          | 0/4 [00:00<?, ?it/s]\n",
            "Epoch 0:   0%|          | 0/4 [00:00<?, ?it/s] \n",
            "Epoch 0:  25%|██▌       | 1/4 [00:00<00:02,  1.15it/s]\n",
            "Epoch 0:  25%|██▌       | 1/4 [00:00<00:02,  1.15it/s, loss=0.356]\n",
            "Epoch 0:  50%|█████     | 2/4 [00:01<00:01,  1.49it/s, loss=0.356]\n",
            "Epoch 0:  50%|█████     | 2/4 [00:01<00:01,  1.49it/s, loss=0.636]\n",
            "Epoch 0:  75%|███████▌  | 3/4 [00:01<00:00,  1.85it/s, loss=0.636]\n",
            "Epoch 0:  75%|███████▌  | 3/4 [00:01<00:00,  1.84it/s, loss=0.579]\n",
            "\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 13.52it/s]\u001b[A\n",
            "Epoch 0: 100%|██████████| 4/4 [00:01<00:00,  2.10it/s, loss=0.579]\n",
            "Epoch 0: 100%|██████████| 4/4 [00:01<00:00,  2.09it/s, loss=0.579, val/loss=0.341, val/loss_a=0.225, val/loss_f=0.0929, val/loss_l=0.023, val/loss_ce=0.000, val/unscaled/loss_a=2.480, val/unscaled/loss_f=0.102, val/unscaled/loss_l=10.10, val/unscaled/loss_ce=0.000, val/best/loss=0.341, val/best/loss_a=0.225, val/best/loss_f=0.0779, val/best/loss_l=0.023, val/best/loss_ce=0.000, val/best/unscaled/loss_a=2.480, val/best/unscaled/loss_f=0.0859, val/best/unscaled/loss_l=10.10, val/best/unscaled/loss_ce=0.000]\n",
            "\n",
            "                                                                      \u001b[A\n",
            "Epoch 0: 100%|██████████| 4/4 [00:01<00:00,  2.00it/s, loss=0.579, val/loss=0.341, val/loss_a=0.225, val/loss_f=0.0929, val/loss_l=0.023, val/loss_ce=0.000, val/unscaled/loss_a=2.480, val/unscaled/loss_f=0.102, val/unscaled/loss_l=10.10, val/unscaled/loss_ce=0.000, val/best/loss=0.341, val/best/loss_a=0.225, val/best/loss_f=0.0779, val/best/loss_l=0.023, val/best/loss_ce=0.000, val/best/unscaled/loss_a=2.480, val/best/unscaled/loss_f=0.0859, val/best/unscaled/loss_l=10.10, val/best/unscaled/loss_ce=0.000]\n",
            "Epoch 0: 100%|██████████| 4/4 [00:06<00:00,  1.73s/it, loss=0.579, val/loss=0.341, val/loss_a=0.225, val/loss_f=0.0929, val/loss_l=0.023, val/loss_ce=0.000, val/unscaled/loss_a=2.480, val/unscaled/loss_f=0.102, val/unscaled/loss_l=10.10, val/unscaled/loss_ce=0.000, val/best/loss=0.341, val/best/loss_a=0.225, val/best/loss_f=0.0779, val/best/loss_l=0.023, val/best/loss_ce=0.000, val/best/unscaled/loss_a=2.480, val/best/unscaled/loss_f=0.0859, val/best/unscaled/loss_l=10.10, val/best/unscaled/loss_ce=0.000]\n",
            "[2025-05-30 19:49:58,642][hydra.utils][INFO] - Starting testing!\n",
            "\n",
            "Testing: 0it [00:00, ?it/s]\n",
            "Testing:   0%|          | 0/1 [00:00<?, ?it/s]\n",
            "Testing DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n",
            "Testing DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n",
            "\n",
            "/usr/local/envs/flowmm_env/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
            "See https://hydra.cc/docs/next/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
            "  ret = run_job(\n",
            "Global seed set to 42\n",
            "GPU available: False, used: False\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "\n",
            "  | Name            | Type           | Params\n",
            "---------------------------------------------------\n",
            "0 | manifold_getter | ManifoldGetter | 0     \n",
            "1 | model           | EMA            | 28.3 M\n",
            "---------------------------------------------------\n",
            "14.1 M    Trainable params\n",
            "14.1 M    Non-trainable params\n",
            "28.3 M    Total params\n",
            "113.056   Total estimated model params size (MB)\n",
            "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
            "FIT Profiler Report\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "|  Action                                                                                                                                                                                                \t|  Mean duration (s)\t|  Num calls      \t|  Total time (s) \t|  Percentage %   \t|\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "|  Total                                                                                                                                                                                                 \t|  -              \t|  332            \t|  7.5445         \t|  100 %          \t|\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "|  [Callback]ModelCheckpoint{'monitor': 'val/loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None, 'save_on_train_epoch_end': True}.on_train_epoch_end       \t|  4.9029         \t|  1              \t|  4.9029         \t|  64.986         \t|\n",
            "|  run_training_epoch                                                                                                                                                                                    \t|  1.9897         \t|  1              \t|  1.9897         \t|  26.373         \t|\n",
            "|  run_training_batch                                                                                                                                                                                    \t|  0.49651        \t|  3              \t|  1.4895         \t|  19.743         \t|\n",
            "|  [LightningModule]MaterialsRFMLitModule.optimizer_step                                                                                                                                                 \t|  0.49569        \t|  3              \t|  1.4871         \t|  19.711         \t|\n",
            "|  [Strategy]SingleDeviceStrategy.backward                                                                                                                                                               \t|  0.14696        \t|  3              \t|  0.44087        \t|  5.8435         \t|\n",
            "|  [Strategy]SingleDeviceStrategy.training_step                                                                                                                                                          \t|  0.13606        \t|  3              \t|  0.40819        \t|  5.4104         \t|\n",
            "|  [Strategy]SingleDeviceStrategy.validation_step                                                                                                                                                        \t|  0.17151        \t|  2              \t|  0.34302        \t|  4.5467         \t|\n",
            "|  [LightningModule]MaterialsRFMLitModule.on_validation_model_train                                                                                                                                      \t|  0.070936       \t|  2              \t|  0.14187        \t|  1.8805         \t|\n",
            "|  [LightningModule]MaterialsRFMLitModule.on_validation_model_eval                                                                                                                                       \t|  0.065985       \t|  2              \t|  0.13197        \t|  1.7492         \t|\n",
            "|  [TrainingEpochLoop].train_dataloader_next                                                                                                                                                             \t|  0.033743       \t|  3              \t|  0.10123        \t|  1.3418         \t|\n",
            "|  [EvaluationEpochLoop].val_dataloader_idx_0_next                                                                                                                                                       \t|  0.054684       \t|  1              \t|  0.054684       \t|  0.72482        \t|\n",
            "|  [EvaluationEpochLoop].None_dataloader_idx_0_next                                                                                                                                                      \t|  0.04945        \t|  1              \t|  0.04945        \t|  0.65544        \t|\n",
            "|  [LightningModule]MaterialsRFMLitModule.configure_gradient_clipping                                                                                                                                    \t|  0.01321        \t|  3              \t|  0.03963        \t|  0.52528        \t|\n",
            "|  [LightningModule]MaterialsRFMLitModule.validation_epoch_end                                                                                                                                           \t|  0.0087281      \t|  2              \t|  0.017456       \t|  0.23138        \t|\n",
            "|  [LightningDataModule]CrystDataModule.setup                                                                                                                                                            \t|  0.014221       \t|  1              \t|  0.014221       \t|  0.18849        \t|\n",
            "|  [Strategy]SingleDeviceStrategy.batch_to_device                                                                                                                                                        \t|  0.0013079      \t|  5              \t|  0.0065394      \t|  0.086677       \t|\n",
            "|  [LightningModule]MaterialsRFMLitModule.transfer_batch_to_device                                                                                                                                       \t|  0.0011143      \t|  5              \t|  0.0055713      \t|  0.073846       \t|\n",
            "|  [LightningModule]MaterialsRFMLitModule.configure_optimizers                                                                                                                                           \t|  0.0046683      \t|  1              \t|  0.0046683      \t|  0.061877       \t|\n",
            "|  [Callback]ModelSummary.on_fit_start                                                                                                                                                                   \t|  0.0039981      \t|  1              \t|  0.0039981      \t|  0.052994       \t|\n",
            "|  [Callback]TQDMProgressBar.on_train_batch_end                                                                                                                                                          \t|  0.0012766      \t|  3              \t|  0.0038297      \t|  0.050762       \t|\n",
            "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 100, 'train_time_interval': None, 'save_on_train_epoch_end': True}.on_train_epoch_end           \t|  0.0025079      \t|  1              \t|  0.0025079      \t|  0.033241       \t|\n",
            "|  [Callback]TQDMProgressBar.on_validation_batch_start                                                                                                                                                   \t|  0.0011089      \t|  2              \t|  0.0022179      \t|  0.029397       \t|\n",
            "|  [LightningModule]MaterialsRFMLitModule.optimizer_zero_grad                                                                                                                                            \t|  0.00063244     \t|  3              \t|  0.0018973      \t|  0.025148       \t|\n",
            "|  [Callback]TQDMProgressBar.on_validation_end                                                                                                                                                           \t|  0.00088752     \t|  2              \t|  0.001775       \t|  0.023528       \t|\n",
            "|  [Callback]TQDMProgressBar.on_sanity_check_start                                                                                                                                                       \t|  0.0011882      \t|  1              \t|  0.0011882      \t|  0.015749       \t|\n",
            "|  [Callback]TQDMProgressBar.on_validation_batch_end                                                                                                                                                     \t|  0.00057591     \t|  2              \t|  0.0011518      \t|  0.015267       \t|\n",
            "|  [Callback]TQDMProgressBar.on_train_epoch_end                                                                                                                                                          \t|  0.0010947      \t|  1              \t|  0.0010947      \t|  0.01451        \t|\n",
            "|  [LightningModule]MaterialsRFMLitModule.training_epoch_end                                                                                                                                             \t|  0.00086302     \t|  1              \t|  0.00086302     \t|  0.011439       \t|\n",
            "|  [Callback]TQDMProgressBar.on_validation_start                                                                                                                                                         \t|  0.00030106     \t|  2              \t|  0.00060212     \t|  0.0079809      \t|\n",
            "|  [Callback]TQDMProgressBar.on_train_start                                                                                                                                                              \t|  0.00042528     \t|  1              \t|  0.00042528     \t|  0.005637       \t|\n",
            "|  [Callback]TQDMProgressBar.on_train_end                                                                                                                                                                \t|  0.00041712     \t|  1              \t|  0.00041712     \t|  0.0055288      \t|\n",
            "|  [Callback]TQDMProgressBar.on_train_epoch_start                                                                                                                                                        \t|  0.000362       \t|  1              \t|  0.000362       \t|  0.0047982      \t|\n",
            "|  [Callback]ModelCheckpoint{'monitor': 'val/loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None, 'save_on_train_epoch_end': True}.on_train_batch_end       \t|  9.5255e-05     \t|  3              \t|  0.00028576     \t|  0.0037877      \t|\n",
            "|  [Callback]ModelCheckpoint{'monitor': 'val/loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None, 'save_on_train_epoch_end': None}.setup                    \t|  0.00017903     \t|  1              \t|  0.00017903     \t|  0.0023729      \t|\n",
            "|  [Callback]ModelCheckpoint{'monitor': 'val/loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None, 'save_on_train_epoch_end': True}.on_validation_end        \t|  7.8484e-05     \t|  2              \t|  0.00015697     \t|  0.0020805      \t|\n",
            "|  [LightningModule]MaterialsRFMLitModule.lr_scheduler_step                                                                                                                                              \t|  0.00013823     \t|  1              \t|  0.00013823     \t|  0.0018322      \t|\n",
            "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 100, 'train_time_interval': None, 'save_on_train_epoch_end': True}.on_train_batch_end           \t|  1.9923e-05     \t|  3              \t|  5.977e-05      \t|  0.00079223     \t|\n",
            "|  [LightningModule]MaterialsRFMLitModule.on_before_batch_transfer                                                                                                                                       \t|  1.043e-05      \t|  5              \t|  5.2151e-05     \t|  0.00069124     \t|\n",
            "|  [Callback]ModelSummary.on_validation_batch_start                                                                                                                                                      \t|  1.8085e-05     \t|  2              \t|  3.617e-05      \t|  0.00047942     \t|\n",
            "|  [Callback]TQDMProgressBar.on_after_backward                                                                                                                                                           \t|  1.0184e-05     \t|  3              \t|  3.0553e-05     \t|  0.00040497     \t|\n",
            "|  [Callback]TQDMProgressBar.on_validation_epoch_end                                                                                                                                                     \t|  1.52e-05       \t|  2              \t|  3.04e-05       \t|  0.00040294     \t|\n",
            "|  [Callback]ModelSummary.on_validation_end                                                                                                                                                              \t|  1.4774e-05     \t|  2              \t|  2.9548e-05     \t|  0.00039165     \t|\n",
            "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 100, 'train_time_interval': None, 'save_on_train_epoch_end': True}.on_validation_end            \t|  1.432e-05      \t|  2              \t|  2.8641e-05     \t|  0.00037963     \t|\n",
            "|  [Callback]ModelSummary.on_train_batch_end                                                                                                                                                             \t|  9.533e-06      \t|  3              \t|  2.8599e-05     \t|  0.00037907     \t|\n",
            "|  [Callback]ModelSummary.on_validation_batch_end                                                                                                                                                        \t|  1.1747e-05     \t|  2              \t|  2.3494e-05     \t|  0.0003114      \t|\n",
            "|  [Callback]TQDMProgressBar.on_before_zero_grad                                                                                                                                                         \t|  7.7663e-06     \t|  3              \t|  2.3299e-05     \t|  0.00030882     \t|\n",
            "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 100, 'train_time_interval': None, 'save_on_train_epoch_end': None}.setup                        \t|  2.1684e-05     \t|  1              \t|  2.1684e-05     \t|  0.00028741     \t|\n",
            "|  [Callback]TQDMProgressBar.on_train_batch_start                                                                                                                                                        \t|  7.0767e-06     \t|  3              \t|  2.123e-05      \t|  0.0002814      \t|\n",
            "|  [Callback]TQDMProgressBar.on_before_backward                                                                                                                                                          \t|  6.5263e-06     \t|  3              \t|  1.9579e-05     \t|  0.00025951     \t|\n",
            "|  [Callback]ModelSummary.on_train_end                                                                                                                                                                   \t|  1.8648e-05     \t|  1              \t|  1.8648e-05     \t|  0.00024717     \t|\n",
            "|  [LightningModule]MaterialsRFMLitModule.validation_step_end                                                                                                                                            \t|  9.2705e-06     \t|  2              \t|  1.8541e-05     \t|  0.00024575     \t|\n",
            "|  [Callback]ModelSummary.on_train_start                                                                                                                                                                 \t|  1.802e-05      \t|  1              \t|  1.802e-05      \t|  0.00023885     \t|\n",
            "|  [Callback]ModelSummary.on_validation_start                                                                                                                                                            \t|  8.7305e-06     \t|  2              \t|  1.7461e-05     \t|  0.00023144     \t|\n",
            "|  [LightningModule]MaterialsRFMLitModule.on_validation_batch_start                                                                                                                                      \t|  8.714e-06      \t|  2              \t|  1.7428e-05     \t|  0.000231       \t|\n",
            "|  [LightningModule]MaterialsRFMLitModule.on_validation_end                                                                                                                                              \t|  8.7105e-06     \t|  2              \t|  1.7421e-05     \t|  0.00023091     \t|\n",
            "|  [Callback]TQDMProgressBar.setup                                                                                                                                                                       \t|  1.6524e-05     \t|  1              \t|  1.6524e-05     \t|  0.00021902     \t|\n",
            "|  [Strategy]SingleDeviceStrategy.on_validation_end                                                                                                                                                      \t|  7.7295e-06     \t|  2              \t|  1.5459e-05     \t|  0.0002049      \t|\n",
            "|  [Callback]GradientAccumulationScheduler.on_validation_batch_start                                                                                                                                     \t|  7.607e-06      \t|  2              \t|  1.5214e-05     \t|  0.00020166     \t|\n",
            "|  [Strategy]SingleDeviceStrategy.on_train_batch_start                                                                                                                                                   \t|  4.939e-06      \t|  3              \t|  1.4817e-05     \t|  0.00019639     \t|\n",
            "|  [LightningModule]MaterialsRFMLitModule.on_validation_start                                                                                                                                            \t|  6.8865e-06     \t|  2              \t|  1.3773e-05     \t|  0.00018256     \t|\n",
            "|  [Callback]TQDMProgressBar.on_sanity_check_end                                                                                                                                                         \t|  1.3692e-05     \t|  1              \t|  1.3692e-05     \t|  0.00018148     \t|\n",
            "|  [Callback]TQDMProgressBar.on_save_checkpoint                                                                                                                                                          \t|  6.4145e-06     \t|  2              \t|  1.2829e-05     \t|  0.00017004     \t|\n",
            "|  [LightningModule]MaterialsRFMLitModule.on_train_batch_start                                                                                                                                           \t|  4.0657e-06     \t|  3              \t|  1.2197e-05     \t|  0.00016167     \t|\n",
            "|  [Callback]TQDMProgressBar.on_validation_epoch_start                                                                                                                                                   \t|  5.902e-06      \t|  2              \t|  1.1804e-05     \t|  0.00015646     \t|\n",
            "|  [LightningModule]MaterialsRFMLitModule.on_after_batch_transfer                                                                                                                                        \t|  2.2628e-06     \t|  5              \t|  1.1314e-05     \t|  0.00014996     \t|\n",
            "|  [Callback]GradientAccumulationScheduler.on_fit_start                                                                                                                                                  \t|  1.0782e-05     \t|  1              \t|  1.0782e-05     \t|  0.00014291     \t|\n",
            "|  [LightningModule]MaterialsRFMLitModule.on_validation_batch_end                                                                                                                                        \t|  5.177e-06      \t|  2              \t|  1.0354e-05     \t|  0.00013724     \t|\n",
            "|  [LightningDataModule]CrystDataModule.state_dict                                                                                                                                                       \t|  5.115e-06      \t|  2              \t|  1.023e-05      \t|  0.00013559     \t|\n",
            "|  [Callback]ModelSummary.on_train_epoch_end                                                                                                                                                             \t|  1.0082e-05     \t|  1              \t|  1.0082e-05     \t|  0.00013363     \t|\n",
            "|  [LightningModule]MaterialsRFMLitModule.on_train_batch_end                                                                                                                                             \t|  3.346e-06      \t|  3              \t|  1.0038e-05     \t|  0.00013305     \t|\n",
            "|  [Callback]ModelSummary.on_sanity_check_end                                                                                                                                                            \t|  9.988e-06      \t|  1              \t|  9.988e-06      \t|  0.00013239     \t|\n",
            "|  [Callback]TQDMProgressBar.on_before_optimizer_step                                                                                                                                                    \t|  3.1087e-06     \t|  3              \t|  9.326e-06      \t|  0.00012361     \t|\n",
            "|  [Callback]TQDMProgressBar.on_fit_end                                                                                                                                                                  \t|  9.156e-06      \t|  1              \t|  9.156e-06      \t|  0.00012136     \t|\n",
            "|  [LightningModule]MaterialsRFMLitModule.on_after_backward                                                                                                                                              \t|  2.9807e-06     \t|  3              \t|  8.942e-06      \t|  0.00011852     \t|\n",
            "|  [Callback]GradientAccumulationScheduler.on_train_epoch_start                                                                                                                                          \t|  8.705e-06      \t|  1              \t|  8.705e-06      \t|  0.00011538     \t|\n",
            "|  [LightningModule]MaterialsRFMLitModule.training_step_end                                                                                                                                              \t|  2.7507e-06     \t|  3              \t|  8.252e-06      \t|  0.00010938     \t|\n",
            "|  [Callback]ModelSummary.on_sanity_check_start                                                                                                                                                          \t|  7.98e-06       \t|  1              \t|  7.98e-06       \t|  0.00010577     \t|\n",
            "|  [Callback]GradientAccumulationScheduler.on_train_batch_end                                                                                                                                            \t|  2.607e-06      \t|  3              \t|  7.821e-06      \t|  0.00010366     \t|\n",
            "|  [Callback]ModelSummary.on_train_batch_start                                                                                                                                                           \t|  2.591e-06      \t|  3              \t|  7.773e-06      \t|  0.00010303     \t|\n",
            "|  [LightningModule]MaterialsRFMLitModule.configure_callbacks                                                                                                                                            \t|  7.086e-06      \t|  1              \t|  7.086e-06      \t|  9.3922e-05     \t|\n",
            "|  [Callback]ModelCheckpoint{'monitor': 'val/loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None, 'save_on_train_epoch_end': True}.on_validation_batch_start\t|  3.435e-06      \t|  2              \t|  6.87e-06       \t|  9.1059e-05     \t|\n",
            "|  [Callback]ModelSummary.on_train_epoch_start                                                                                                                                                           \t|  6.87e-06       \t|  1              \t|  6.87e-06       \t|  9.1059e-05     \t|\n",
            "|  [Callback]ModelCheckpoint{'monitor': 'val/loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None, 'save_on_train_epoch_end': True}.on_train_batch_start     \t|  2.2463e-06     \t|  3              \t|  6.739e-06      \t|  8.9323e-05     \t|\n",
            "|  [Callback]ModelSummary.on_before_zero_grad                                                                                                                                                            \t|  2.226e-06      \t|  3              \t|  6.678e-06      \t|  8.8514e-05     \t|\n",
            "|  [Callback]GradientAccumulationScheduler.on_train_batch_start                                                                                                                                          \t|  2.1663e-06     \t|  3              \t|  6.499e-06      \t|  8.6142e-05     \t|\n",
            "|  [Callback]ModelSummary.on_after_backward                                                                                                                                                              \t|  2.1237e-06     \t|  3              \t|  6.371e-06      \t|  8.4445e-05     \t|\n",
            "|  [LightningModule]MaterialsRFMLitModule.on_before_zero_grad                                                                                                                                            \t|  2.0863e-06     \t|  3              \t|  6.259e-06      \t|  8.2961e-05     \t|\n",
            "|  [Callback]ModelSummary.on_validation_epoch_end                                                                                                                                                        \t|  2.976e-06      \t|  2              \t|  5.952e-06      \t|  7.8892e-05     \t|\n",
            "|  [Callback]ModelCheckpoint{'monitor': 'val/loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None, 'save_on_train_epoch_end': True}.on_before_backward       \t|  1.9353e-06     \t|  3              \t|  5.806e-06      \t|  7.6956e-05     \t|\n",
            "|  [Callback]ModelSummary.on_before_backward                                                                                                                                                             \t|  1.9213e-06     \t|  3              \t|  5.764e-06      \t|  7.64e-05       \t|\n",
            "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 100, 'train_time_interval': None, 'save_on_train_epoch_end': True}.on_before_zero_grad          \t|  1.914e-06      \t|  3              \t|  5.742e-06      \t|  7.6108e-05     \t|\n",
            "|  [Strategy]SingleDeviceStrategy.training_step_end                                                                                                                                                      \t|  1.908e-06      \t|  3              \t|  5.724e-06      \t|  7.587e-05      \t|\n",
            "|  [Callback]TQDMProgressBar.on_fit_start                                                                                                                                                                \t|  5.535e-06      \t|  1              \t|  5.535e-06      \t|  7.3364e-05     \t|\n",
            "|  [Callback]ModelCheckpoint{'monitor': 'val/loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None, 'save_on_train_epoch_end': True}.on_before_zero_grad      \t|  1.83e-06       \t|  3              \t|  5.49e-06       \t|  7.2768e-05     \t|\n",
            "|  [Callback]ModelCheckpoint{'monitor': 'val/loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None, 'save_on_train_epoch_end': True}.on_after_backward        \t|  1.8173e-06     \t|  3              \t|  5.452e-06      \t|  7.2264e-05     \t|\n",
            "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 100, 'train_time_interval': None, 'save_on_train_epoch_end': True}.on_train_batch_start         \t|  1.812e-06      \t|  3              \t|  5.436e-06      \t|  7.2052e-05     \t|\n",
            "|  [Callback]GradientAccumulationScheduler.on_validation_end                                                                                                                                             \t|  2.7035e-06     \t|  2              \t|  5.407e-06      \t|  7.1668e-05     \t|\n",
            "|  [Callback]ModelCheckpoint{'monitor': 'val/loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None, 'save_on_train_epoch_end': True}.on_before_optimizer_step \t|  1.7787e-06     \t|  3              \t|  5.336e-06      \t|  7.0727e-05     \t|\n",
            "|  [LightningModule]MaterialsRFMLitModule.on_before_backward                                                                                                                                             \t|  1.76e-06       \t|  3              \t|  5.28e-06       \t|  6.9985e-05     \t|\n",
            "|  [LightningModule]MaterialsRFMLitModule.on_before_optimizer_step                                                                                                                                       \t|  1.6753e-06     \t|  3              \t|  5.026e-06      \t|  6.6618e-05     \t|\n",
            "|  [Callback]GradientAccumulationScheduler.on_after_backward                                                                                                                                             \t|  1.671e-06      \t|  3              \t|  5.013e-06      \t|  6.6446e-05     \t|\n",
            "|  [Callback]GradientAccumulationScheduler.on_before_backward                                                                                                                                            \t|  1.6677e-06     \t|  3              \t|  5.003e-06      \t|  6.6313e-05     \t|\n",
            "|  [Callback]GradientAccumulationScheduler.on_before_zero_grad                                                                                                                                           \t|  1.6523e-06     \t|  3              \t|  4.957e-06      \t|  6.5703e-05     \t|\n",
            "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 100, 'train_time_interval': None, 'save_on_train_epoch_end': True}.on_before_backward           \t|  1.6187e-06     \t|  3              \t|  4.856e-06      \t|  6.4365e-05     \t|\n",
            "|  [Callback]GradientAccumulationScheduler.on_validation_batch_end                                                                                                                                       \t|  2.3945e-06     \t|  2              \t|  4.789e-06      \t|  6.3476e-05     \t|\n",
            "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 100, 'train_time_interval': None, 'save_on_train_epoch_end': True}.on_after_backward            \t|  1.5553e-06     \t|  3              \t|  4.666e-06      \t|  6.1846e-05     \t|\n",
            "|  [Callback]ModelCheckpoint{'monitor': 'val/loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None, 'save_on_train_epoch_end': True}.on_validation_batch_end  \t|  2.33e-06       \t|  2              \t|  4.66e-06       \t|  6.1767e-05     \t|\n",
            "|  [Callback]ModelSummary.on_before_optimizer_step                                                                                                                                                       \t|  1.538e-06      \t|  3              \t|  4.614e-06      \t|  6.1157e-05     \t|\n",
            "|  [Callback]ModelSummary.on_save_checkpoint                                                                                                                                                             \t|  2.3065e-06     \t|  2              \t|  4.613e-06      \t|  6.1144e-05     \t|\n",
            "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 100, 'train_time_interval': None, 'save_on_train_epoch_end': True}.on_before_optimizer_step     \t|  1.5173e-06     \t|  3              \t|  4.552e-06      \t|  6.0335e-05     \t|\n",
            "|  [Callback]GradientAccumulationScheduler.on_before_optimizer_step                                                                                                                                      \t|  1.4937e-06     \t|  3              \t|  4.481e-06      \t|  5.9394e-05     \t|\n",
            "|  [Callback]ModelCheckpoint{'monitor': 'val/loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None, 'save_on_train_epoch_end': True}.on_train_start           \t|  4.335e-06      \t|  1              \t|  4.335e-06      \t|  5.7459e-05     \t|\n",
            "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 100, 'train_time_interval': None, 'save_on_train_epoch_end': True}.on_validation_batch_start    \t|  2.111e-06      \t|  2              \t|  4.222e-06      \t|  5.5961e-05     \t|\n",
            "|  [Strategy]SingleDeviceStrategy.on_validation_start                                                                                                                                                    \t|  2.0105e-06     \t|  2              \t|  4.021e-06      \t|  5.3297e-05     \t|\n",
            "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 100, 'train_time_interval': None, 'save_on_train_epoch_end': True}.on_validation_batch_end      \t|  1.994e-06      \t|  2              \t|  3.988e-06      \t|  5.2859e-05     \t|\n",
            "|  [LightningModule]MaterialsRFMLitModule.on_validation_epoch_end                                                                                                                                        \t|  1.9845e-06     \t|  2              \t|  3.969e-06      \t|  5.2608e-05     \t|\n",
            "|  [Callback]ModelCheckpoint{'monitor': 'val/loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None, 'save_on_train_epoch_end': True}.on_save_checkpoint       \t|  1.908e-06      \t|  2              \t|  3.816e-06      \t|  5.058e-05      \t|\n",
            "|  [Callback]GradientAccumulationScheduler.on_validation_start                                                                                                                                           \t|  1.8815e-06     \t|  2              \t|  3.763e-06      \t|  4.9877e-05     \t|\n",
            "|  [Callback]GradientAccumulationScheduler.on_train_start                                                                                                                                                \t|  3.669e-06      \t|  1              \t|  3.669e-06      \t|  4.8631e-05     \t|\n",
            "|  [Callback]GradientAccumulationScheduler.on_save_checkpoint                                                                                                                                            \t|  1.8305e-06     \t|  2              \t|  3.661e-06      \t|  4.8525e-05     \t|\n",
            "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 100, 'train_time_interval': None, 'save_on_train_epoch_end': True}.on_validation_start          \t|  1.716e-06      \t|  2              \t|  3.432e-06      \t|  4.549e-05      \t|\n",
            "|  [Callback]ModelSummary.on_validation_epoch_start                                                                                                                                                      \t|  1.6835e-06     \t|  2              \t|  3.367e-06      \t|  4.4628e-05     \t|\n",
            "|  [Callback]GradientAccumulationScheduler.on_train_end                                                                                                                                                  \t|  3.356e-06      \t|  1              \t|  3.356e-06      \t|  4.4483e-05     \t|\n",
            "|  [Callback]ModelCheckpoint{'monitor': 'val/loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None, 'save_on_train_epoch_end': True}.on_validation_epoch_start\t|  1.676e-06      \t|  2              \t|  3.352e-06      \t|  4.443e-05      \t|\n",
            "|  [LightningDataModule]CrystDataModule.prepare_data                                                                                                                                                     \t|  3.281e-06      \t|  1              \t|  3.281e-06      \t|  4.3488e-05     \t|\n",
            "|  [Callback]ModelCheckpoint{'monitor': 'val/loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None, 'save_on_train_epoch_end': True}.on_validation_start      \t|  1.577e-06      \t|  2              \t|  3.154e-06      \t|  4.1805e-05     \t|\n",
            "|  [Callback]ModelSummary.setup                                                                                                                                                                          \t|  3.103e-06      \t|  1              \t|  3.103e-06      \t|  4.1129e-05     \t|\n",
            "|  [Callback]GradientAccumulationScheduler.on_validation_epoch_end                                                                                                                                       \t|  1.5025e-06     \t|  2              \t|  3.005e-06      \t|  3.983e-05      \t|\n",
            "|  [Callback]ModelCheckpoint{'monitor': 'val/loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None, 'save_on_train_epoch_end': True}.on_validation_epoch_end  \t|  1.4665e-06     \t|  2              \t|  2.933e-06      \t|  3.8876e-05     \t|\n",
            "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 100, 'train_time_interval': None, 'save_on_train_epoch_end': True}.on_validation_epoch_start    \t|  1.4545e-06     \t|  2              \t|  2.909e-06      \t|  3.8558e-05     \t|\n",
            "|  [Strategy]SingleDeviceStrategy.validation_step_end                                                                                                                                                    \t|  1.4485e-06     \t|  2              \t|  2.897e-06      \t|  3.8399e-05     \t|\n",
            "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 100, 'train_time_interval': None, 'save_on_train_epoch_end': True}.on_validation_epoch_end      \t|  1.4335e-06     \t|  2              \t|  2.867e-06      \t|  3.8001e-05     \t|\n",
            "|  [Callback]TQDMProgressBar.teardown                                                                                                                                                                    \t|  2.813e-06      \t|  1              \t|  2.813e-06      \t|  3.7285e-05     \t|\n",
            "|  [Callback]GradientAccumulationScheduler.on_train_epoch_end                                                                                                                                            \t|  2.702e-06      \t|  1              \t|  2.702e-06      \t|  3.5814e-05     \t|\n",
            "|  [LightningModule]MaterialsRFMLitModule.on_train_epoch_end                                                                                                                                             \t|  2.662e-06      \t|  1              \t|  2.662e-06      \t|  3.5284e-05     \t|\n",
            "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 100, 'train_time_interval': None, 'save_on_train_epoch_end': True}.on_save_checkpoint           \t|  1.329e-06      \t|  2              \t|  2.658e-06      \t|  3.5231e-05     \t|\n",
            "|  [Callback]GradientAccumulationScheduler.on_sanity_check_end                                                                                                                                           \t|  2.608e-06      \t|  1              \t|  2.608e-06      \t|  3.4568e-05     \t|\n",
            "|  [Callback]ModelCheckpoint{'monitor': 'val/loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None, 'save_on_train_epoch_end': True}.on_fit_start             \t|  2.602e-06      \t|  1              \t|  2.602e-06      \t|  3.4489e-05     \t|\n",
            "|  [Callback]GradientAccumulationScheduler.on_validation_epoch_start                                                                                                                                     \t|  1.276e-06      \t|  2              \t|  2.552e-06      \t|  3.3826e-05     \t|\n",
            "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 100, 'train_time_interval': None, 'save_on_train_epoch_end': True}.on_train_start               \t|  2.486e-06      \t|  1              \t|  2.486e-06      \t|  3.2951e-05     \t|\n",
            "|  [LightningModule]MaterialsRFMLitModule.on_train_epoch_start                                                                                                                                           \t|  2.463e-06      \t|  1              \t|  2.463e-06      \t|  3.2646e-05     \t|\n",
            "|  [LightningModule]MaterialsRFMLitModule.on_validation_epoch_start                                                                                                                                      \t|  1.2005e-06     \t|  2              \t|  2.401e-06      \t|  3.1824e-05     \t|\n",
            "|  [Strategy]SingleDeviceStrategy.on_train_start                                                                                                                                                         \t|  2.352e-06      \t|  1              \t|  2.352e-06      \t|  3.1175e-05     \t|\n",
            "|  [LightningModule]MaterialsRFMLitModule.setup                                                                                                                                                          \t|  2.351e-06      \t|  1              \t|  2.351e-06      \t|  3.1162e-05     \t|\n",
            "|  [Callback]ModelCheckpoint{'monitor': 'val/loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None, 'save_on_train_epoch_end': True}.on_train_epoch_start     \t|  2.297e-06      \t|  1              \t|  2.297e-06      \t|  3.0446e-05     \t|\n",
            "|  [LightningDataModule]CrystDataModule.teardown                                                                                                                                                         \t|  2.285e-06      \t|  1              \t|  2.285e-06      \t|  3.0287e-05     \t|\n",
            "|  [LightningModule]MaterialsRFMLitModule.prepare_data                                                                                                                                                   \t|  2.234e-06      \t|  1              \t|  2.234e-06      \t|  2.9611e-05     \t|\n",
            "|  [LightningModule]MaterialsRFMLitModule.on_fit_end                                                                                                                                                     \t|  2.234e-06      \t|  1              \t|  2.234e-06      \t|  2.9611e-05     \t|\n",
            "|  [LightningModule]MaterialsRFMLitModule.on_fit_start                                                                                                                                                   \t|  2.202e-06      \t|  1              \t|  2.202e-06      \t|  2.9187e-05     \t|\n",
            "|  [LightningModule]MaterialsRFMLitModule.on_save_checkpoint                                                                                                                                             \t|  1.086e-06      \t|  2              \t|  2.172e-06      \t|  2.8789e-05     \t|\n",
            "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 100, 'train_time_interval': None, 'save_on_train_epoch_end': True}.on_fit_start                 \t|  2.123e-06      \t|  1              \t|  2.123e-06      \t|  2.814e-05      \t|\n",
            "|  [LightningModule]MaterialsRFMLitModule.configure_sharded_model                                                                                                                                        \t|  2.106e-06      \t|  1              \t|  2.106e-06      \t|  2.7914e-05     \t|\n",
            "|  [LightningModule]MaterialsRFMLitModule.on_train_start                                                                                                                                                 \t|  2.053e-06      \t|  1              \t|  2.053e-06      \t|  2.7212e-05     \t|\n",
            "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 100, 'train_time_interval': None, 'save_on_train_epoch_end': True}.on_train_epoch_start         \t|  1.891e-06      \t|  1              \t|  1.891e-06      \t|  2.5065e-05     \t|\n",
            "|  [Strategy]SingleDeviceStrategy.on_train_end                                                                                                                                                           \t|  1.856e-06      \t|  1              \t|  1.856e-06      \t|  2.4601e-05     \t|\n",
            "|  [Callback]ModelSummary.on_fit_end                                                                                                                                                                     \t|  1.826e-06      \t|  1              \t|  1.826e-06      \t|  2.4203e-05     \t|\n",
            "|  [Callback]GradientAccumulationScheduler.setup                                                                                                                                                         \t|  1.782e-06      \t|  1              \t|  1.782e-06      \t|  2.362e-05      \t|\n",
            "|  [LightningModule]MaterialsRFMLitModule.on_train_end                                                                                                                                                   \t|  1.751e-06      \t|  1              \t|  1.751e-06      \t|  2.3209e-05     \t|\n",
            "|  [Callback]GradientAccumulationScheduler.on_sanity_check_start                                                                                                                                         \t|  1.712e-06      \t|  1              \t|  1.712e-06      \t|  2.2692e-05     \t|\n",
            "|  [Callback]GradientAccumulationScheduler.on_fit_end                                                                                                                                                    \t|  1.677e-06      \t|  1              \t|  1.677e-06      \t|  2.2228e-05     \t|\n",
            "|  [Callback]ModelCheckpoint{'monitor': 'val/loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None, 'save_on_train_epoch_end': True}.on_train_end             \t|  1.657e-06      \t|  1              \t|  1.657e-06      \t|  2.1963e-05     \t|\n",
            "|  [Callback]ModelCheckpoint{'monitor': 'val/loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None, 'save_on_train_epoch_end': True}.on_sanity_check_end      \t|  1.609e-06      \t|  1              \t|  1.609e-06      \t|  2.1327e-05     \t|\n",
            "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 100, 'train_time_interval': None, 'save_on_train_epoch_end': True}.on_train_end                 \t|  1.608e-06      \t|  1              \t|  1.608e-06      \t|  2.1313e-05     \t|\n",
            "|  [Callback]ModelSummary.teardown                                                                                                                                                                       \t|  1.57e-06       \t|  1              \t|  1.57e-06       \t|  2.081e-05      \t|\n",
            "|  [Callback]ModelCheckpoint{'monitor': 'val/loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None, 'save_on_train_epoch_end': True}.on_fit_end               \t|  1.546e-06      \t|  1              \t|  1.546e-06      \t|  2.0492e-05     \t|\n",
            "|  [Callback]ModelCheckpoint{'monitor': 'val/loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None, 'save_on_train_epoch_end': True}.on_sanity_check_start    \t|  1.488e-06      \t|  1              \t|  1.488e-06      \t|  1.9723e-05     \t|\n",
            "|  [Callback]ModelCheckpoint{'monitor': 'val/loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None, 'save_on_train_epoch_end': True}.teardown                 \t|  1.422e-06      \t|  1              \t|  1.422e-06      \t|  1.8848e-05     \t|\n",
            "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 100, 'train_time_interval': None, 'save_on_train_epoch_end': True}.teardown                     \t|  1.414e-06      \t|  1              \t|  1.414e-06      \t|  1.8742e-05     \t|\n",
            "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 100, 'train_time_interval': None, 'save_on_train_epoch_end': True}.on_fit_end                   \t|  1.398e-06      \t|  1              \t|  1.398e-06      \t|  1.853e-05      \t|\n",
            "|  [Callback]GradientAccumulationScheduler.teardown                                                                                                                                                      \t|  1.376e-06      \t|  1              \t|  1.376e-06      \t|  1.8238e-05     \t|\n",
            "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 100, 'train_time_interval': None, 'save_on_train_epoch_end': True}.on_sanity_check_start        \t|  1.372e-06      \t|  1              \t|  1.372e-06      \t|  1.8185e-05     \t|\n",
            "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 100, 'train_time_interval': None, 'save_on_train_epoch_end': True}.on_sanity_check_end          \t|  1.336e-06      \t|  1              \t|  1.336e-06      \t|  1.7708e-05     \t|\n",
            "|  [LightningModule]MaterialsRFMLitModule.teardown                                                                                                                                                       \t|  1.171e-06      \t|  1              \t|  1.171e-06      \t|  1.5521e-05     \t|\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "/usr/local/envs/flowmm_env/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:145: UserWarning: `.test(ckpt_path=\"best\")` is called with Trainer configured with multiple `ModelCheckpoint` callbacks. It will use the best checkpoint path from first checkpoint callback.\n",
            "  rank_zero_warn(\n",
            "Restoring states from the checkpoint path at /content/flowmm/runs/trash/2025-05-30/19-49-50/abits_params-rfm_cspnet-sr7kny01/checkpoints/epoch=0-step=3.ckpt\n",
            "Loaded model weights from checkpoint at /content/flowmm/runs/trash/2025-05-30/19-49-50/abits_params-rfm_cspnet-sr7kny01/checkpoints/epoch=0-step=3.ckpt\n",
            "Error executing job with overrides: ['data=supercon', 'model=abits_params', 'train.pl_trainer.accelerator=cpu', 'train.pl_trainer.devices=1', 'train.model_checkpoints.save_last=True', 'logging.val_check_interval=1', 'train.pl_trainer.max_epochs=1']\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/envs/flowmm_env/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/local/envs/flowmm_env/lib/python3.9/runpy.py\", line 87, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/flowmm/scripts_model/run.py\", line 209, in <module>\n",
            "    main()\n",
            "  File \"/usr/local/envs/flowmm_env/lib/python3.9/site-packages/hydra/main.py\", line 90, in decorated_main\n",
            "    _run_hydra(\n",
            "  File \"/usr/local/envs/flowmm_env/lib/python3.9/site-packages/hydra/_internal/utils.py\", line 389, in _run_hydra\n",
            "    _run_app(\n",
            "  File \"/usr/local/envs/flowmm_env/lib/python3.9/site-packages/hydra/_internal/utils.py\", line 452, in _run_app\n",
            "    run_and_report(\n",
            "  File \"/usr/local/envs/flowmm_env/lib/python3.9/site-packages/hydra/_internal/utils.py\", line 216, in run_and_report\n",
            "    raise ex\n",
            "  File \"/usr/local/envs/flowmm_env/lib/python3.9/site-packages/hydra/_internal/utils.py\", line 213, in run_and_report\n",
            "    return func()\n",
            "  File \"/usr/local/envs/flowmm_env/lib/python3.9/site-packages/hydra/_internal/utils.py\", line 453, in <lambda>\n",
            "    lambda: hydra.run(\n",
            "  File \"/usr/local/envs/flowmm_env/lib/python3.9/site-packages/hydra/_internal/hydra.py\", line 132, in run\n",
            "    _ = ret.return_value\n",
            "  File \"/usr/local/envs/flowmm_env/lib/python3.9/site-packages/hydra/core/utils.py\", line 260, in return_value\n",
            "    raise self._return_value\n",
            "  File \"/usr/local/envs/flowmm_env/lib/python3.9/site-packages/hydra/core/utils.py\", line 186, in run_job\n",
            "    ret.return_value = task_function(task_cfg)\n",
            "  File \"/content/flowmm/scripts_model/run.py\", line 205, in main\n",
            "    run(cfg)\n",
            "  File \"/content/flowmm/scripts_model/run.py\", line 192, in run\n",
            "    trainer.test(datamodule=datamodule, ckpt_path=ckpt_path)\n",
            "  File \"/usr/local/envs/flowmm_env/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\", line 780, in test\n",
            "    return call._call_and_handle_interrupt(\n",
            "  File \"/usr/local/envs/flowmm_env/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py\", line 38, in _call_and_handle_interrupt\n",
            "    return trainer_fn(*args, **kwargs)\n",
            "  File \"/usr/local/envs/flowmm_env/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\", line 829, in _test_impl\n",
            "    results = self._run(model, ckpt_path=self.ckpt_path)\n",
            "  File \"/usr/local/envs/flowmm_env/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\", line 1098, in _run\n",
            "    results = self._run_stage()\n",
            "  File \"/usr/local/envs/flowmm_env/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\", line 1174, in _run_stage\n",
            "    return self._run_evaluate()\n",
            "  File \"/usr/local/envs/flowmm_env/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\", line 1214, in _run_evaluate\n",
            "    eval_loop_results = self._evaluation_loop.run()\n",
            "  File \"/usr/local/envs/flowmm_env/lib/python3.9/site-packages/pytorch_lightning/loops/loop.py\", line 199, in run\n",
            "    self.advance(*args, **kwargs)\n",
            "  File \"/usr/local/envs/flowmm_env/lib/python3.9/site-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py\", line 152, in advance\n",
            "    dl_outputs = self.epoch_loop.run(self._data_fetcher, dl_max_batches, kwargs)\n",
            "  File \"/usr/local/envs/flowmm_env/lib/python3.9/site-packages/pytorch_lightning/loops/loop.py\", line 199, in run\n",
            "    self.advance(*args, **kwargs)\n",
            "  File \"/usr/local/envs/flowmm_env/lib/python3.9/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py\", line 137, in advance\n",
            "    output = self._evaluation_step(**kwargs)\n",
            "  File \"/usr/local/envs/flowmm_env/lib/python3.9/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py\", line 234, in _evaluation_step\n",
            "    output = self.trainer._call_strategy_hook(hook_name, *kwargs.values())\n",
            "  File \"/usr/local/envs/flowmm_env/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\", line 1480, in _call_strategy_hook\n",
            "    output = fn(*args, **kwargs)\n",
            "  File \"/usr/local/envs/flowmm_env/lib/python3.9/site-packages/pytorch_lightning/strategies/strategy.py\", line 399, in test_step\n",
            "    return self.model.test_step(*args, **kwargs)\n",
            "  File \"/content/flowmm/src/flowmm/model/model_pl.py\", line 1030, in test_step\n",
            "    return self.shared_eval_step(\n",
            "  File \"/content/flowmm/src/flowmm/model/model_pl.py\", line 736, in shared_eval_step\n",
            "    loss_dict = self.loss_fn(batch)\n",
            "  File \"/content/flowmm/src/flowmm/model/model_pl.py\", line 546, in loss_fn\n",
            "    return self.rfm_loss_fn(batch, *args, **kwargs)\n",
            "  File \"/content/flowmm/src/flowmm/model/model_pl.py\", line 594, in rfm_loss_fn\n",
            "    x_t, u_t = manifold.cond_u(x0, x1, t)\n",
            "  File \"/content/flowmm/src/flowmm/rfm/vmap.py\", line 235, in cond_u\n",
            "    return self.vmap(CondU, (x0, x1, t), data_in_dim=data_in_dim)\n",
            "  File \"/content/flowmm/src/flowmm/rfm/vmap.py\", line 125, in vmap\n",
            "    return torch.func.vmap(wrapper, (0, 0, data_in_dim), randomness=\"different\")(\n",
            "  File \"/usr/local/envs/flowmm_env/lib/python3.9/site-packages/torch/_functorch/apis.py\", line 188, in wrapped\n",
            "    return vmap_impl(func, in_dims, out_dims, randomness, chunk_size, *args, **kwargs)\n",
            "  File \"/usr/local/envs/flowmm_env/lib/python3.9/site-packages/torch/_functorch/vmap.py\", line 266, in vmap_impl\n",
            "    return _flat_vmap(\n",
            "  File \"/usr/local/envs/flowmm_env/lib/python3.9/site-packages/torch/_functorch/vmap.py\", line 38, in fn\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/envs/flowmm_env/lib/python3.9/site-packages/torch/_functorch/vmap.py\", line 379, in _flat_vmap\n",
            "    batched_outputs = func(*batched_inputs, **kwargs)\n",
            "  File \"/content/flowmm/src/flowmm/rfm/vmap.py\", line 118, in wrapper\n",
            "    return torch.func.functional_call(\n",
            "  File \"/usr/local/envs/flowmm_env/lib/python3.9/site-packages/torch/_functorch/functional_call.py\", line 143, in functional_call\n",
            "    return nn.utils.stateless._functional_call(\n",
            "  File \"/usr/local/envs/flowmm_env/lib/python3.9/site-packages/torch/nn/utils/stateless.py\", line 264, in _functional_call\n",
            "    return module(*args, **kwargs)\n",
            "  File \"/usr/local/envs/flowmm_env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/envs/flowmm_env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/flowmm/src/flowmm/rfm/vmap.py\", line 24, in forward\n",
            "    return method(*args, **kwargs)\n",
            "  File \"/content/flowmm/src/flowmm/rfm/manifolds/product.py\", line 106, in cond_u\n",
            "    x_t, u_t = self._cond_u(manifold, x0p, x1p, t)\n",
            "  File \"/content/flowmm/src/flowmm/rfm/manifolds/product.py\", line 95, in _cond_u\n",
            "    x_t, u_t = jvp(path, (t,), (torch.ones_like(t).to(t),))\n",
            "  File \"/usr/local/envs/flowmm_env/lib/python3.9/site-packages/torch/_functorch/eager_transforms.py\", line 919, in jvp\n",
            "    return _jvp_with_argnums(func, primals, tangents, argnums=None, strict=strict, has_aux=has_aux)\n",
            "  File \"/usr/local/envs/flowmm_env/lib/python3.9/site-packages/torch/_functorch/vmap.py\", line 38, in fn\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/envs/flowmm_env/lib/python3.9/site-packages/torch/_functorch/eager_transforms.py\", line 962, in _jvp_with_argnums\n",
            "    flat_duals = tuple(fwAD.make_dual(p, t)\n",
            "  File \"/usr/local/envs/flowmm_env/lib/python3.9/site-packages/torch/_functorch/eager_transforms.py\", line 962, in <genexpr>\n",
            "    flat_duals = tuple(fwAD.make_dual(p, t)\n",
            "  File \"/usr/local/envs/flowmm_env/lib/python3.9/site-packages/torch/autograd/forward_ad.py\", line 121, in make_dual\n",
            "    return torch._VF._make_dual(tensor, tangent, level=level)\n",
            "RuntimeError: Batching rule not implemented for aten::_make_dual; the fallback path doesn't work on out= or view ops.\n",
            "\n",
            "ERROR conda.cli.main_run:execute(125): `conda run python -u -m scripts_model.run data=supercon model=abits_params train.pl_trainer.accelerator=cpu train.pl_trainer.devices=1 train.model_checkpoints.save_last=True logging.val_check_interval=1 train.pl_trainer.max_epochs=1` failed. (See above for error)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conditional Training"
      ],
      "metadata": {
        "id": "BdD4OYhiZ6RR"
      },
      "id": "BdD4OYhiZ6RR"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b4bd253",
      "metadata": {
        "id": "1b4bd253",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "%cd /content/flowmm\n",
        "!bash create_env_file.sh && \\\n",
        " echo \"successfully ran create_env_file.sh\" && \\\n",
        " HYDRA_FULL_ERROR=1 \\\n",
        " conda run -p /usr/local/envs/flowmm_env --live-stream \\\n",
        "    python -u -m scripts_model.run data=supercon model=null_params"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FlowLLM Training"
      ],
      "metadata": {
        "id": "7w1-2_bTg2JE"
      },
      "id": "7w1-2_bTg2JE"
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/flowmm\n",
        "!bash create_env_file.sh && \\\n",
        " echo \"successfully ran create_env_file.sh\" && \\\n",
        " HYDRA_FULL_ERROR=1 \\\n",
        " conda run -p /usr/local/envs/flowmm_env --live-stream \\\n",
        "    python -u -m scripts_model.run data=mp20_llama model=null_params \\\n",
        "      base_distribution_from_data=True"
      ],
      "metadata": {
        "id": "4Yp_mWsEg01N"
      },
      "id": "4Yp_mWsEg01N",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (5) INFERENCE\n",
        "# Unconditional Evaluation - De Novo Generation\n",
        "\n"
      ],
      "metadata": {
        "id": "82OOqQ49aAgQ"
      },
      "id": "82OOqQ49aAgQ"
    },
    {
      "cell_type": "code",
      "source": [
        "!bash create_env_file.sh && \\\n",
        " echo \"successfully ran create_env_file.sh\" && \\\n",
        " ckpt=PATH_TO_CHECKPOINT \\\n",
        " subdir=NAME_OF_SUBDIRECTORY_AT_CHECKPOINT \\\n",
        " slope=SLOPE_OF_INFERENCE_ANTI_ANNEALING \\\n",
        " conda run -p /usr/local/envs/flowmm_env --live-stream \\\n",
        "    python scripts_model/evaluate.py generate ${ckpt} --subdir ${subdir} \\\n",
        "      --inference_anneal_slope ${slope} --stage test && \\\n",
        "    python scripts_model/evaluate.py consolidate ${ckpt} --subdir ${subdir} && \\\n",
        "    python scripts_model/evaluate.py old_eval_metrics ${ckpt} --subdir ${subdir} \\\n",
        "      --stage test && \\\n",
        "    python scripts_model/evaluate.py lattice_metrics ${ckpt} --subdir ${subdir} \\\n",
        "      --stage test"
      ],
      "metadata": {
        "id": "36yfncwoIjTG"
      },
      "id": "36yfncwoIjTG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from pprint import pprint\n",
        "path = \"/content/cdvae/hydra_outputs/singlerun/2025-05-27/supercon/eval_recon.pt\"\n",
        "data = torch.load(path, map_location=\"cpu\", weights_only=False)\n",
        "pprint(data, width=120, indent=2)"
      ],
      "metadata": {
        "id": "OU1Tnz-jEIGH"
      },
      "id": "OU1Tnz-jEIGH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conditional Evaluation - Crystal Structure Prediction - Reconstruction"
      ],
      "metadata": {
        "id": "mLqYqyMOffIa"
      },
      "id": "mLqYqyMOffIa"
    },
    {
      "cell_type": "code",
      "source": [
        "!bash create_env_file.sh && \\\n",
        " echo \"successfully ran create_env_file.sh\" && \\\n",
        " ckpt=PATH_TO_CHECKPOINT \\\n",
        " subdir=NAME_OF_SUBDIRECTORY_AT_CHECKPOINT \\\n",
        " slope=SLOPE_OF_INFERENCE_ANTI_ANNEALING \\\n",
        " conda run -p /usr/local/envs/flowmm_env --live-stream \\\n",
        "    python scripts_model/evaluate.py reconstruct ${ckpt} --subdir ${subdir} \\\n",
        "      --inference_anneal_slope ${slope} --stage test && \\\n",
        "    python scripts_model/evaluate.py consolidate ${ckpt} --subdir ${subdir} && \\\n",
        "    python scripts_model/evaluate.py old_eval_metrics ${ckpt} --subdir ${subdir} \\\n",
        "      --stage test && \\\n",
        "    python scripts_model/evaluate.py lattice_metrics ${ckpt} --subdir ${subdir} \\\n",
        "      --stage test"
      ],
      "metadata": {
        "id": "Nt5aa6zwfpjw"
      },
      "id": "Nt5aa6zwfpjw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from pprint import pprint\n",
        "path = \"/content/cdvae/hydra_outputs/singlerun/2025-05-27/supercon/eval_recon.pt\"\n",
        "data = torch.load(path, map_location=\"cpu\", weights_only=False)\n",
        "pprint(data, width=120, indent=2)"
      ],
      "metadata": {
        "id": "fHke2Kl8gkqa"
      },
      "id": "fHke2Kl8gkqa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (6) NEXT STEPS & REFERENCES\n",
        "\n",
        "## Next Steps\n",
        "\n",
        "1. **Hyperparameter exploration**  \n",
        "   - Try different numbers of noise levels (`model.num_noise_level`) and training epochs to improve sample quality.\n",
        "\n",
        "2. **Property-conditioned generation**  \n",
        "   - Re-enable the property predictor (`model.predict_property=True`) and train with longer schedules to improve prediction accuracy.\n",
        "   - After training, sample structures by specifying a target critical temperature and evaluate via DFT or empirical models.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "## References\n",
        "\n",
        "- **Original CDVAE paper:**  \n",
        "  Li _et al._, “Crystal Diffusion Variational Autoencoder for Inverse Materials Design,” _J. Phys. Chem. Lett._ 2023, DOI: [10.1021/acs.jpclett.3c01260](https://pubs.acs.org/doi/10.1021/acs.jpclett.3c01260)\n",
        "\n",
        "- **CDVAE GitHub repo:**  \n",
        "  https://github.com/txie-93/cdvae\n",
        "\n",
        "- **JARVIS-Materials-Design:**  \n",
        "  https://github.com/JARVIS-Materials-Design/jarvis\n",
        "\n",
        "- **Hydra configuration framework:**  \n",
        "  https://hydra.cc\n",
        "\n",
        "- **PyTorch Lightning:**  \n",
        "  https://www.pytorchlightning.ai\n",
        "\n",
        "- **condacolab:**  \n",
        "  https://github.com/conda-incubator/condacolab\n",
        "\n",
        "- **Mamba (fast conda):**  \n",
        "  https://github.com/mamba-org/mamba\n",
        "\n",
        "- **Jarvis-tools (data ETL):**  \n",
        "  https://github.com/JARVIS-Materials-Design/jarvis-tools\n"
      ],
      "metadata": {
        "id": "jl8B-XPE-GR3"
      },
      "id": "jl8B-XPE-GR3"
    }
  ],
  "metadata": {
    "jupytext": {
      "cell_metadata_filter": "-all",
      "encoding": "# -*- coding: utf-8 -*-",
      "main_language": "python",
      "notebook_metadata_filter": "-all"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}